{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using Naive Bayes classifier described in this chapter, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "from nltk.classify import MaxentClassifier\n",
    "from nltk.classify import apply_features\n",
    "from nltk.classify import accuracy\n",
    "from nltk import ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(names)\n",
    "\n",
    "# Sample the file into test, devtest and training datasets:\n",
    "test, devtest, training = names[:500], names[500:1000], names[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the example name gender classifier as we did in class:\n",
    "def gender_features1(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'm',\n",
       " 'last_letter': 'e',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 1,\n",
       " 'has(e)': True,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 0,\n",
       " 'has(h)': False,\n",
       " 'count(i)': 1,\n",
       " 'has(i)': True,\n",
       " 'count(j)': 0,\n",
       " 'has(j)': False,\n",
       " 'count(k)': 1,\n",
       " 'has(k)': True,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 1,\n",
       " 'has(m)': True,\n",
       " 'count(n)': 0,\n",
       " 'has(n)': False,\n",
       " 'count(o)': 0,\n",
       " 'has(o)': False,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verfiy one example name:\n",
    "gender_features1('Mike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Devtest for gender_features1: 74.0 %\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier for training and dev test for gender_features_1:\n",
    "train_set = [(gender_features1(n), g) for (n,g) in training]\n",
    "devtest_set = [(gender_features1(n), g) for (n,g) in devtest]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy of Devtest for gender_features1:\", round((nltk.classify.accuracy(classifier, devtest_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Analysis of which ones were classified wrong:\n",
    "def error_analysis(gender_features):\n",
    "    errors = []\n",
    "    for (name, tag) in devtest:\n",
    "        guess = classifier.classify(gender_features(name))\n",
    "        if guess != tag:\n",
    "            errors.append((tag, guess, name))\n",
    "    print ('no. of errors: ', len(errors))\n",
    "        \n",
    "    for (tag, guess, name) in sorted(errors):\n",
    "        print ('correct=%-8s guess=%-8s name=%-30s' % (tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of errors:  130\n",
      "correct=female   guess=male     name=Ardis                         \n",
      "correct=female   guess=male     name=Astrix                        \n",
      "correct=female   guess=male     name=Bel                           \n",
      "correct=female   guess=male     name=Bess                          \n",
      "correct=female   guess=male     name=Bev                           \n",
      "correct=female   guess=male     name=Brunhilde                     \n",
      "correct=female   guess=male     name=Cathryn                       \n",
      "correct=female   guess=male     name=Coreen                        \n",
      "correct=female   guess=male     name=Correy                        \n",
      "correct=female   guess=male     name=Darb                          \n",
      "correct=female   guess=male     name=Dode                          \n",
      "correct=female   guess=male     name=Donny                         \n",
      "correct=female   guess=male     name=Elsbeth                       \n",
      "correct=female   guess=male     name=Farah                         \n",
      "correct=female   guess=male     name=Florry                        \n",
      "correct=female   guess=male     name=Fran                          \n",
      "correct=female   guess=male     name=Freddi                        \n",
      "correct=female   guess=male     name=Gerry                         \n",
      "correct=female   guess=male     name=Glad                          \n",
      "correct=female   guess=male     name=Gretchen                      \n",
      "correct=female   guess=male     name=Gunvor                        \n",
      "correct=female   guess=male     name=Gus                           \n",
      "correct=female   guess=male     name=Hesther                       \n",
      "correct=female   guess=male     name=Inez                          \n",
      "correct=female   guess=male     name=Jewell                        \n",
      "correct=female   guess=male     name=Joey                          \n",
      "correct=female   guess=male     name=Kirstin                       \n",
      "correct=female   guess=male     name=Marybeth                      \n",
      "correct=female   guess=male     name=Marys                         \n",
      "correct=female   guess=male     name=Meggy                         \n",
      "correct=female   guess=male     name=Melody                        \n",
      "correct=female   guess=male     name=Modesty                       \n",
      "correct=female   guess=male     name=Monique                       \n",
      "correct=female   guess=male     name=Noreen                        \n",
      "correct=female   guess=male     name=Olly                          \n",
      "correct=female   guess=male     name=Pearl                         \n",
      "correct=female   guess=male     name=Pegeen                        \n",
      "correct=female   guess=male     name=Pet                           \n",
      "correct=female   guess=male     name=Reiko                         \n",
      "correct=female   guess=male     name=Rhodie                        \n",
      "correct=female   guess=male     name=Rosemonde                     \n",
      "correct=female   guess=male     name=Rubie                         \n",
      "correct=female   guess=male     name=Ruthanne                      \n",
      "correct=female   guess=male     name=Sharity                       \n",
      "correct=female   guess=male     name=Sharl                         \n",
      "correct=female   guess=male     name=Sharon                        \n",
      "correct=female   guess=male     name=Sheelagh                      \n",
      "correct=female   guess=male     name=Sherye                        \n",
      "correct=female   guess=male     name=Siouxie                       \n",
      "correct=female   guess=male     name=Sunny                         \n",
      "correct=female   guess=male     name=Suzan                         \n",
      "correct=female   guess=male     name=Sybyl                         \n",
      "correct=female   guess=male     name=Tamar                         \n",
      "correct=female   guess=male     name=Tobye                         \n",
      "correct=female   guess=male     name=Ursuline                      \n",
      "correct=female   guess=male     name=Wandis                        \n",
      "correct=female   guess=male     name=Wendy                         \n",
      "correct=female   guess=male     name=Wilie                         \n",
      "correct=female   guess=male     name=Wini                          \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=female   guess=male     name=Zorah                         \n",
      "correct=male     guess=female   name=Aditya                        \n",
      "correct=male     guess=female   name=Alejandro                     \n",
      "correct=male     guess=female   name=Alexis                        \n",
      "correct=male     guess=female   name=Allyn                         \n",
      "correct=male     guess=female   name=Anatole                       \n",
      "correct=male     guess=female   name=Antone                        \n",
      "correct=male     guess=female   name=Arvin                         \n",
      "correct=male     guess=female   name=Bailie                        \n",
      "correct=male     guess=female   name=Beale                         \n",
      "correct=male     guess=female   name=Bubba                         \n",
      "correct=male     guess=female   name=Carl                          \n",
      "correct=male     guess=female   name=Clay                          \n",
      "correct=male     guess=female   name=Clement                       \n",
      "correct=male     guess=female   name=Colin                         \n",
      "correct=male     guess=female   name=Conan                         \n",
      "correct=male     guess=female   name=Denny                         \n",
      "correct=male     guess=female   name=Donal                         \n",
      "correct=male     guess=female   name=Donnie                        \n",
      "correct=male     guess=female   name=Dorian                        \n",
      "correct=male     guess=female   name=Elnar                         \n",
      "correct=male     guess=female   name=Emanuel                       \n",
      "correct=male     guess=female   name=Erich                         \n",
      "correct=male     guess=female   name=Ernie                         \n",
      "correct=male     guess=female   name=Esteban                       \n",
      "correct=male     guess=female   name=Felice                        \n",
      "correct=male     guess=female   name=Finn                          \n",
      "correct=male     guess=female   name=Gavin                         \n",
      "correct=male     guess=female   name=Gay                           \n",
      "correct=male     guess=female   name=Hillary                       \n",
      "correct=male     guess=female   name=Jere                          \n",
      "correct=male     guess=female   name=Jermain                       \n",
      "correct=male     guess=female   name=Jessey                        \n",
      "correct=male     guess=female   name=Jimmy                         \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Johnnie                       \n",
      "correct=male     guess=female   name=Joshua                        \n",
      "correct=male     guess=female   name=Jule                          \n",
      "correct=male     guess=female   name=Kelley                        \n",
      "correct=male     guess=female   name=Leigh                         \n",
      "correct=male     guess=female   name=Lenard                        \n",
      "correct=male     guess=female   name=Leslie                        \n",
      "correct=male     guess=female   name=Levi                          \n",
      "correct=male     guess=female   name=Lionel                        \n",
      "correct=male     guess=female   name=Marchall                      \n",
      "correct=male     guess=female   name=Matt                          \n",
      "correct=male     guess=female   name=Micky                         \n",
      "correct=male     guess=female   name=Mike                          \n",
      "correct=male     guess=female   name=Mitchael                      \n",
      "correct=male     guess=female   name=Nevile                        \n",
      "correct=male     guess=female   name=Neville                       \n",
      "correct=male     guess=female   name=Nicholas                      \n",
      "correct=male     guess=female   name=Nickey                        \n",
      "correct=male     guess=female   name=Nigel                         \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Pail                          \n",
      "correct=male     guess=female   name=Pate                          \n",
      "correct=male     guess=female   name=Rickie                        \n",
      "correct=male     guess=female   name=Ripley                        \n",
      "correct=male     guess=female   name=Samuele                       \n",
      "correct=male     guess=female   name=Shea                          \n",
      "correct=male     guess=female   name=Sibyl                         \n",
      "correct=male     guess=female   name=Silvan                        \n",
      "correct=male     guess=female   name=Smitty                        \n",
      "correct=male     guess=female   name=Tallie                        \n",
      "correct=male     guess=female   name=Tanney                        \n",
      "correct=male     guess=female   name=Virge                         \n",
      "correct=male     guess=female   name=Vite                          \n",
      "correct=male     guess=female   name=Vladamir                      \n",
      "correct=male     guess=female   name=Voltaire                      \n"
     ]
    }
   ],
   "source": [
    "# Error Analysis for first combination of features from gender_features_1:\n",
    "error_analysis(gender_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test set for gender_features2: 77.0 %\n"
     ]
    }
   ],
   "source": [
    "# Final performance of the test set for gender_features_1:\n",
    "test_set = [(gender_features1(n), g) for (n,g) in test]\n",
    "print(\"Accuracy of Test set for gender_features2:\", round((nltk.classify.accuracy(classifier, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using incremental approach I am trying to add more features now:\n",
    "# Let me call it gender_features_2 -- I have added for features for suffixes:\n",
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"suffix3\"] = name[-3:].lower()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Devtest for gender_features2: 79.8 %\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier for training and dev test for gender_features_2:\n",
    "train_set = [(gender_features2(n), g) for (n,g) in training]\n",
    "devtest_set = [(gender_features2(n), g) for (n,g) in devtest]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy of Devtest for gender_features2:\", round((nltk.classify.accuracy(classifier, devtest_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of errors:  101\n",
      "correct=female   guess=male     name=Bamby                         \n",
      "correct=female   guess=male     name=Bess                          \n",
      "correct=female   guess=male     name=Bev                           \n",
      "correct=female   guess=male     name=Constance                     \n",
      "correct=female   guess=male     name=Correy                        \n",
      "correct=female   guess=male     name=Darb                          \n",
      "correct=female   guess=male     name=Darell                        \n",
      "correct=female   guess=male     name=Debby                         \n",
      "correct=female   guess=male     name=Devan                         \n",
      "correct=female   guess=male     name=Devin                         \n",
      "correct=female   guess=male     name=Dode                          \n",
      "correct=female   guess=male     name=Donny                         \n",
      "correct=female   guess=male     name=Eran                          \n",
      "correct=female   guess=male     name=Fancy                         \n",
      "correct=female   guess=male     name=Florry                        \n",
      "correct=female   guess=male     name=Fran                          \n",
      "correct=female   guess=male     name=Gerry                         \n",
      "correct=female   guess=male     name=Glad                          \n",
      "correct=female   guess=male     name=Gretchen                      \n",
      "correct=female   guess=male     name=Gunvor                        \n",
      "correct=female   guess=male     name=Gus                           \n",
      "correct=female   guess=male     name=Hesther                       \n",
      "correct=female   guess=male     name=Inez                          \n",
      "correct=female   guess=male     name=Jewell                        \n",
      "correct=female   guess=male     name=Joey                          \n",
      "correct=female   guess=male     name=Kirstin                       \n",
      "correct=female   guess=male     name=Konstance                     \n",
      "correct=female   guess=male     name=Kristan                       \n",
      "correct=female   guess=male     name=Mariam                        \n",
      "correct=female   guess=male     name=Meggy                         \n",
      "correct=female   guess=male     name=Melody                        \n",
      "correct=female   guess=male     name=Milicent                      \n",
      "correct=female   guess=male     name=Modesty                       \n",
      "correct=female   guess=male     name=Monique                       \n",
      "correct=female   guess=male     name=Pearl                         \n",
      "correct=female   guess=male     name=Pet                           \n",
      "correct=female   guess=male     name=Reiko                         \n",
      "correct=female   guess=male     name=Rhodie                        \n",
      "correct=female   guess=male     name=Sharl                         \n",
      "correct=female   guess=male     name=Sharon                        \n",
      "correct=female   guess=male     name=Sheelagh                      \n",
      "correct=female   guess=male     name=Siouxie                       \n",
      "correct=female   guess=male     name=Sunny                         \n",
      "correct=female   guess=male     name=Suzan                         \n",
      "correct=female   guess=male     name=Sybyl                         \n",
      "correct=female   guess=male     name=Tamar                         \n",
      "correct=female   guess=male     name=Wandis                        \n",
      "correct=female   guess=male     name=Wendy                         \n",
      "correct=female   guess=male     name=Wini                          \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=male     guess=female   name=Aditya                        \n",
      "correct=male     guess=female   name=Alexis                        \n",
      "correct=male     guess=female   name=Allyn                         \n",
      "correct=male     guess=female   name=Anatole                       \n",
      "correct=male     guess=female   name=Antone                        \n",
      "correct=male     guess=female   name=Bailie                        \n",
      "correct=male     guess=female   name=Beale                         \n",
      "correct=male     guess=female   name=Brandy                        \n",
      "correct=male     guess=female   name=Bubba                         \n",
      "correct=male     guess=female   name=Colin                         \n",
      "correct=male     guess=female   name=Denny                         \n",
      "correct=male     guess=female   name=Donnie                        \n",
      "correct=male     guess=female   name=Durante                       \n",
      "correct=male     guess=female   name=Ernie                         \n",
      "correct=male     guess=female   name=Felice                        \n",
      "correct=male     guess=female   name=Filmore                       \n",
      "correct=male     guess=female   name=Finn                          \n",
      "correct=male     guess=female   name=Gay                           \n",
      "correct=male     guess=female   name=Hillary                       \n",
      "correct=male     guess=female   name=Jere                          \n",
      "correct=male     guess=female   name=Jessey                        \n",
      "correct=male     guess=female   name=Jimmy                         \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Johnnie                       \n",
      "correct=male     guess=female   name=Joshua                        \n",
      "correct=male     guess=female   name=Jule                          \n",
      "correct=male     guess=female   name=Kelley                        \n",
      "correct=male     guess=female   name=Leslie                        \n",
      "correct=male     guess=female   name=Levi                          \n",
      "correct=male     guess=female   name=Lionel                        \n",
      "correct=male     guess=female   name=Micky                         \n",
      "correct=male     guess=female   name=Mike                          \n",
      "correct=male     guess=female   name=Mitchael                      \n",
      "correct=male     guess=female   name=Nevile                        \n",
      "correct=male     guess=female   name=Neville                       \n",
      "correct=male     guess=female   name=Nickey                        \n",
      "correct=male     guess=female   name=Nigel                         \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Oral                          \n",
      "correct=male     guess=female   name=Pate                          \n",
      "correct=male     guess=female   name=Rickie                        \n",
      "correct=male     guess=female   name=Samuele                       \n",
      "correct=male     guess=female   name=Shea                          \n",
      "correct=male     guess=female   name=Sibyl                         \n",
      "correct=male     guess=female   name=Skye                          \n",
      "correct=male     guess=female   name=Smitty                        \n",
      "correct=male     guess=female   name=Tallie                        \n",
      "correct=male     guess=female   name=Tanney                        \n",
      "correct=male     guess=female   name=Vite                          \n",
      "correct=male     guess=female   name=Voltaire                      \n",
      "correct=male     guess=female   name=Willie                        \n"
     ]
    }
   ],
   "source": [
    "# Error Analysis for first combination of features from gender_features_2:\n",
    "error_analysis(gender_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test set for gender_features1: 81.4 %\n"
     ]
    }
   ],
   "source": [
    "# Final performance of the test set for gender_features_2:\n",
    "test_set = [(gender_features2(n), g) for (n,g) in test]\n",
    "print(\"Accuracy of Test set for gender_features1:\", round((nltk.classify.accuracy(classifier, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using incremental approach I am trying to add more features now:\n",
    "# Let me call it gender_features_3 -- I have added for features for prefixes:\n",
    "def gender_features3(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"suffix3\"] = name[-3:].lower()\n",
    "    features[\"prefix3\"] = name[:3].lower()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Devtest for gender_features3: 81.4 %\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier for training and dev test for gender_features_3:\n",
    "train_set = [(gender_features3(n), g) for (n,g) in training]\n",
    "devtest_set = [(gender_features3(n), g) for (n,g) in devtest]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy of Devtest for gender_features3:\", round((nltk.classify.accuracy(classifier, devtest_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of errors:  93\n",
      "correct=female   guess=male     name=Bess                          \n",
      "correct=female   guess=male     name=Bev                           \n",
      "correct=female   guess=male     name=Constance                     \n",
      "correct=female   guess=male     name=Correy                        \n",
      "correct=female   guess=male     name=Darb                          \n",
      "correct=female   guess=male     name=Darell                        \n",
      "correct=female   guess=male     name=Devan                         \n",
      "correct=female   guess=male     name=Devin                         \n",
      "correct=female   guess=male     name=Eran                          \n",
      "correct=female   guess=male     name=Florry                        \n",
      "correct=female   guess=male     name=Fran                          \n",
      "correct=female   guess=male     name=Gerry                         \n",
      "correct=female   guess=male     name=Glad                          \n",
      "correct=female   guess=male     name=Gretchen                      \n",
      "correct=female   guess=male     name=Gunvor                        \n",
      "correct=female   guess=male     name=Gus                           \n",
      "correct=female   guess=male     name=Hesther                       \n",
      "correct=female   guess=male     name=Inez                          \n",
      "correct=female   guess=male     name=Jewell                        \n",
      "correct=female   guess=male     name=Joey                          \n",
      "correct=female   guess=male     name=Kirstin                       \n",
      "correct=female   guess=male     name=Konstance                     \n",
      "correct=female   guess=male     name=Kristan                       \n",
      "correct=female   guess=male     name=Mariam                        \n",
      "correct=female   guess=male     name=Milicent                      \n",
      "correct=female   guess=male     name=Modesty                       \n",
      "correct=female   guess=male     name=Monique                       \n",
      "correct=female   guess=male     name=Murial                        \n",
      "correct=female   guess=male     name=Olly                          \n",
      "correct=female   guess=male     name=Pearl                         \n",
      "correct=female   guess=male     name=Pet                           \n",
      "correct=female   guess=male     name=Reiko                         \n",
      "correct=female   guess=male     name=Rubie                         \n",
      "correct=female   guess=male     name=Sharl                         \n",
      "correct=female   guess=male     name=Sharon                        \n",
      "correct=female   guess=male     name=Sheelagh                      \n",
      "correct=female   guess=male     name=Sunny                         \n",
      "correct=female   guess=male     name=Suzan                         \n",
      "correct=female   guess=male     name=Tamar                         \n",
      "correct=female   guess=male     name=Tobye                         \n",
      "correct=female   guess=male     name=Wandis                        \n",
      "correct=female   guess=male     name=Wendy                         \n",
      "correct=female   guess=male     name=Wilie                         \n",
      "correct=female   guess=male     name=Wini                          \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=male     guess=female   name=Aditya                        \n",
      "correct=male     guess=female   name=Alexis                        \n",
      "correct=male     guess=female   name=Allyn                         \n",
      "correct=male     guess=female   name=Anatole                       \n",
      "correct=male     guess=female   name=Antone                        \n",
      "correct=male     guess=female   name=Bailie                        \n",
      "correct=male     guess=female   name=Beale                         \n",
      "correct=male     guess=female   name=Brandy                        \n",
      "correct=male     guess=female   name=Bubba                         \n",
      "correct=male     guess=female   name=Clay                          \n",
      "correct=male     guess=female   name=Colin                         \n",
      "correct=male     guess=female   name=Denny                         \n",
      "correct=male     guess=female   name=Donal                         \n",
      "correct=male     guess=female   name=Donnie                        \n",
      "correct=male     guess=female   name=Dorian                        \n",
      "correct=male     guess=female   name=Emanuel                       \n",
      "correct=male     guess=female   name=Ernie                         \n",
      "correct=male     guess=female   name=Esteban                       \n",
      "correct=male     guess=female   name=Felice                        \n",
      "correct=male     guess=female   name=Gay                           \n",
      "correct=male     guess=female   name=Hillary                       \n",
      "correct=male     guess=female   name=Holly                         \n",
      "correct=male     guess=female   name=Jere                          \n",
      "correct=male     guess=female   name=Jessey                        \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Johnnie                       \n",
      "correct=male     guess=female   name=Jose                          \n",
      "correct=male     guess=female   name=Joshua                        \n",
      "correct=male     guess=female   name=Jule                          \n",
      "correct=male     guess=female   name=Kelley                        \n",
      "correct=male     guess=female   name=Leslie                        \n",
      "correct=male     guess=female   name=Levi                          \n",
      "correct=male     guess=female   name=Lionel                        \n",
      "correct=male     guess=female   name=Mitchael                      \n",
      "correct=male     guess=female   name=Nevile                        \n",
      "correct=male     guess=female   name=Neville                       \n",
      "correct=male     guess=female   name=Nickey                        \n",
      "correct=male     guess=female   name=Nigel                         \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Oral                          \n",
      "correct=male     guess=female   name=Pate                          \n",
      "correct=male     guess=female   name=Samuele                       \n",
      "correct=male     guess=female   name=Shea                          \n",
      "correct=male     guess=female   name=Sibyl                         \n",
      "correct=male     guess=female   name=Tallie                        \n",
      "correct=male     guess=female   name=Tanney                        \n",
      "correct=male     guess=female   name=Vite                          \n",
      "correct=male     guess=female   name=Voltaire                      \n"
     ]
    }
   ],
   "source": [
    "# Error Analysis for first combination of features from gender_features_3:\n",
    "error_analysis(gender_features3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test set for gender_features3: 82.6 %\n"
     ]
    }
   ],
   "source": [
    "# Final performance of the test set for gender_features_3:\n",
    "test_set = [(gender_features3(n), g) for (n,g) in test]\n",
    "print(\"Accuracy of Test set for gender_features3:\", round((nltk.classify.accuracy(classifier, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using incremental approach I am trying to add more features now:\n",
    "# Let me call it gender_features_4 -- I have added for features for first 2 letters and vowels:\n",
    "def gender_features4(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"first_two_letters\"] = name[:2].lower()\n",
    "    features[\"last_two_letters\"] = name[-2:].lower()\n",
    "    features[\"double_letters\"] = (sum([1 for ch in range(len(name) - 1) if name[ch] == name[ch + 1]]))\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"suffix3\"] = name[-3:].lower()\n",
    "    features[\"prefix3\"] = name[:3].lower()\n",
    "    features[\"first_letter_vowel\"] = [i for i in range(len(name)) if name[i] in 'AEIOUaeiouy'][0]\n",
    "    features[\"num_vowels\"] = len([letter for letter in name if letter in 'AEIOUaeiouy'])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Devtest for gender_features4: 82.6 %\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier for training and dev test for gender_features_4:\n",
    "train_set = [(gender_features4(n), g) for (n,g) in training]\n",
    "devtest_set = [(gender_features4(n), g) for (n,g) in devtest]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy of Devtest for gender_features4:\", round((nltk.classify.accuracy(classifier, devtest_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of errors:  87\n",
      "correct=female   guess=male     name=Bamby                         \n",
      "correct=female   guess=male     name=Bess                          \n",
      "correct=female   guess=male     name=Bev                           \n",
      "correct=female   guess=male     name=Constance                     \n",
      "correct=female   guess=male     name=Correy                        \n",
      "correct=female   guess=male     name=Darb                          \n",
      "correct=female   guess=male     name=Darell                        \n",
      "correct=female   guess=male     name=Del                           \n",
      "correct=female   guess=male     name=Devan                         \n",
      "correct=female   guess=male     name=Devin                         \n",
      "correct=female   guess=male     name=Eran                          \n",
      "correct=female   guess=male     name=Florry                        \n",
      "correct=female   guess=male     name=Fran                          \n",
      "correct=female   guess=male     name=Gerry                         \n",
      "correct=female   guess=male     name=Glad                          \n",
      "correct=female   guess=male     name=Gretchen                      \n",
      "correct=female   guess=male     name=Gunvor                        \n",
      "correct=female   guess=male     name=Gus                           \n",
      "correct=female   guess=male     name=Hesther                       \n",
      "correct=female   guess=male     name=Hildy                         \n",
      "correct=female   guess=male     name=Inez                          \n",
      "correct=female   guess=male     name=Jewell                        \n",
      "correct=female   guess=male     name=Joey                          \n",
      "correct=female   guess=male     name=Kirstin                       \n",
      "correct=female   guess=male     name=Konstance                     \n",
      "correct=female   guess=male     name=Kristan                       \n",
      "correct=female   guess=male     name=Mariam                        \n",
      "correct=female   guess=male     name=Milicent                      \n",
      "correct=female   guess=male     name=Modesty                       \n",
      "correct=female   guess=male     name=Monique                       \n",
      "correct=female   guess=male     name=Murial                        \n",
      "correct=female   guess=male     name=Olly                          \n",
      "correct=female   guess=male     name=Pearl                         \n",
      "correct=female   guess=male     name=Pet                           \n",
      "correct=female   guess=male     name=Reiko                         \n",
      "correct=female   guess=male     name=Rubie                         \n",
      "correct=female   guess=male     name=Sharl                         \n",
      "correct=female   guess=male     name=Sharon                        \n",
      "correct=female   guess=male     name=Sheelagh                      \n",
      "correct=female   guess=male     name=Sunny                         \n",
      "correct=female   guess=male     name=Suzan                         \n",
      "correct=female   guess=male     name=Tamar                         \n",
      "correct=female   guess=male     name=Wandis                        \n",
      "correct=female   guess=male     name=Wendy                         \n",
      "correct=female   guess=male     name=Wilie                         \n",
      "correct=female   guess=male     name=Wini                          \n",
      "correct=female   guess=male     name=Yoko                          \n",
      "correct=male     guess=female   name=Aditya                        \n",
      "correct=male     guess=female   name=Alexis                        \n",
      "correct=male     guess=female   name=Allyn                         \n",
      "correct=male     guess=female   name=Anatole                       \n",
      "correct=male     guess=female   name=Antone                        \n",
      "correct=male     guess=female   name=Bailie                        \n",
      "correct=male     guess=female   name=Beale                         \n",
      "correct=male     guess=female   name=Bubba                         \n",
      "correct=male     guess=female   name=Denny                         \n",
      "correct=male     guess=female   name=Donal                         \n",
      "correct=male     guess=female   name=Donnie                        \n",
      "correct=male     guess=female   name=Dorian                        \n",
      "correct=male     guess=female   name=Emanuel                       \n",
      "correct=male     guess=female   name=Ernie                         \n",
      "correct=male     guess=female   name=Esteban                       \n",
      "correct=male     guess=female   name=Felice                        \n",
      "correct=male     guess=female   name=Jessey                        \n",
      "correct=male     guess=female   name=Jodi                          \n",
      "correct=male     guess=female   name=Johnnie                       \n",
      "correct=male     guess=female   name=Jose                          \n",
      "correct=male     guess=female   name=Joshua                        \n",
      "correct=male     guess=female   name=Jule                          \n",
      "correct=male     guess=female   name=Kelley                        \n",
      "correct=male     guess=female   name=Leslie                        \n",
      "correct=male     guess=female   name=Levi                          \n",
      "correct=male     guess=female   name=Lionel                        \n",
      "correct=male     guess=female   name=Mitchael                      \n",
      "correct=male     guess=female   name=Nevile                        \n",
      "correct=male     guess=female   name=Neville                       \n",
      "correct=male     guess=female   name=Nickey                        \n",
      "correct=male     guess=female   name=Odie                          \n",
      "correct=male     guess=female   name=Oral                          \n",
      "correct=male     guess=female   name=Pate                          \n",
      "correct=male     guess=female   name=Samuele                       \n",
      "correct=male     guess=female   name=Shea                          \n",
      "correct=male     guess=female   name=Sibyl                         \n",
      "correct=male     guess=female   name=Tallie                        \n",
      "correct=male     guess=female   name=Tanney                        \n",
      "correct=male     guess=female   name=Vite                          \n",
      "correct=male     guess=female   name=Voltaire                      \n"
     ]
    }
   ],
   "source": [
    "# Error Analysis for first combination of features from gender_features_4:\n",
    "error_analysis(gender_features4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test set for gender_features4: 83.2 %\n"
     ]
    }
   ],
   "source": [
    "# Final performance of the test set for gender_features_4:\n",
    "test_set = [(gender_features4(n), g) for (n,g) in test]\n",
    "print(\"Accuracy of Test set for gender_features4:\", round((nltk.classify.accuracy(classifier, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 4 iterations of different feature extraction and acuuracy testing I come to the conclusion that:\n",
    "\n",
    "The accuracy of the classifier is slightly better when evaluating the test set (83.2%) than when evaluating the devtest set (82.6%). I have built the models incremently and as we see with every new addition the accuracy has increased for the dev test. After 4 such different additions, I check the errors and it seems some are really ambiguous and even a human mind will be confused. The difference can be attributed to inability to find definitve features for cases which can be evaluated to find the gender. We can go on to think for more possible features to tune it further but this is a good overall result and we know now how to build necessary features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using the movie review document classifier discussed in Chapter 6- Section 1.3 ( constructing a list of the 2500 most frequent words as features and use the first 150 documents as the test dataset) , generate a list of the 10 features that the classifier finds to be most informative. Can you explain why these particular features are informative? Do you find any of them surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "            for category in movie_reviews.categories()\n",
    "            for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020)\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words)[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot',\n",
       " ':',\n",
       " 'two',\n",
       " 'teen',\n",
       " 'couples',\n",
       " 'go',\n",
       " 'to',\n",
       " 'a',\n",
       " 'church',\n",
       " 'party',\n",
       " ',',\n",
       " 'drink',\n",
       " 'and',\n",
       " 'then',\n",
       " 'drive',\n",
       " '.',\n",
       " 'they',\n",
       " 'get',\n",
       " 'into',\n",
       " 'an',\n",
       " 'accident',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'guys',\n",
       " 'dies',\n",
       " 'but',\n",
       " 'his',\n",
       " 'girlfriend',\n",
       " 'continues',\n",
       " 'see',\n",
       " 'him',\n",
       " 'in',\n",
       " 'her',\n",
       " 'life',\n",
       " 'has',\n",
       " 'nightmares',\n",
       " 'what',\n",
       " \"'\",\n",
       " 's',\n",
       " 'deal',\n",
       " '?',\n",
       " 'watch',\n",
       " 'movie',\n",
       " '\"',\n",
       " 'sorta',\n",
       " 'find',\n",
       " 'out',\n",
       " 'critique',\n",
       " 'mind',\n",
       " '-',\n",
       " 'fuck',\n",
       " 'for',\n",
       " 'generation',\n",
       " 'that',\n",
       " 'touches',\n",
       " 'on',\n",
       " 'very',\n",
       " 'cool',\n",
       " 'idea',\n",
       " 'presents',\n",
       " 'it',\n",
       " 'bad',\n",
       " 'package',\n",
       " 'which',\n",
       " 'is',\n",
       " 'makes',\n",
       " 'this',\n",
       " 'review',\n",
       " 'even',\n",
       " 'harder',\n",
       " 'write',\n",
       " 'since',\n",
       " 'i',\n",
       " 'generally',\n",
       " 'applaud',\n",
       " 'films',\n",
       " 'attempt',\n",
       " 'break',\n",
       " 'mold',\n",
       " 'mess',\n",
       " 'with',\n",
       " 'your',\n",
       " 'head',\n",
       " 'such',\n",
       " '(',\n",
       " 'lost',\n",
       " 'highway',\n",
       " '&',\n",
       " 'memento',\n",
       " ')',\n",
       " 'there',\n",
       " 'are',\n",
       " 'good',\n",
       " 'ways',\n",
       " 'making',\n",
       " 'all',\n",
       " 'types',\n",
       " 'these',\n",
       " 'folks',\n",
       " 'just',\n",
       " 'didn',\n",
       " 't',\n",
       " 'snag',\n",
       " 'correctly',\n",
       " 'seem',\n",
       " 'have',\n",
       " 'taken',\n",
       " 'pretty',\n",
       " 'neat',\n",
       " 'concept',\n",
       " 'executed',\n",
       " 'terribly',\n",
       " 'so',\n",
       " 'problems',\n",
       " 'well',\n",
       " 'its',\n",
       " 'main',\n",
       " 'problem',\n",
       " 'simply',\n",
       " 'too',\n",
       " 'jumbled',\n",
       " 'starts',\n",
       " 'off',\n",
       " 'normal',\n",
       " 'downshifts',\n",
       " 'fantasy',\n",
       " 'world',\n",
       " 'you',\n",
       " 'as',\n",
       " 'audience',\n",
       " 'member',\n",
       " 'no',\n",
       " 'going',\n",
       " 'dreams',\n",
       " 'characters',\n",
       " 'coming',\n",
       " 'back',\n",
       " 'from',\n",
       " 'dead',\n",
       " 'others',\n",
       " 'who',\n",
       " 'look',\n",
       " 'like',\n",
       " 'strange',\n",
       " 'apparitions',\n",
       " 'disappearances',\n",
       " 'looooot',\n",
       " 'chase',\n",
       " 'scenes',\n",
       " 'tons',\n",
       " 'weird',\n",
       " 'things',\n",
       " 'happen',\n",
       " 'most',\n",
       " 'not',\n",
       " 'explained',\n",
       " 'now',\n",
       " 'personally',\n",
       " 'don',\n",
       " 'trying',\n",
       " 'unravel',\n",
       " 'film',\n",
       " 'every',\n",
       " 'when',\n",
       " 'does',\n",
       " 'give',\n",
       " 'me',\n",
       " 'same',\n",
       " 'clue',\n",
       " 'over',\n",
       " 'again',\n",
       " 'kind',\n",
       " 'fed',\n",
       " 'up',\n",
       " 'after',\n",
       " 'while',\n",
       " 'biggest',\n",
       " 'obviously',\n",
       " 'got',\n",
       " 'big',\n",
       " 'secret',\n",
       " 'hide',\n",
       " 'seems',\n",
       " 'want',\n",
       " 'completely',\n",
       " 'until',\n",
       " 'final',\n",
       " 'five',\n",
       " 'minutes',\n",
       " 'do',\n",
       " 'make',\n",
       " 'entertaining',\n",
       " 'thrilling',\n",
       " 'or',\n",
       " 'engaging',\n",
       " 'meantime',\n",
       " 'really',\n",
       " 'sad',\n",
       " 'part',\n",
       " 'arrow',\n",
       " 'both',\n",
       " 'dig',\n",
       " 'flicks',\n",
       " 'we',\n",
       " 'actually',\n",
       " 'figured',\n",
       " 'by',\n",
       " 'half',\n",
       " 'way',\n",
       " 'point',\n",
       " 'strangeness',\n",
       " 'did',\n",
       " 'start',\n",
       " 'little',\n",
       " 'bit',\n",
       " 'sense',\n",
       " 'still',\n",
       " 'more',\n",
       " 'guess',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movies',\n",
       " 'should',\n",
       " 'always',\n",
       " 'sure',\n",
       " 'before',\n",
       " 'given',\n",
       " 'password',\n",
       " 'enter',\n",
       " 'understanding',\n",
       " 'mean',\n",
       " 'showing',\n",
       " 'melissa',\n",
       " 'sagemiller',\n",
       " 'running',\n",
       " 'away',\n",
       " 'visions',\n",
       " 'about',\n",
       " '20',\n",
       " 'throughout',\n",
       " 'plain',\n",
       " 'lazy',\n",
       " '!',\n",
       " 'okay',\n",
       " 'people',\n",
       " 'chasing',\n",
       " 'know',\n",
       " 'need',\n",
       " 'how',\n",
       " 'giving',\n",
       " 'us',\n",
       " 'different',\n",
       " 'offering',\n",
       " 'further',\n",
       " 'insight',\n",
       " 'down',\n",
       " 'apparently',\n",
       " 'studio',\n",
       " 'took',\n",
       " 'director',\n",
       " 'chopped',\n",
       " 'themselves',\n",
       " 'shows',\n",
       " 'might',\n",
       " 've',\n",
       " 'been',\n",
       " 'decent',\n",
       " 'here',\n",
       " 'somewhere',\n",
       " 'suits',\n",
       " 'decided',\n",
       " 'turning',\n",
       " 'music',\n",
       " 'video',\n",
       " 'edge',\n",
       " 'would',\n",
       " 'actors',\n",
       " 'although',\n",
       " 'wes',\n",
       " 'bentley',\n",
       " 'seemed',\n",
       " 'be',\n",
       " 'playing',\n",
       " 'exact',\n",
       " 'character',\n",
       " 'he',\n",
       " 'american',\n",
       " 'beauty',\n",
       " 'only',\n",
       " 'new',\n",
       " 'neighborhood',\n",
       " 'my',\n",
       " 'kudos',\n",
       " 'holds',\n",
       " 'own',\n",
       " 'entire',\n",
       " 'feeling',\n",
       " 'unraveling',\n",
       " 'overall',\n",
       " 'doesn',\n",
       " 'stick',\n",
       " 'because',\n",
       " 'entertain',\n",
       " 'confusing',\n",
       " 'rarely',\n",
       " 'excites',\n",
       " 'feels',\n",
       " 'redundant',\n",
       " 'runtime',\n",
       " 'despite',\n",
       " 'ending',\n",
       " 'explanation',\n",
       " 'craziness',\n",
       " 'came',\n",
       " 'oh',\n",
       " 'horror',\n",
       " 'slasher',\n",
       " 'flick',\n",
       " 'packaged',\n",
       " 'someone',\n",
       " 'assuming',\n",
       " 'genre',\n",
       " 'hot',\n",
       " 'kids',\n",
       " 'also',\n",
       " 'wrapped',\n",
       " 'production',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'sitting',\n",
       " 'shelves',\n",
       " 'ever',\n",
       " 'whatever',\n",
       " 'skip',\n",
       " 'where',\n",
       " 'joblo',\n",
       " 'nightmare',\n",
       " 'elm',\n",
       " 'street',\n",
       " '3',\n",
       " '7',\n",
       " '/',\n",
       " '10',\n",
       " 'blair',\n",
       " 'witch',\n",
       " '2',\n",
       " 'crow',\n",
       " '9',\n",
       " 'salvation',\n",
       " '4',\n",
       " 'stir',\n",
       " 'echoes',\n",
       " '8',\n",
       " 'happy',\n",
       " 'bastard',\n",
       " 'quick',\n",
       " 'damn',\n",
       " 'y2k',\n",
       " 'bug',\n",
       " 'starring',\n",
       " 'jamie',\n",
       " 'lee',\n",
       " 'curtis',\n",
       " 'another',\n",
       " 'baldwin',\n",
       " 'brother',\n",
       " 'william',\n",
       " 'time',\n",
       " 'story',\n",
       " 'regarding',\n",
       " 'crew',\n",
       " 'tugboat',\n",
       " 'comes',\n",
       " 'across',\n",
       " 'deserted',\n",
       " 'russian',\n",
       " 'tech',\n",
       " 'ship',\n",
       " 'kick',\n",
       " 'power',\n",
       " 'within',\n",
       " 'gore',\n",
       " 'bringing',\n",
       " 'few',\n",
       " 'action',\n",
       " 'sequences',\n",
       " 'virus',\n",
       " 'empty',\n",
       " 'flash',\n",
       " 'substance',\n",
       " 'why',\n",
       " 'was',\n",
       " 'middle',\n",
       " 'nowhere',\n",
       " 'origin',\n",
       " 'pink',\n",
       " 'flashy',\n",
       " 'thing',\n",
       " 'hit',\n",
       " 'mir',\n",
       " 'course',\n",
       " 'donald',\n",
       " 'sutherland',\n",
       " 'stumbling',\n",
       " 'around',\n",
       " 'drunkenly',\n",
       " 'hey',\n",
       " 'let',\n",
       " 'some',\n",
       " 'robots',\n",
       " 'acting',\n",
       " 'below',\n",
       " 'average',\n",
       " 'likes',\n",
       " 're',\n",
       " 'likely',\n",
       " 'work',\n",
       " 'halloween',\n",
       " 'h20',\n",
       " 'wasted',\n",
       " 'real',\n",
       " 'star',\n",
       " 'stan',\n",
       " 'winston',\n",
       " 'robot',\n",
       " 'design',\n",
       " 'schnazzy',\n",
       " 'cgi',\n",
       " 'occasional',\n",
       " 'shot',\n",
       " 'picking',\n",
       " 'brain',\n",
       " 'if',\n",
       " 'body',\n",
       " 'parts',\n",
       " 'turn',\n",
       " 'otherwise',\n",
       " 'much',\n",
       " 'sunken',\n",
       " 'jaded',\n",
       " 'viewer',\n",
       " 'thankful',\n",
       " 'invention',\n",
       " 'timex',\n",
       " 'indiglo',\n",
       " 'based',\n",
       " 'late',\n",
       " '1960',\n",
       " 'television',\n",
       " 'show',\n",
       " 'name',\n",
       " 'mod',\n",
       " 'squad',\n",
       " 'tells',\n",
       " 'tale',\n",
       " 'three',\n",
       " 'reformed',\n",
       " 'criminals',\n",
       " 'under',\n",
       " 'employ',\n",
       " 'police',\n",
       " 'undercover',\n",
       " 'however',\n",
       " 'wrong',\n",
       " 'evidence',\n",
       " 'gets',\n",
       " 'stolen',\n",
       " 'immediately',\n",
       " 'suspicion',\n",
       " 'ads',\n",
       " 'cuts',\n",
       " 'claire',\n",
       " 'dane',\n",
       " 'nice',\n",
       " 'hair',\n",
       " 'cute',\n",
       " 'outfits',\n",
       " 'car',\n",
       " 'chases',\n",
       " 'stuff',\n",
       " 'blowing',\n",
       " 'sounds',\n",
       " 'first',\n",
       " 'fifteen',\n",
       " 'quickly',\n",
       " 'becomes',\n",
       " 'apparent',\n",
       " 'certainly',\n",
       " 'slick',\n",
       " 'looking',\n",
       " 'complete',\n",
       " 'costumes',\n",
       " 'isn',\n",
       " 'enough',\n",
       " 'best',\n",
       " 'described',\n",
       " 'cross',\n",
       " 'between',\n",
       " 'hour',\n",
       " 'long',\n",
       " 'cop',\n",
       " 'stretched',\n",
       " 'span',\n",
       " 'single',\n",
       " 'clich',\n",
       " 'matter',\n",
       " 'elements',\n",
       " 'recycled',\n",
       " 'everything',\n",
       " 'already',\n",
       " 'seen',\n",
       " 'nothing',\n",
       " 'spectacular',\n",
       " 'sometimes',\n",
       " 'bordering',\n",
       " 'wooden',\n",
       " 'danes',\n",
       " 'omar',\n",
       " 'epps',\n",
       " 'deliver',\n",
       " 'their',\n",
       " 'lines',\n",
       " 'bored',\n",
       " 'transfers',\n",
       " 'onto',\n",
       " 'escape',\n",
       " 'relatively',\n",
       " 'unscathed',\n",
       " 'giovanni',\n",
       " 'ribisi',\n",
       " 'plays',\n",
       " 'resident',\n",
       " 'crazy',\n",
       " 'man',\n",
       " 'ultimately',\n",
       " 'being',\n",
       " 'worth',\n",
       " 'watching',\n",
       " 'unfortunately',\n",
       " 'save',\n",
       " 'convoluted',\n",
       " 'apart',\n",
       " 'occupying',\n",
       " 'screen',\n",
       " 'young',\n",
       " 'cast',\n",
       " 'clothes',\n",
       " 'hip',\n",
       " 'soundtrack',\n",
       " 'appears',\n",
       " 'geared',\n",
       " 'towards',\n",
       " 'teenage',\n",
       " 'mindset',\n",
       " 'r',\n",
       " 'rating',\n",
       " 'content',\n",
       " 'justify',\n",
       " 'juvenile',\n",
       " 'older',\n",
       " 'information',\n",
       " 'literally',\n",
       " 'spoon',\n",
       " 'hard',\n",
       " 'instead',\n",
       " 'telling',\n",
       " 'dialogue',\n",
       " 'poorly',\n",
       " 'written',\n",
       " 'extremely',\n",
       " 'predictable',\n",
       " 'progresses',\n",
       " 'won',\n",
       " 'care',\n",
       " 'heroes',\n",
       " 'any',\n",
       " 'jeopardy',\n",
       " 'll',\n",
       " 'aren',\n",
       " 'basing',\n",
       " 'nobody',\n",
       " 'remembers',\n",
       " 'questionable',\n",
       " 'wisdom',\n",
       " 'especially',\n",
       " 'considers',\n",
       " 'target',\n",
       " 'fact',\n",
       " 'number',\n",
       " 'memorable',\n",
       " 'can',\n",
       " 'counted',\n",
       " 'hand',\n",
       " 'missing',\n",
       " 'finger',\n",
       " 'times',\n",
       " 'checked',\n",
       " 'six',\n",
       " 'clear',\n",
       " 'indication',\n",
       " 'them',\n",
       " 'than',\n",
       " 'cash',\n",
       " 'spending',\n",
       " 'dollar',\n",
       " 'judging',\n",
       " 'rash',\n",
       " 'awful',\n",
       " 'seeing',\n",
       " 'avoid',\n",
       " 'at',\n",
       " 'costs',\n",
       " 'quest',\n",
       " 'camelot',\n",
       " 'warner',\n",
       " 'bros',\n",
       " 'feature',\n",
       " 'length',\n",
       " 'fully',\n",
       " 'animated',\n",
       " 'steal',\n",
       " 'clout',\n",
       " 'disney',\n",
       " 'cartoon',\n",
       " 'empire',\n",
       " 'mouse',\n",
       " 'reason',\n",
       " 'worried',\n",
       " 'other',\n",
       " 'recent',\n",
       " 'challenger',\n",
       " 'throne',\n",
       " 'last',\n",
       " 'fall',\n",
       " 'promising',\n",
       " 'flawed',\n",
       " '20th',\n",
       " 'century',\n",
       " 'fox',\n",
       " 'anastasia',\n",
       " 'hercules',\n",
       " 'lively',\n",
       " 'colorful',\n",
       " 'palate',\n",
       " 'had',\n",
       " 'beat',\n",
       " 'hands',\n",
       " 'crown',\n",
       " '1997',\n",
       " 'piece',\n",
       " 'animation',\n",
       " 'year',\n",
       " 'contest',\n",
       " 'arrival',\n",
       " 'magic',\n",
       " 'kingdom',\n",
       " 'mediocre',\n",
       " '--',\n",
       " 'd',\n",
       " 'pocahontas',\n",
       " 'those',\n",
       " 'keeping',\n",
       " 'score',\n",
       " 'nearly',\n",
       " 'dull',\n",
       " 'revolves',\n",
       " 'adventures',\n",
       " 'free',\n",
       " 'spirited',\n",
       " 'kayley',\n",
       " 'voiced',\n",
       " 'jessalyn',\n",
       " 'gilsig',\n",
       " 'early',\n",
       " 'daughter',\n",
       " 'belated',\n",
       " 'knight',\n",
       " 'king',\n",
       " 'arthur',\n",
       " 'round',\n",
       " 'table',\n",
       " 'dream',\n",
       " 'follow',\n",
       " 'father',\n",
       " 'footsteps',\n",
       " 'she',\n",
       " 'chance',\n",
       " 'evil',\n",
       " 'warlord',\n",
       " 'ruber',\n",
       " 'gary',\n",
       " 'oldman',\n",
       " 'ex',\n",
       " 'gone',\n",
       " 'steals',\n",
       " 'magical',\n",
       " 'sword',\n",
       " 'excalibur',\n",
       " 'accidentally',\n",
       " 'loses',\n",
       " 'dangerous',\n",
       " 'booby',\n",
       " 'trapped',\n",
       " 'forest',\n",
       " 'help',\n",
       " 'hunky',\n",
       " 'blind',\n",
       " 'timberland',\n",
       " 'dweller',\n",
       " 'garrett',\n",
       " 'carey',\n",
       " 'elwes',\n",
       " 'headed',\n",
       " 'dragon',\n",
       " 'eric',\n",
       " 'idle',\n",
       " 'rickles',\n",
       " 'arguing',\n",
       " 'itself',\n",
       " 'able',\n",
       " 'medieval',\n",
       " 'sexist',\n",
       " 'prove',\n",
       " 'fighter',\n",
       " 'side',\n",
       " 'pure',\n",
       " 'showmanship',\n",
       " 'essential',\n",
       " 'element',\n",
       " 'expected',\n",
       " 'climb',\n",
       " 'high',\n",
       " 'ranks',\n",
       " 'differentiates',\n",
       " 'something',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'subpar',\n",
       " 'instantly',\n",
       " 'forgettable',\n",
       " 'songs',\n",
       " 'integrated',\n",
       " 'computerized',\n",
       " 'footage',\n",
       " 'compare',\n",
       " 'run',\n",
       " 'angry',\n",
       " 'ogre',\n",
       " 'herc',\n",
       " 'battle',\n",
       " 'hydra',\n",
       " 'rest',\n",
       " 'case',\n",
       " 'stink',\n",
       " 'none',\n",
       " 'remotely',\n",
       " 'interesting',\n",
       " 'race',\n",
       " 'bland',\n",
       " 'end',\n",
       " 'tie',\n",
       " 'win',\n",
       " 'comedy',\n",
       " 'shtick',\n",
       " 'awfully',\n",
       " 'cloying',\n",
       " 'least',\n",
       " 'signs',\n",
       " 'pulse',\n",
       " 'fans',\n",
       " \"-'\",\n",
       " '90s',\n",
       " 'tgif',\n",
       " 'will',\n",
       " 'thrilled',\n",
       " 'jaleel',\n",
       " 'urkel',\n",
       " 'white',\n",
       " 'bronson',\n",
       " 'balki',\n",
       " 'pinchot',\n",
       " 'sharing',\n",
       " 'nicely',\n",
       " 'realized',\n",
       " 'though',\n",
       " 'm',\n",
       " 'loss',\n",
       " 'recall',\n",
       " 'specific',\n",
       " 'providing',\n",
       " 'voice',\n",
       " 'talent',\n",
       " 'enthusiastic',\n",
       " 'paired',\n",
       " 'singers',\n",
       " 'sound',\n",
       " 'musical',\n",
       " 'moments',\n",
       " 'jane',\n",
       " 'seymour',\n",
       " 'celine',\n",
       " 'dion',\n",
       " 'must',\n",
       " 'strain',\n",
       " 'through',\n",
       " 'aside',\n",
       " 'children',\n",
       " 'probably',\n",
       " 'adults',\n",
       " 'grievous',\n",
       " 'error',\n",
       " 'lack',\n",
       " 'personality',\n",
       " 'learn',\n",
       " 'goes',\n",
       " 'synopsis',\n",
       " 'mentally',\n",
       " 'unstable',\n",
       " 'undergoing',\n",
       " 'psychotherapy',\n",
       " 'saves',\n",
       " 'boy',\n",
       " 'potentially',\n",
       " 'fatal',\n",
       " 'falls',\n",
       " 'love',\n",
       " 'mother',\n",
       " 'fledgling',\n",
       " 'restauranteur',\n",
       " 'unsuccessfully',\n",
       " 'attempting',\n",
       " 'gain',\n",
       " 'woman',\n",
       " 'favor',\n",
       " 'takes',\n",
       " 'pictures',\n",
       " 'kills',\n",
       " 'comments',\n",
       " 'stalked',\n",
       " 'yet',\n",
       " 'seemingly',\n",
       " 'endless',\n",
       " 'string',\n",
       " 'spurned',\n",
       " 'psychos',\n",
       " 'getting',\n",
       " 'revenge',\n",
       " 'type',\n",
       " 'stable',\n",
       " 'category',\n",
       " '1990s',\n",
       " 'industry',\n",
       " 'theatrical',\n",
       " 'direct',\n",
       " 'proliferation',\n",
       " 'may',\n",
       " 'due',\n",
       " 'typically',\n",
       " 'inexpensive',\n",
       " 'produce',\n",
       " 'special',\n",
       " 'effects',\n",
       " 'stars',\n",
       " 'serve',\n",
       " 'vehicles',\n",
       " 'nudity',\n",
       " 'allowing',\n",
       " 'frequent',\n",
       " 'night',\n",
       " 'cable',\n",
       " 'wavers',\n",
       " 'slightly',\n",
       " 'norm',\n",
       " 'respect',\n",
       " 'psycho',\n",
       " 'never',\n",
       " 'affair',\n",
       " ';',\n",
       " 'contrary',\n",
       " 'rejected',\n",
       " 'rather',\n",
       " 'lover',\n",
       " 'wife',\n",
       " 'husband',\n",
       " 'entry',\n",
       " 'doomed',\n",
       " 'collect',\n",
       " 'dust',\n",
       " 'viewed',\n",
       " 'midnight',\n",
       " 'provide',\n",
       " 'suspense',\n",
       " 'sets',\n",
       " 'interspersed',\n",
       " 'opening',\n",
       " 'credits',\n",
       " 'instance',\n",
       " 'serious',\n",
       " 'sounding',\n",
       " 'narrator',\n",
       " 'spouts',\n",
       " 'statistics',\n",
       " 'stalkers',\n",
       " 'ponders',\n",
       " 'cause',\n",
       " 'stalk',\n",
       " 'implicitly',\n",
       " 'implied',\n",
       " 'men',\n",
       " 'shown',\n",
       " 'snapshot',\n",
       " 'actor',\n",
       " 'jay',\n",
       " 'underwood',\n",
       " 'states',\n",
       " 'daryl',\n",
       " 'gleason',\n",
       " 'stalker',\n",
       " 'brooke',\n",
       " 'daniels',\n",
       " 'meant',\n",
       " 'called',\n",
       " 'guesswork',\n",
       " 'required',\n",
       " 'proceeds',\n",
       " 'begins',\n",
       " 'obvious',\n",
       " 'sequence',\n",
       " 'contrived',\n",
       " 'quite',\n",
       " 'brings',\n",
       " 'victim',\n",
       " 'together',\n",
       " 'obsesses',\n",
       " 'follows',\n",
       " 'tries',\n",
       " 'woo',\n",
       " 'plans',\n",
       " 'become',\n",
       " 'desperate',\n",
       " 'elaborate',\n",
       " 'include',\n",
       " 'cliche',\n",
       " 'murdered',\n",
       " 'pet',\n",
       " 'require',\n",
       " 'found',\n",
       " 'exception',\n",
       " 'cat',\n",
       " 'shower',\n",
       " 'events',\n",
       " 'lead',\n",
       " 'inevitable',\n",
       " 'showdown',\n",
       " 'survives',\n",
       " 'invariably',\n",
       " 'conclusion',\n",
       " 'turkey',\n",
       " 'uniformly',\n",
       " 'adequate',\n",
       " 'anything',\n",
       " 'home',\n",
       " 'either',\n",
       " 'turns',\n",
       " 'toward',\n",
       " 'melodrama',\n",
       " 'overdoes',\n",
       " 'words',\n",
       " 'manages',\n",
       " 'creepy',\n",
       " 'pass',\n",
       " 'demands',\n",
       " 'maryam',\n",
       " 'abo',\n",
       " 'close',\n",
       " 'played',\n",
       " 'bond',\n",
       " 'chick',\n",
       " 'living',\n",
       " 'daylights',\n",
       " 'equally',\n",
       " 'title',\n",
       " 'ditzy',\n",
       " 'strong',\n",
       " 'independent',\n",
       " 'business',\n",
       " 'owner',\n",
       " 'needs',\n",
       " 'proceed',\n",
       " 'example',\n",
       " 'suspicions',\n",
       " 'ensure',\n",
       " 'use',\n",
       " 'excuse',\n",
       " 'decides',\n",
       " 'return',\n",
       " 'toolbox',\n",
       " 'left',\n",
       " 'place',\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d, c) in documents]\n",
    "train_set, test_set = featuresets[150:], featuresets[:150]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "     contains(atrocious) = True              neg : pos    =     11.0 : 1.0\n",
      "        contains(turkey) = True              neg : pos    =     10.6 : 1.0\n",
      "       contains(frances) = True              pos : neg    =      9.0 : 1.0\n",
      "        contains(annual) = True              pos : neg    =      9.0 : 1.0\n",
      "      contains(bothered) = True              neg : pos    =      8.3 : 1.0\n",
      " contains(unimaginative) = True              neg : pos    =      8.3 : 1.0\n",
      "        contains(stinks) = True              neg : pos    =      7.7 : 1.0\n",
      "    contains(schumacher) = True              neg : pos    =      7.0 : 1.0\n",
      "        contains(shoddy) = True              neg : pos    =      6.3 : 1.0\n",
      "          contains(mena) = True              neg : pos    =      6.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words such as shoddy, stinks, bothered have a negative connotation so it is not surprsing to see that having a negative tag to it but words like turkey, annual are not ambiguous and can't be clearly said whether those words were used with negative or positive connotation. We will need a more context based understanding to come to a conclusion. We have a good accuracy of 83.33% which is also a good indication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Select one of the classification tasks described in this chapter, such as name gender detection, document classification, part-of-speech tagging, or dialog act classification. Using the same training and test data, and the same feature extractor, build three classifiers for the task: a decision tree, a naive Bayes classifier, and a  Maximum Entropy classifier. Compare the performance of the three classifiers on your selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the gender classification case and use the features I built in question 1 above\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "\n",
    "names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for gender classification\n",
    "def gender_features(name):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = name[0].lower()\n",
    "    features[\"last_letter\"] = name[-1].lower()\n",
    "    features[\"first_two_letters\"] = name[:2].lower()\n",
    "    features[\"last_two_letters\"] = name[-2:].lower()\n",
    "    features[\"double_letters\"] = (sum([1 for ch in range(len(name) - 1) if name[ch] == name[ch + 1]]))\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
    "    features[\"suffix2\"] = name[-2:].lower()\n",
    "    features[\"suffix3\"] = name[-3:].lower()\n",
    "    features[\"prefix3\"] = name[:3].lower()\n",
    "    features[\"first_letter_vowel\"] = [i for i in range(len(name)) if name[i] in 'AEIOUaeiouy'][0]\n",
    "    features[\"num_vowels\"] = len([letter for letter in name if letter in 'AEIOUaeiouy'])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train set for Decision Tree: 92.86 %\n",
      "Accuracy of Test set for Decision Tree: 60.0 %\n"
     ]
    }
   ],
   "source": [
    "# 1. Evaluating decision tree:\n",
    "classifier_dt = nltk.DecisionTreeClassifier.train(train_set)\n",
    "print(\"Accuracy of Train set for Decision Tree:\", round((nltk.classify.accuracy(classifier_dt, train_set)*100),2),\"%\")\n",
    "print(\"Accuracy of Test set for Decision Tree:\", round((nltk.classify.accuracy(classifier_dt, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train set for Naive Bayes: 88.7 %\n",
      "Accuracy of Test set for Naive Bayes: 83.33 %\n"
     ]
    }
   ],
   "source": [
    "# 2. Evaluating naive bayes classifier\n",
    "classifier_nbc = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Accuracy of Train set for Naive Bayes:\", round((nltk.classify.accuracy(classifier_nbc, train_set)*100),2),\"%\")\n",
    "print(\"Accuracy of Test set for Naive Bayes:\", round((nltk.classify.accuracy(classifier_nbc, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.371\n",
      "             2          -0.58532        0.629\n",
      "             3          -0.54989        0.638\n",
      "             4          -0.51888        0.702\n",
      "             5          -0.49183        0.761\n",
      "             6          -0.46824        0.797\n",
      "             7          -0.44762        0.815\n",
      "             8          -0.42954        0.828\n",
      "             9          -0.41360        0.837\n",
      "            10          -0.39949        0.843\n",
      "            11          -0.38693        0.848\n",
      "            12          -0.37569        0.853\n",
      "            13          -0.36558        0.857\n",
      "            14          -0.35645        0.859\n",
      "            15          -0.34815        0.860\n",
      "            16          -0.34059        0.863\n",
      "            17          -0.33367        0.864\n",
      "            18          -0.32730        0.866\n",
      "            19          -0.32143        0.867\n",
      "            20          -0.31600        0.869\n",
      "            21          -0.31095        0.870\n",
      "            22          -0.30624        0.871\n",
      "            23          -0.30185        0.872\n",
      "            24          -0.29773        0.873\n",
      "            25          -0.29386        0.874\n",
      "            26          -0.29022        0.875\n",
      "            27          -0.28678        0.876\n",
      "            28          -0.28353        0.877\n",
      "            29          -0.28045        0.877\n",
      "            30          -0.27753        0.878\n",
      "            31          -0.27475        0.879\n",
      "            32          -0.27210        0.880\n",
      "            33          -0.26958        0.881\n",
      "            34          -0.26716        0.882\n",
      "            35          -0.26485        0.883\n",
      "            36          -0.26264        0.883\n",
      "            37          -0.26051        0.884\n",
      "            38          -0.25847        0.885\n",
      "            39          -0.25650        0.885\n",
      "            40          -0.25461        0.887\n",
      "            41          -0.25279        0.887\n",
      "            42          -0.25103        0.888\n",
      "            43          -0.24933        0.888\n",
      "            44          -0.24769        0.889\n",
      "            45          -0.24610        0.889\n",
      "            46          -0.24456        0.890\n",
      "            47          -0.24307        0.891\n",
      "            48          -0.24162        0.892\n",
      "            49          -0.24022        0.892\n",
      "            50          -0.23885        0.893\n",
      "            51          -0.23753        0.893\n",
      "            52          -0.23624        0.893\n",
      "            53          -0.23498        0.894\n",
      "            54          -0.23376        0.894\n",
      "            55          -0.23257        0.894\n",
      "            56          -0.23141        0.896\n",
      "            57          -0.23028        0.896\n",
      "            58          -0.22917        0.896\n",
      "            59          -0.22809        0.897\n",
      "            60          -0.22704        0.897\n",
      "            61          -0.22600        0.897\n",
      "            62          -0.22500        0.897\n",
      "            63          -0.22401        0.898\n",
      "            64          -0.22305        0.898\n",
      "            65          -0.22210        0.898\n",
      "            66          -0.22118        0.898\n",
      "            67          -0.22027        0.899\n",
      "            68          -0.21938        0.899\n",
      "            69          -0.21851        0.899\n",
      "            70          -0.21766        0.900\n",
      "            71          -0.21682        0.900\n",
      "            72          -0.21600        0.901\n",
      "            73          -0.21519        0.901\n",
      "            74          -0.21440        0.901\n",
      "            75          -0.21362        0.902\n",
      "            76          -0.21286        0.902\n",
      "            77          -0.21211        0.902\n",
      "            78          -0.21137        0.902\n",
      "            79          -0.21064        0.902\n",
      "            80          -0.20993        0.902\n",
      "            81          -0.20923        0.902\n",
      "            82          -0.20854        0.903\n",
      "            83          -0.20786        0.903\n",
      "            84          -0.20719        0.904\n",
      "            85          -0.20653        0.904\n",
      "            86          -0.20588        0.904\n",
      "            87          -0.20524        0.904\n",
      "            88          -0.20462        0.904\n",
      "            89          -0.20400        0.904\n",
      "            90          -0.20339        0.905\n",
      "            91          -0.20278        0.906\n",
      "            92          -0.20219        0.906\n",
      "            93          -0.20161        0.906\n",
      "            94          -0.20103        0.906\n",
      "            95          -0.20046        0.906\n",
      "            96          -0.19990        0.907\n",
      "            97          -0.19935        0.907\n",
      "            98          -0.19880        0.908\n",
      "            99          -0.19826        0.908\n",
      "         Final          -0.19773        0.908\n",
      "Accuracy of Train set for Maximum Entropy: 90.83 %\n",
      "Accuracy of Test set for Maximum Entropy: 83.8 %\n"
     ]
    }
   ],
   "source": [
    "# 3. Evaluating maximum entropy classifier\n",
    "featuresets = [(gender_features(n), gender) for (n, gender) in names]\n",
    "train_set, devtest_set, test_set = featuresets[1000:], featuresets[500:1000], featuresets[:500]\n",
    "classifier_mec = nltk.classify.MaxentClassifier.train(train_set, max_iter = 100)\n",
    "print(\"Accuracy of Train set for Maximum Entropy:\", round((nltk.classify.accuracy(classifier_mec, train_set)*100),2),\"%\")\n",
    "print(\"Accuracy of Test set for Maximum Entropy:\", round((nltk.classify.accuracy(classifier_mec, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compare the three models on the test set and we can see that the results are in the following order:\n",
    "\n",
    "Maximum Entropy Classifier > Naive Bayes Classifier > Decision Tree\n",
    "\n",
    "Maximum Entropy classifier calculates the likelihood of each label for a given input value by multiplying together the parameters that are applicable for the input value and label. Thus, Maximum entropy classifier does the best job as it builds iteratively on various likelihood scenarios and improve the accuracy based on each sequence. It thus optimzes the result for each iteration as we can see above. It lead to an accuracy of 83.8% at the end for the test set. \n",
    "\n",
    "Naive Bayes classifier model defines a parameter for each label, specifying its prior probability, and a parameter for each (feature, label) pair, specifying the contribution of individual features towards a label's likelihood. Naive bayes classifier is a good model and gets a 83.33% accuracy in classification of gender features but it is often affected by features which may have high co-relation. \n",
    "\n",
    "Lastly, decision trees gave an accuracy of 60.0% which is low and far below the other two models, and it can be attributed to the compliacted nature of the feature extraction. It works best on simplified models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Identify the NPS Chat Corpus, which was demonstrated in Chapter 2, consists of over 15,000 posts from instant messaging sessions. These posts have all been labeled with one of 15 dialogue act types, such as \"Statement,\" \"Emotion,\" \"ynQuestion\", and \"Continuer.\" We can therefore use this data to build a classifier that can identify the dialogue act types for new instant messaging posts. Build a simple feature extractor that checks what words the post contains. Construct the training and testing data by applying the feature extractor to each post and create a Nave Bayes classifier. Please print the accuracy of this classifier. We use the first 15,000 messages from these instant messages as our dataset and use 8% data as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10567"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.nps_chat.xml_posts())\n",
    "# There are less than 15k rows but we will consider them all and use 8% of 15K. \n",
    "# I double checked with Prof to be sure if I am on the right track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a feature extractor that checks what words the post contains:\n",
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
    "              for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definign training and test sets:\n",
    "size = int(len(featuresets) * 0.08)\n",
    "\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.69 %\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy of the classifier:\n",
    "print(\"Accuracy:\", round((nltk.classify.accuracy(classifier, test_set)*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Given the following confusion matrix, please calculate: a) Accuracy Rate; b) Precision; c) Recall; d) F-Measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tNo\tYes\n",
    "No\t104\t33\n",
    "Yes\t13\t50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_no</th>\n",
       "      <th>predicted_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_no</th>\n",
       "      <td>104</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_yes</th>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_no  predicted_yes\n",
       "actual_no            104             33\n",
       "actual_yes            13             50"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a confusion matrix:\n",
    "column_names = ['predicted_no', 'predicted_yes']\n",
    "row_names    = ['actual_no', 'actual_yes']\n",
    "matrix = np.reshape((104,33,13,50), (2,2))\n",
    "df = pd.DataFrame(matrix, columns=column_names, index=row_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate: 77.0 %\n"
     ]
    }
   ],
   "source": [
    "# a) Accuracy Rate\n",
    "acc = (df['predicted_no']['actual_no'] + df['predicted_yes']['actual_yes'])/ matrix.sum()\n",
    "print(\"Accuracy Rate:\",round((acc*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 79.37 %\n"
     ]
    }
   ],
   "source": [
    "# b) Precision\n",
    "pre = df['predicted_yes']['actual_yes'] / (df['predicted_no']['actual_yes'] + df['predicted_yes']['actual_yes'])\n",
    "print(\"Precision:\",round((pre*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 60.24 %\n"
     ]
    }
   ],
   "source": [
    "# c) Recall\n",
    "rec = df['predicted_yes']['actual_yes'] / (df['predicted_yes']['actual_no'] + df['predicted_yes']['actual_yes'])\n",
    "print(\"Recall:\",round((rec*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F - measure: 68.49 %\n"
     ]
    }
   ],
   "source": [
    "#d) F-score\n",
    "fm = 2*pre*rec / (pre + rec)\n",
    "print(\"F - measure:\",round((fm*100),2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a tag pattern to match noun phrases containing plural head nouns in the following sentence: \"Many researchers discussed this project for two weeks.\" Try to do this by generalizing the tag pattern that handled singular noun phrases too. Please 1) pos-tag this sentence 2) write a tag pattern (i.e. grammar); 3) use RegexpParser to parse the sentence and 4) print out the result containing NP (noun phrases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# singular noun phrases: <DT>?<JJ.*>*<NN.*>+\n",
    "# plural noun phrases: <DT>?<JJ.*>*<NN.*>*<NNS>+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Many', 'JJ'),\n",
       " ('researchers', 'NNS'),\n",
       " ('discussed', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('project', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('two', 'CD'),\n",
       " ('weeks', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 - pos-tag the given sentence:\n",
    "sentence  =  \"Many researchers discussed this project for two weeks.\"\n",
    "sentence_tokenized =  nltk.word_tokenize(sentence)\n",
    "tagged_sentence = nltk.pos_tag(sentence_tokenized)\n",
    "tagged_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - define the tag pattern (grammar):\n",
    "grammar = \"NP: {<(JJ|CD|DT).*>+<NNS?>}\"\n",
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - use regex parser to parse the sentence:\n",
    "result = cp.parse(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Many/JJ researchers/NNS)\n",
      "  discussed/VBD\n",
      "  (NP this/DT project/NN)\n",
      "  for/IN\n",
      "  (NP two/CD weeks/NNS)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - print out the results than contains NPs:\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            S                                                   \n",
      "       _____________________________________|_______________________________________             \n",
      "      |         |     |           NP                          NP                    NP          \n",
      "      |         |     |      _____|_________             _____|______          _____|______      \n",
      "discussed/VBD for/IN ./. Many/JJ     researchers/NNS this/DT     project/NN two/CD     weeks/NNS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5 - print the result graphically using a tree\n",
    "output = '(S (NP Many/JJ researchers/NNS) discussed/VBD (NP this/DT project/NN) for/IN (NP two/CD weeks/NNS) ./.)'\n",
    "\n",
    "from nltk.tree import Tree\n",
    "parsetree = Tree.fromstring(output)\n",
    "parsetree.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a tag pattern to cover noun phrases that contain gerunds, e.g. \"the/DT receiving/VBG end/NN\", \"assistant/NN managing/VBG editor/NN\". Add these patterns to the grammar, one per line. Test your work using some tagged sentences of your own devising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "    NP: {<DT><VBG><NN.*>}    # chunk determiner, gerund, and noun\n",
    "        {<NN.*><VBG><NN.*>}   # chunk noun, gerund, and noun\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the/DT receiving/VBG end/NN))\n",
      "(S (NP assistant/NN managing/VBG editor/NN))\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(grammar)\n",
    "sentences = [[(\"the\", \"DT\"), (\"receiving\", \"VBG\"), (\"end\", \"NN\")], \n",
    "             [(\"assistant\", \"NN\"),  (\"managing\", \"VBG\"),  (\"editor\", \"NN\")]]\n",
    "\n",
    "for sent in sentences:\n",
    "    print(cp.parse(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American', 'NNP'),\n",
       " ('citizens', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('vote', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('president', 'NN')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the work using my own sentences - 1\n",
    "my_sentence = \"American citizens will vote for the new president\"\n",
    "my_sentence_tokenized =  nltk.word_tokenize(my_sentence)\n",
    "tagged_my_sentence = nltk.pos_tag(my_sentence_tokenized)\n",
    "tagged_my_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  American/NNP\n",
      "  citizens/NNS\n",
      "  will/MD\n",
      "  vote/VB\n",
      "  for/IN\n",
      "  the/DT\n",
      "  new/JJ\n",
      "  president/NN)\n"
     ]
    }
   ],
   "source": [
    "result = cp.parse(tagged_my_sentence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('excited', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('upcoming', 'JJ'),\n",
       " ('olympic', 'NN'),\n",
       " ('games', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('2021', 'CD')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the work using my own sentences - 2\n",
    "my_sentence_2 = \"I am excited for the upcoming olympic games in 2021\"\n",
    "my_sentence_tokenized_2 =  nltk.word_tokenize(my_sentence_2)\n",
    "tagged_my_sentence_2 = nltk.pos_tag(my_sentence_tokenized_2)\n",
    "tagged_my_sentence_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  am/VBP\n",
      "  excited/VBN\n",
      "  for/IN\n",
      "  the/DT\n",
      "  upcoming/JJ\n",
      "  olympic/NN\n",
      "  games/NNS\n",
      "  in/IN\n",
      "  2021/CD)\n"
     ]
    }
   ],
   "source": [
    "result_2 = cp.parse(tagged_my_sentence_2)\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S the/DT new/JJ president/NN)\n",
      "(S upcoming/JJ olympic/NNS games/NNS)\n"
     ]
    }
   ],
   "source": [
    "my_sentence_tags = [[(\"the\", \"DT\"), (\"new\", \"JJ\"), (\"president\", \"NN\")], \n",
    "             [(\"upcoming\", \"JJ\"),  (\"olympic\", \"NNS\"),  (\"games\", \"NNS\")]]\n",
    "\n",
    "for sent in my_sentence_tags:\n",
    "    print(cp.parse(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Use the Brown Corpus and the cascaded chunkers that has patterns for noun phrases, prepositional phrases, verb phrases, and clauses to print out all the verb phrases in the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN\n",
    "  PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "  VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n",
    "  CLAUSE: {<NP><VP>}           # Chunk NP, VP\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(grammar, loop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(VP Ask/VB-HL (NP jail/NN-HL deputies/NNS-HL))\n",
      "(VP revolving/VBG-HL (NP fund/NN-HL))\n",
      "(VP Issue/VB-HL (NP jury/NN-HL subpoenas/NNS-HL))\n",
      "(VP Nursing/VBG-HL (NP home/NN-HL care/NN-HL))\n",
      "(VP pay/VB-HL (NP doctors/NNS-HL))\n",
      "(VP nursing/VBG-HL (NP homes/NNS))\n",
      "(VP Asks/VBZ-HL (NP research/NN-HL funds/NNS-HL))\n",
      "(VP Regrets/VBZ-HL (NP attack/NN-HL))\n",
      "(VP Decries/VBZ-HL (NP joblessness/NN-HL))\n",
      "(VP Underlying/VBG-HL (NP concern/NN-HL))\n",
      "(VP bar/VB-HL (NP vehicles/NNS-HL))\n",
      "(VP loses/VBZ-HL (NP pace/NN-HL))\n",
      "(VP hits/VBZ-HL (NP homer/NN-HL))\n",
      "(VP attend/VB-HL (NP races/NNS-HL))\n",
      "(VP follows/VBZ-HL (NP ceremonies/NNS-HL))\n",
      "(VP Noted/VBN-HL (NP artist/NN-HL))\n",
      "(VP Cites/VBZ-HL (NP discrepancies/NNS-HL))\n",
      "(VP calls/VBZ-HL (NP police/NNS-HL))\n",
      "(VP held/VBN-HL (NP key/NN-HL))\n",
      "(VP grant/VB-HL (NP bail/NN-HL))\n",
      "(VP Held/VBD-HL (NP candle/NN-HL))\n",
      "(VP Expresses/VBZ-HL (NP thanks/NNS-HL))\n",
      "(VP Gets/VBZ-HL (NP car/NN-HL number/NN-HL))\n",
      "(VP Attacks/VBZ-HL (NP officer/NN-HL))\n",
      "(VP oks/VBZ-HL (NP pact/NN-HL))\n",
      "(VP report/VB-HL (NP gains/NNS-HL))\n",
      "(VP Pulling/VBG-HL (NP strings/NNS-HL))\n",
      "(VP United/VBN-TL-HL (NP States/NNS-TL-HL defense/NN-HL))\n",
      "(VP Betting/VBG-HL (NP men/NNS-HL))\n",
      "(VP brings/VBZ-HL (NP numbness/NN-HL))\n",
      "(VP Questions/VBZ-HL (NP shelters/NNS-HL))\n",
      "(VP Marketing/VBG-HL (NP meat/NN-HL))\n",
      "(VP Taxing/VBG-HL (NP improvements/NNS-HL))\n",
      "(VP Praises/VBZ-HL (NP exhibit/NN-HL))\n",
      "(VP aid/VB (NP international/JJ law/NN))\n",
      "(VP retarded/VBN-HL (NP children/NNS-HL))\n",
      "(VP tormented/VBN-HL (NP span/NN-HL))\n",
      "(VP dashed/VBN-HL (NP hope/NN-HL))\n",
      "(VP open/VB-HL (NP program/NN-HL))\n",
      "(VP Fleeting/VBG-HL (NP glimpse/NN-HL))\n",
      "(VP fragmented/VBN-HL (NP Society/NN-TL-HL))\n",
      "(VP locking/VBG-HL (NP bars/NNS-HL))\n",
      "(VP fire/VB (NP standard/JJ))\n",
      "(VP Canned/VBN-HL (NP cocktail/NN-HL frankfurters/NNS-HL))\n",
      "(VP whipped/VBN (NP Salt/NN Paprika/NN))\n",
      "(VP Barbecued/VBN-HL (NP frankfurters/NNS-HL))\n",
      "(VP Changing/VBG-HL (NP colors/NNS-HL))\n",
      "(VP Measuring/VBG-HL (NP armhole/NN-HL))\n",
      "(VP Backstitching/VBG-HL (NP seam/NN-HL))\n",
      "(VP Weaving/VBG-HL (NP seam/NN-HL))\n",
      "(VP drilling/VBG-HL (NP tools/NNS-HL))\n",
      "(VP drilling/VBG-HL (NP operations/NNS-HL))\n",
      "(VP Adjoining/VBG-HL (NP areas/NNS-HL))\n",
      "(VP chinning/VBG-HL (NP bar/NN-HL))\n",
      "(VP fattening/VBG-HL (NP rations/NNS-HL))\n",
      "(VP marketing/VBG-HL (NP methods/NNS-HL))\n",
      "(VP marketing/VBG-HL (NP management/NN-HL))\n",
      "(VP feeding/VBG-HL (NP facilities/NNS-HL))\n",
      "(VP Paid/VBN-HL (NP vacations/NNS-HL))\n",
      "(VP Eating/VBG-HL (NP facilities/NNS-HL))\n",
      "(VP farming/VBG-HL (NP methods/NNS-HL))\n",
      "(VP Nourishing/VBG (NP meals/NNS))\n",
      "(VP save/VB-HL (NP teeth/NNS-HL))\n",
      "(VP helps/VBZ-HL (NP families/NNS-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP planning/VBG-HL (NP process/NN-HL))\n",
      "(VP applying/VBG-HL (NP conditions/NNS-HL))\n",
      "(VP Encouraging/VBG-HL (NP self-help/NN-HL))\n",
      "(VP stressing/VBG-HL (NP self-help/NN-HL))\n",
      "(VP nearing/VBG-HL (NP self-sufficiency/NN-HL))\n",
      "(VP Advertising/VBG-HL (NP program/NN-HL))\n",
      "(VP Planning/VBG-HL (NP division/NN-HL))\n",
      "(VP financing/VBG-HL (NP adjustments/NNS-HL))\n",
      "(VP distributing/VBG-HL (NP funds/NNS-HL))\n",
      "(VP Matching/VBG-HL (NP requirements/NNS-HL))\n",
      "(VP prepared/VBN (NP shelter/NN))\n",
      "(VP Increased/VBN-HL (NP efficiency/NN-HL))\n",
      "(VP shifting/VBG-HL (NP styles/NNS-HL))\n",
      "(VP broadcasting/VBG-HL (NP station/NN-HL))\n",
      "(VP cleaning/VBG-HL (NP process/NN-HL))\n",
      "(VP frozen/VBN-HL (NP sections/NNS-HL))\n",
      "(VP Staining/VBG-HL (NP technique/NN-HL))\n",
      "(VP Concluding/VBG-HL (NP remarks/NNS-HL))\n",
      "(VP modernizing/VBG-HL (NP societies/NNS-HL))\n",
      "(VP teaching/VBG-HL (NP methods/NNS-HL))\n",
      "(VP teaching/VBG-HL (NP methods/NNS-HL))\n",
      "(VP bargaining/VBG-HL (NP issues/NNS-HL))\n",
      "(VP\n",
      "  selecting/VBG-HL\n",
      "  (NP mail/NN-HL questionnaire/NN-HL method/NN-HL))\n",
      "(VP mailing/VBG-HL (NP lists/NNS-HL))\n",
      "(VP distributed/VBN-HL (NP cost/NN-HL analysis/NN-HL))\n",
      "(VP define/VB-HL (NP input/output/NN-HL control/NN-HL system/NN-HL))\n",
      "(VP related/VBN-HL (NP materials/NNS-HL))\n",
      "(VP ionizing/VBG-HL (NP radiation/NN-HL))\n",
      "(VP seen/VBN (NP that/DT Af/NN))\n",
      "(VP\n",
      "  Chipping/VBG\n",
      "  (NP mechanism/NN)\n",
      "  (PP of/IN (NP cohesive/JJ failure/NN)))\n",
      "(VP cracking/VBG-HL (NP mechanism/NN-HL))\n",
      "(VP Processing/VBG-HL (NP urethanes/NNS-HL))\n",
      "(VP coupled/VBN-HL (NP image/NN-HL intensifiers/NNS-HL))\n",
      "(VP following/VBG (NP morning/NN))\n",
      "(VP hear/VB (CLAUSE (NP that/DT) (VP whining/VBG (NP voice/NN))))\n",
      "(VP whining/VBG (NP voice/NN))\n",
      "(VP convinced/VBN (PP of/IN (NP that/DT)))\n"
     ]
    }
   ],
   "source": [
    "for sent in nltk.corpus.brown.tagged_sents():\n",
    "    tree = cp.parse(sent)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == 'VP': print(subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. The bigram chunker scores about 90% accuracy. Study its errors and try to work out why it doesn't get 100% accuracy. Experiment with trigram chunking. Are you able to improve the performance any more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000\n",
    "\n",
    "# Define train and test sets\n",
    "test_sents = conll2000.chunked_sents('test.txt')\n",
    "train_sents = conll2000.chunked_sents('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigram chunker\n",
    "class BigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                       for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data)       \n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word, pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  89.3%%\n",
      "    Precision:     81.2%%\n",
      "    Recall:        86.2%%\n",
      "    F-Measure:     83.6%%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the bigram chunker\n",
    "bigram_chunker = BigramChunker(train_sents)\n",
    "print(bigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"VP: {<VB.>?<RB>*<MD>?<VB.>?<TO>?<MD>?<RB>*<VB.>}\"\n",
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImmutableTree('VP', [('rebound', 'NN'), ('to', 'TO'), ('close', 'VB')]),\n",
       " ImmutableTree('NP', [('Mr.', 'NNP'), ('Edelman', 'NNP')]),\n",
       " ImmutableTree('NP', [(\"'s\", 'POS'), ('chief', 'JJ'), ('retail', 'JJ'), ('banking', 'NN'), ('officer', 'NN')]),\n",
       " ImmutableTree('NP', [('McNally', 'NNP')]),\n",
       " ImmutableTree('PP', [('with', 'IN')]),\n",
       " ImmutableTree('NP', [('next', 'JJ'), ('year', 'NN')]),\n",
       " ImmutableTree('VP', [('were', 'VBD'), ('both', 'DT'), ('hired', 'VBN')]),\n",
       " ImmutableTree('NP', [('any', 'DT'), ('alternative', 'NN')]),\n",
       " ImmutableTree('PP', [('to', 'TO')]),\n",
       " ImmutableTree('NP', [('a', 'DT'), ('one-time', 'JJ'), ('$', '$'), ('16', 'CD'), ('million', 'CD'), ('gain', 'NN')])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study the errors for bigram chunker:\n",
    "# a) chunkscore.missed()\n",
    "cp.evaluate(test_sents).missed()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImmutableTree('VP', [('scrambled', 'VBD')]),\n",
       " ImmutableTree('VP', [('does', 'VBZ')]),\n",
       " ImmutableTree('VP', [('proposed', 'VBN')]),\n",
       " ImmutableTree('VP', [('recently', 'RB'), ('launched', 'VBN')]),\n",
       " ImmutableTree('VP', [('pushed', 'VBN')]),\n",
       " ImmutableTree('VP', [('holding', 'VBG')]),\n",
       " ImmutableTree('VP', [('swelling', 'VBG')]),\n",
       " ImmutableTree('VP', [('get', 'VBP'), ('is', 'VBZ')]),\n",
       " ImmutableTree('VP', [('shares', 'VBZ')]),\n",
       " ImmutableTree('VP', [('have', 'VBP'), ('been', 'VBN'), ('forced', 'VBN')])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study the errors for bigram chunker:\n",
    "# b) chunkscore.incorrect()\n",
    "cp.evaluate(test_sents).incorrect()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error study as seen above doesn't give much directions. I looked at 10 incorrect ones and we can see how the chunks are an issue when the past tense and past participle forms are difficult for the system to tag.\n",
    "\n",
    "However, oen thing that appears is that sometimes chunker marks single VBN or VBG as VP chunk. This could be thought of as a direcyion to improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trigram chunker\n",
    "class TrigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents):\n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                       for sent in train_sents]\n",
    "        self.tagger = nltk.TrigramTagger(train_data)\n",
    "        \n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        pos_tags = [pos for (word, pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word, pos), chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  87.7%%\n",
      "    Precision:     81.0%%\n",
      "    Recall:        84.4%%\n",
      "    F-Measure:     82.6%%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trigram chunker\n",
    "trigram_chunker = TrigramChunker(train_sents)\n",
    "print(trigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No the performance doesn't improve for trigram chunker as comapred to the bigram chunker. As we studied in class (quoting the nltk book), the specificity of the contexts increases, as does the chance that the data we wish to tag contains contexts that were not present in the training data. This is known as the sparse data problem, and is quite pervasive in NLP. As a consequence, there is a trade-off between the accuracy and the coverage of our results (and this is related to the precision/recall trade-off in information retrieval)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Explore the Brown Corpus to print out all the FACILITIES (one of the commonly used types of name entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown = nltk.corpus.brown.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_facilities = {subtree[0][0] for sent in brown\n",
    "                  for subtree in nltk.ne_chunk(sent).subtrees()\n",
    "                  if subtree.label() == 'FACILITY'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baltimore', 'Bari', 'Berlin', 'Boron', 'Caltech', 'Caracas', 'Clayton', 'Francie', 'Franklin', 'Grafton', 'Hilo', 'Israelite', 'Jack', 'Jenks', 'Kremlin', 'Lublin', 'Madison', 'Marston', 'Ninth', 'Northfield', 'Pennsylvania', 'Penny', 'Pensacola', 'Phil', 'Raymondville', 'Rome', 'Teheran', 'Versailles', 'White', 'Whiteleaf', 'Whitemarsh', 'Winston']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(brown_facilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
