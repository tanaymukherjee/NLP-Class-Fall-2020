{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 3 Processing Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,re,pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Accessing Text from the Web and from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text number 1125 is “All's Well That Ends Well” by William Shakespeare, and we can access it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/files/1125/1125.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160953"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\r\\n**********************************************************************\\r\\nTHIS EBOOK WAS ONE OF PROJECT GUTENBERG'S EARLY FILES PRODUCED AT A\\r\\nTIME WHEN PROOFING METHODS AND TOOLS WERE NOT WELL DEVELOPED.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The variable raw contains a string with 160,953 characters. This is the raw content of the book, including many details we are not interested in such as whitespace, line breaks and blank lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our language processing, we want to break up the string into words and punctuation. This step is called tokenization, and it produces our familiar structure, a list of words and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of words in this text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first ten words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**********************************************************************',\n",
       " 'THIS',\n",
       " 'EBOOK',\n",
       " 'WAS',\n",
       " 'ONE',\n",
       " 'OF',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " \"'S\",\n",
       " 'EARLY',\n",
       " 'FILES',\n",
       " 'PRODUCED',\n",
       " 'AT',\n",
       " 'A',\n",
       " 'TIME',\n",
       " 'WHEN',\n",
       " 'PROOFING',\n",
       " 'METHODS',\n",
       " 'AND',\n",
       " 'TOOLS']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of the text on the web is in the form of HTML documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use a web browser to save a page as text to a local file, then access this as described in the section on files below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is the same as before, using urlopen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fun we'll pick a BBC News story called Blondes to die out in 200 years, an urban legend passed along by the BBC as established scientific fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = request.urlopen(url).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can type print(html) to see the HTML content in all its glory, including meta tags, an image map, JavaScript, forms, and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\r\n",
      "<html>\r\n",
      "<head>\r\n",
      "<title>BBC NEWS | Health | Blondes 'to die out in 200 years'</title>\r\n",
      "<meta name=\"keywords\" content=\"BBC, News, BBC News, news online, world, uk, international, foreign, british, online, service\">\r\n",
      "<meta name=\"OriginalPublicationDate\" content=\"2002/09/27 11:51:55\">\r\n",
      "<meta name=\"UKFS_URL\" content=\"/1/hi/health/2284783.stm\">\r\n",
      "<meta name=\"IFS_URL\" content=\"/2/hi/health/2284783.stm\">\r\n",
      "<meta name=\"HTTP-EQUIV\" content=\"text/html;charset=iso-8859-1\">\r\n",
      "<meta name=\"Headline\" content=\"Blondes 'to die out in 200 years'\">\r\n",
      "<meta name=\"Section\" content=\"Health\">\r\n",
      "<meta name=\"Description\" content=\"Natural blondes are an endangered species and will die out by 2202, a study suggests.\">\r\n",
      "<!-- GENMaps-->\r\n",
      "<map name=\"banner\">\r\n",
      "<area alt=\"BBC NEWS\" coords=\"7,9,167,32\" href=\"http://news.bbc.co.uk/1/hi.html\" shape=\"RECT\">\r\n",
      "</map>\r\n",
      "\r\n",
      "<script src=\"/nol/shared/js/livestats_v1_1.js\" language=\"JavaScript\" type=\"text/javascript\"></script>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t\t\t\r\n",
      "\t<map name=\"world_map\">\r\n",
      "<area alt=\"Americas\" coords=\"40,55,40,4,6,4,7,55\" href=\"/2/hi/americas/default.stm\" shape=\"POLY\">\r\n",
      "<area alt=\"Africa\" shape=\"POLY\" coords=\"41,54,41,27,46,27,46,32,46,33,55,33,55,36,58,36,58,54\" href=\"/2/hi/africa/default.stm\">\r\n",
      "<area alt=\"Europe\" shape=\"POLY\" coords=\"41,5,41,25,63,25,63,17,73,17,73,4\" href=\"/2/hi/europe/default.stm\">\r\n",
      "<area alt=\"Middle East\" shape=\"POLY\" coords=\"60,54,60,54,60,34,57,34,57,31,48,31,48,27,63,27,63,54\" href=\"/2/hi/middle_east/default.stm\">\r\n",
      "<area alt=\"South Asia\" coords=\"67,55,65,54,65,27,71,27,71,54\" href=\"/2/hi/south_asia/default.stm\" shape=\"POLY\">\r\n",
      "<area alt=\"Asia Pacific\" shape=\"POLY\" coords=\"75,54,73,54,73,25,65,25,65,19,75,19,75,5,94,5,94,56\" href=\"/2/hi/asia-pacific/default.stm\">\r\n",
      "</map>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"/nol/shared/stylesheets/uki_globalstylesheet.css\">\r\n",
      "<script src=\"/nol/shared/js_ifs/nol.js\" language=\"JavaScript\"></script>\r\n",
      "</head>\r\n",
      "\r\n",
      "<body bgcolor=\"#FFFFFF\" text=\"#000000\" link=\"#000066\" alink=\"#000066\" vlink=\"#993333\" topmargin=\"0\" leftmargin=\"0\" marginheight=\"0\" marginwidth=\"0\">\r\n",
      "<!--[START]--(( BBCi TOOLBAR )) IFS News -->\r\n",
      "<table width=\"610\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\r\n",
      "<tr>\r\n",
      "<td class=\"bbcpageShadow\"><a name=\"top\"><img src=\"/nol/shared/img/global_toolbar/t.gif\" width=\"600\" height=\"2\" alt=\"\"/></a></td>\r\n",
      "</tr>\r\n",
      "<form action=\"http://newssearch.bbc.co.uk/cgi-bin/search/results.pl\">\r\n",
      "<input type=\"hidden\" name=\"scope\" value=\"newsifs\">\r\n",
      "<input type=\"hidden\" name=\"tab\" value=\"news\">\r\n",
      "<tr>\r\n",
      "<td class=\"bbcpageGrey\">\r\n",
      "<table cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\r\n",
      "<tr>\r\n",
      "<td class=\"bbcpageShadowLeft\" width=\"100%\"><a href=\"http://www.bbc.co.uk/\"><img src=\"/nol/shared/img/global_toolbar/logo.gif\" width=\"62\" height=\"20\" alt=\"BBCi\" border=\"0\" hspace=\"7\" vspace=\"2\" /></a></td>\r\n",
      "<td class=\"bbcpageGreyT\" align=\"right\"><font color=\"#000000\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\"><b><a href=\"http://news.bbc.co.uk\" class=\"bbcpageWhite\">NEWS</a></b></font></td>\r\n",
      "<td class=\"bbcpageBar\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://news.bbc.co.uk/sport/\" class=\"bbcpageWhite\">SPORT</a></b></font></td>\r\n",
      "<td class=\"bbcpageBar2\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/weather/\" class=\"bbcpageWhite\">WEATHER</a></b></font></td>\r\n",
      "<td class=\"bbcpageBar\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/worldservice/index.shtml\" class=\"bbcpageWhite\">WORLD SERVICE</a></b></font></td>\r\n",
      "<!-- <td class=\"bbcpageBar2\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/whereilive/\" class=\"bbcpageWhite\">WHERE&nbsp;I&nbsp;LIVE</a></b></font></td> -->\r\n",
      "<td class=\"bbcpageBar\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/a-z/\" class=\"bbcpageWhite\">A-Z INDEX</a>&nbsp;</b></font></td>\r\n",
      "<td class=\"bbcpageSearchL\"><img src=\"/furniture/nothing.gif\" width=\"2\" height=\"30\" alt=\"\"/></td>\r\n",
      "<td class=\"bbcpageSearch\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageCream\">&nbsp;&nbsp;<label for=\"bbcpagesearchbox\"><b>SEARCH</b></label>&nbsp;</font></td>\r\n",
      "<td class=\"bbcpageSearch2\" style=\"font-family:tahoma,arial,helvetica,sans-serif;\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"3\" alt=\"\" /><br /><INPUT type=\"text\" name=\"q\" id=\"bbcpagesearchbox\" size=\"5\" style=\"width:95px;\" /></td>\r\n",
      "<td class=\"bbcpageSearch\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\" /></td>\r\n",
      "<td class=\"bbcpageSearch2\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"5\" alt=\"\" /><br /><input type=\"image\" value=\"go\" src=\"/nol/shared/img/global_toolbar/go.gif\" width=\"20\" height=\"16\" border=\"0\" alt=\"Go\" align=\"top\" /></td>\r\n",
      "<td class=\"bbcpageSearch\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\" /></td>\r\n",
      "<td class=\"bbcpageSearchR\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"30\" alt=\"\" /></td>\r\n",
      "</tr>\r\n",
      "\r\n",
      "<tr bgcolor=\"#000000\">\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"76\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"76\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"20\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"42\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"94\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"80\" height=\"1\" alt=\"\"/></td>\r\n",
      "<!-- <td><img src=\"/shared/img/o.gif\" width=\"42\" height=\"1\" alt=\"\"/></td> -->\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"2\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"51\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"100\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"20\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"/></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"/></td>\r\n",
      "</tr>\r\n",
      "\r\n",
      "</table></td>\r\n",
      "\r\n",
      "</tr>\r\n",
      "</form>\r\n",
      "</table>\r\n",
      "<!-- end news toolbar 1.0 -->\r\n",
      "<table width=\"610\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n",
      "<tr><td bgcolor=\"#9C0000\"><img src=\"/nol/shared/img/banners/ifs_banner.gif\" width=\"610\" height=\"40\" border=\"0\" alt=\"BBC News World Edition\" usemap=\"#banner\"></td></tr></table>\r\n",
      "<!--END OF BANNER-->\r\n",
      "\r\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"610\">\r\n",
      "<tr>\r\n",
      "<td width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\r\n",
      "<td width=\"100\"><img src=\"/shared/img/o.gif\" width=\"100\" height=\"1\" alt=\"\"></td>\r\n",
      "<td width=\"5\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#999966\" width=\"315\"><img src=\"/shared/img/o.gif\" width=\"315\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#999966\" width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#999966\" width=\"170\"><img src=\"/shared/img/o.gif\" width=\"170\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "\r\n",
      "<tr>\r\n",
      "<td width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\r\n",
      "<td width=\"100\"><img src=\"/shared/img/o.gif\" width=\"100\" height=\"1\" alt=\"\"></td>\r\n",
      "<td width=\"5\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"3\" alt=\"\"></td>\r\n",
      "<td colspan=\"3\" width=\"495\" class=\"crumbtraila\" bgcolor=\"#CCCC99\">\r\n",
      "    &nbsp;You are in:&nbsp;<a href=\"/2/hi/health/default.stm\"><b>Health</b> </a>&nbsp;\r\n",
      "    \r\n",
      "    \r\n",
      "</td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"LEFT\" valign=\"TOP\">\r\n",
      "    \r\n",
      "\t<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n",
      "\t<tr>\r\n",
      "\t<td><img height=\"1\" border=\"0\" width=\"96\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t<td><img height=\"1\" border=\"0\" width=\"4\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t</tr>\r\n",
      "\t\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyleTight\" align=\"right\"><a href=\"/2/hi/default.stm\" class=\"index\"><b>News Front Page</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td colspan=\"2\"><img height=\"60\" usemap=\"#world_map\" border=\"0\" width=\"100\" alt=\"\" src=\"http://newsimg.bbc.co.uk/nol/shared/img/nav/blue_map_world.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/africa/default.stm\" class=\"index\"><b>Africa</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/americas/default.stm\" class=\"index\"><b>Americas</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/asia-pacific/default.stm\" class=\"index\"><b>Asia-Pacific</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/europe/default.stm\" class=\"index\"><b>Europe</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/middle_east/default.stm\" class=\"index\"><b>Middle East</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/south_asia/default.stm\" class=\"index\"><b>South Asia</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/uk_news/default.stm\" class=\"index\"><b>UK</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/business/default.stm\" class=\"index\"><b>Business</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/entertainment/default.stm\" class=\"index\"><b>Entertainment</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyleTight\" align=\"right\"><a href=\"/2/hi/science/nature/default.stm\" class=\"index\"><b>Science/Nature</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/technology/default.stm\" class=\"index\"><b>Technology</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#999999\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/health/default.stm\" class=\"index\"><b>Health</b></a></td><td bgColor=\"#CC3300\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\t\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#CCCCCC\" align=\"right\" class=\"sectionStyle\"><a href=\"/2/hi/health/medical_notes/default.stm\" class=\"index\"><b>Medical notes</b></a></td><td bgcolor=\"#CCCCCC\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/talking_point/default.stm\" class=\"index\"><b>Talking Point</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t<tr>\r\n",
      "\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyleTight\" align=\"right\"><a href=\"/2/shared/bsp/hi/country_profiles/html/default.stm\" class=\"index\"><b>Country Profiles</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t</tr>\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t<tr>\r\n",
      "\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/shared/bsp/hi/in_depth/html/default.stm\" class=\"index\"><b>In Depth</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t</tr>\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t<tr>\r\n",
      "\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\r\n",
      "\t\t\t\t</tr>\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\t\t\r\n",
      "\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/programmes/default.stm\" class=\"index\"><b>Programmes</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t<tr>\r\n",
      "\t\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\r\n",
      "\t\t\t\t\t</tr>\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t<tr><td colspan=\"2\"><img height=\"5\" border=\"0\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td></tr>\r\n",
      "\t</table>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    \r\n",
      "    \r\n",
      "\r\n",
      "\r\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n",
      "<tr>\r\n",
      "<td><a href=\"/sport2/hi/default.stm\"><img src=\"/nol/shared/img/nav/sport.gif\" width=\"100\" height=\"13\" alt=\"BBC Sport\" border=\"0\"></a></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td><img src=\"/shared/img/o.gif\" height=\"3\" width=\"1\" border=\"0\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td><a href=\"http://www.bbc.co.uk/weather/worldweather/index.shtml\"><img src=\"/nol/shared/img/nav/weather.gif\" width=\"100\" height=\"13\" alt=\"BBC Weather\" border=\"0\"></a></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td><img src=\"/shared/img/o.gif\" height=\"10\" width=\"1\" border=\"0\"></td>\r\n",
      "</tr>\r\n",
      "\r\n",
      "</table>\r\n",
      "\r\n",
      "\r\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n",
      "<tr bgcolor=\"#990000\">\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr bgcolor=\"#990000\">\r\n",
      "<td colspan=\"3\" align=\"right\"><div class=\"servicehead\">SERVICES\r\n",
      "</div></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td class=\"servicebg1\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"right\" class=\"servicebg1\"><div class=\"servicesnav\"><a href=\"http://www.bbc.co.uk/email/news\">Daily E-mail\r\n",
      "</a></div></td>\r\n",
      "<td class=\"serviceoption1\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr> \r\n",
      "<tr>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td class=\"servicebg2\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"right\" class=\"servicebg2\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/ticker/html/default.stm\">News Ticker\r\n",
      "</a></div></td>\r\n",
      "<td class=\"serviceoption2\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td class=\"servicebg3\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"right\" class=\"servicebg3\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/mobiles/html/default.stm\">Mobile/PDAs\r\n",
      "</a></div></td>\r\n",
      "<td class=\"serviceoption3\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"center\" colspan=\"3\"><span class=\"lhsNavSeparator\">-------------\r\n",
      "</span></td>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "</table>\r\n",
      "\r\n",
      "\r\n",
      "    <table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n",
      "    <tr>\r\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "    </tr>\r\n",
      "    <tr>\r\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td class=\"servicebg4\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td align=\"right\" class=\"servicebg4\"><div class=\"servicesnav\"><a href=\"/2/low/health/2284783.stm\">Text Only</a></div></td>\r\n",
      "    <td class=\"serviceoption4\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "    </tr>\r\n",
      "    </table>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n",
      "<tr>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td class=\"servicebg5\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"right\" class=\"servicebg5\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/feedback/html/default.stm\">Feedback\r\n",
      "</a></div></td>\r\n",
      "<td class=\"serviceoption5\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td class=\"servicebg6\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"right\" class=\"servicebg6\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/help/html/default.stm\">Help\r\n",
      "</a></div></td>\r\n",
      "<td class=\"serviceoption6\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr bgcolor=\"#CCCCCC\">\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td colspan=\"5\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"4\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "</table>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n",
      "<tr bgcolor=\"#6699CC\">\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr bgcolor=\"#336699\">\r\n",
      "<td colspan=\"3\" align=\"right\"><div class=\"servicehead\">EDITIONS\r\n",
      "</div></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td align=\"right\"><div class=\"servicesnavtight\"><a href=\"/shared/hi/change_edition-news.stm\">Change to UK\r\n",
      "</a></div></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "<tr bgcolor=\"#CCCCCC\">\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\r\n",
      "</tr>\r\n",
      "</table>\r\n",
      "</td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"200\" alt=\"\"></td>\r\n",
      "<td valign=\"TOP\">\r\n",
      "    \t\r\n",
      "\t\r\n",
      "\r\n",
      "                \r\n",
      "\r\n",
      "\r\n",
      "<font face=\"sans-serif\" size=\"1\"><span class=\"date\">Friday, 27 September, 2002, 11:51 GMT 12:51 UK\r\n",
      "</span></font>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t\t\r\n",
      "\t\t\t<div class=\"headlinestory\"><b>Blondes 'to die out in 200 years'</b><br></div>\r\n",
      "\t\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "                \r\n",
      "\t\r\n",
      "\t<div class=\"inlineimage\">\r\n",
      "\t\t<img height=\"180\" vspace=\"0\" border=\"0\" width=\"300\" alt=\" \" src=\"/media/images/38280000/jpg/_38280456_blonde300.jpg\">\r\n",
      "\t\t\r\n",
      "\t\t\t<div class=\"caption\"><font size=\"1\">Scientists believe the last blondes will be in Finland</font><br></div>\r\n",
      "\t\t\r\n",
      "\t</div>\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "\r\n",
      "\t<font class=\"body\" face=\"sans-serif\" size=\"2\">\r\n",
      "\t<div class=\"bodytext\">\r\n",
      "\tThe last natural blondes will die out within 200 years, scientists believe. \r\n",
      "<P>\r\n",
      "A study by experts in Germany suggests people with blonde hair are an endangered species and will become extinct by 2202.\r\n",
      "<P>\r\n",
      "Researchers predict the last truly natural blonde will be born in Finland - the country with the highest proportion of blondes. \r\n",
      "<P>\r\n",
      "\r\n",
      "\r\n",
      "<!-- GENInlineBOX -->\r\n",
      "\r\n",
      "\t<table bgcolor=\"#FFFFCC\" class=\"boxbody\" cellspacing=\"0\" width=\"150\" border=\"0\" cellpadding=\"3\" align=\"right\">\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "<!-- GENInlineQUOTE -->\r\n",
      "\r\n",
      "\t<tr><td><img src=\"/nol/shared/img/startquote.gif\" width=\"23\" height=\"18\" border=\"0\" valign=\"TOP\" alt=\"\"><br><div class=\"boxbody\">\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\tThe frequency of blondes may drop but they won't disappear\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t</div><img align=\"RIGHT\" src=\"/nol/shared/img/endquote.gif\" width=\"23\" height=\"18\" border=\"0\" valign=\"ABSBOTTOM\" alt=\"\"><br clear=\"ALL\"></td></tr>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "<!-- GENInlineNAME -->\r\n",
      "\r\n",
      "\t<tr><td bgcolor=\"cccc99\"><div class=\"boxhead\">\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\tProf Jonathan Rees, University of Edinburgh\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t</div></td></tr>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t</table>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t\r\n",
      "But they say too few people now carry the gene for blondes to last beyond the next two centuries. \r\n",
      "<P>\r\n",
      "The problem is that blonde hair is caused by a recessive gene. \r\n",
      "<P>\r\n",
      "In order for a child to have blonde hair, it must have the gene on both sides of the family in the grandparents' generation. \r\n",
      "<P><B>Dyed rivals</B>\r\n",
      "<P>\r\n",
      "\r\n",
      "The researchers also believe that so-called bottle blondes may be to blame for the demise of their natural rivals. \r\n",
      "<P>\r\n",
      "They suggest that dyed-blondes are more attractive to men who choose them as partners over true blondes. \r\n",
      "<P>\r\n",
      "\r\n",
      "\r\n",
      "<!-- GENInlineIMAGE -->\r\n",
      "\r\n",
      "\t\t\r\n",
      "\t\t\t<table cellspacing=\"3\" align=\"RIGHT\" width=\"154\" border=\"0\" cellpadding=\"3\"><tr><td><font size=\"2\">\r\n",
      "\t\t\r\n",
      "\t\t<div class=\"inlineimage\">\r\n",
      "            <img alt=\"Tory MP Ann Widdecombe\" height=\"180\" vspace=\"0\" src=\"/media/images/38280000/jpg/_38280457_widders150.jpg\" border=\"0\" width=\"150\">\r\n",
      "            \r\n",
      "                <div class=\"caption\"><small>Bottle-blondes like Ann Widdecombe may be to blame</small><br></div>\r\n",
      "            \r\n",
      "\t\t</div>\r\n",
      "\t\t\r\n",
      "\t\t\t</font></td></tr></table>\r\n",
      "\t\t\r\n",
      "\r\n",
      "\t\r\n",
      "But Jonathan Rees, professor of dermatology at the University of Edinburgh said it was unlikely blondes would die out completely. \r\n",
      "<P>\r\n",
      "\"Genes don't die out unless there is a disadvantage of having that gene or by chance. They don't disappear,\" he told BBC News Online.\r\n",
      "<P>\r\n",
      "\"The only reason blondes would disappear is if having the gene was a disadvantage and I do not think that is the case. \r\n",
      "<P>\r\n",
      "\"The frequency of blondes may drop but they won't disappear.\"\r\n",
      "<P>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "</div>\r\n",
      "\t</font>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "</td>\r\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\r\n",
      "<td valign=\"TOP\"><font face=\"sans-serif\" size=\"2\">\r\n",
      "\t\r\n",
      "\t\r\n",
      "\r\n",
      "\t\r\n",
      "        \r\n",
      "\t<div class=\"rhslist\"><div class=\"rhshead\"><b>See also:</b><br><img src=\"/shared/img/999999.gif\" width=\"170\" vspace=\"2\" height=\"1\" alt=\"\"><br></div>\r\n",
      "\t\r\n",
      "\t\t<div class=\"aitem\">\r\n",
      "\t\t\t<span class=\"seealsodate\">28 Mar 01&nbsp;|&nbsp;Education</span>\r\n",
      "                        <div><a href=\"/2/hi/uk_news/education/1248103.stm\"><span>What is it about blondes?</span></a><br></div>\r\n",
      "\r\n",
      "\t\t</div>\r\n",
      "\t\r\n",
      "\t\t<div class=\"aitem\">\r\n",
      "\t\t\t<span class=\"seealsodate\">09 Apr 99&nbsp;|&nbsp;Health</span>\r\n",
      "                        <div><a href=\"/2/hi/health/315527.stm\"><span>Platinum blondes are labelled as dumb</span></a><br></div>\r\n",
      "\r\n",
      "\t\t</div>\r\n",
      "\t\r\n",
      "\t\t<div class=\"aitem\">\r\n",
      "\t\t\t<span class=\"seealsodate\">17 Apr 02&nbsp;|&nbsp;Health</span>\r\n",
      "                        <div><a href=\"/2/hi/health/1934496.stm\"><span>Hair dye cancer alert</span></a><br></div>\r\n",
      "\r\n",
      "\t\t</div>\r\n",
      "\t\r\n",
      "\t</div>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\t\r\n",
      "<div class=\"rhslist\">\r\n",
      "<div class=\"rhshead\"><b>Internet links:</b><br><img src=\"/shared/img/999999.gif\" width=\"170\" vspace=\"2\" height=\"1\" alt=\"\"><br></div>\r\n",
      "<div class=\"aitem\"><a href=\"http://www.ed.ac.uk/\">University of Edinburgh</a></div>\r\n",
      "<span class=\"disclaimer\"><br>The BBC is not responsible for the content of external internet sites</span><br>\r\n",
      "</div>\r\n",
      "\r\n",
      "\t\r\n",
      "            \r\n",
      "    \r\n",
      "<div class=\"rhslist\">\r\n",
      "\t<div class=\"rhshead\"><b>Top Health stories now:</b><br><img src=\"/shared/img/999999.gif\" width=\"170\" vspace=\"2\" height=\"1\" alt=\"\"><br></div>\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2770999.stm\"><span>Heart risk link to big families</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2761469.stm\"><span>Back pain drug 'may aid diabetics'</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/africa/2776719.stm\"><span>Congo Ebola outbreak confirmed</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2772499.stm\"><span>Vegetables ward off Alzheimer's</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/middle_east/2774951.stm\"><span>Polio campaign launched in Iraq</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2760843.stm\"><span>Gene defect explains high blood pressure</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2772263.stm\"><span>Botox 'may cause new wrinkles'</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/in_depth/sci_tech/2003/denver_2003/2769875.stm\"><span>Alien 'abductees' show real symptoms</span></a><br></div>\r\n",
      "\r\n",
      "\t\r\n",
      "</div>\r\n",
      "<img src=\"/shared/img/999999.gif\" width=\"170\" height=\"1\" border=\"0\" alt=\"\">\r\n",
      "<div class=\"promotextbold\">Links to more Health stories are at the foot of the page.<br><img src=\"/shared/img/999999.gif\" width=\"170\" height=\"1\" border=\"0\" vspace=\"4\" alt=\"\"><br>\r\n",
      "</div>\r\n",
      "\r\n",
      "\r\n",
      "    \r\n",
      "    \r\n",
      "\r\n",
      "\t\r\n",
      "</font></td>\r\n",
      "</tr>\r\n",
      "</table>\r\n",
      "<br>\r\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\r\n",
      "<tr>\r\n",
      "  <td width=\"115\"><img src=\"/shared/img/o.gif\" width=\"105\" height=\"1\" border=\"0\" alt=\"\"></td>\r\n",
      "  <td width=\"315\"><img border=\"0\" alt=\"\" src=\"/shared/img/999999.gif\" width=\"315\" height=\"1\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "  <td width=\"115\" height=\"18\"><img src=\"/shared/img/o.gif\" width=\"115\" height=\"1\" border=\"0\" alt=\"\"></td>\r\n",
      "  <td width=\"315\" align=\"left\"><a onClick=\"window.open('http://newsvote.bbc.co.uk/cgi-bin/emailthisstory/emailthisstory.pl','Mailer','status=no,scrollbars=yes,resizable=yes,width=370,height=445');\" href=\"http://newsvote.bbc.co.uk/cgi-bin/emailthisstory/emailthisstory.pl\" class=\"index\" target=\"Mailer\"><img border=\"0\" alt=\"\" src=\"/sol/shared/img/mail_icon.gif\" width=\"13\" height=\"9\"> <span class=\"blueText\"><b>E-mail this story to a friend</b></span></td>\r\n",
      "</tr>\r\n",
      "</table>\r\n",
      "\r\n",
      "    <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\r\n",
      "  <tr>\r\n",
      "    <td width=\"115\"><img src=\"/shared/img/o.gif\" width=\"115\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td width=\"315\"><img border=\"0\" alt=\"\" src=\"/shared/img/999999.gif\" width=\"315\" height=\"1\"></td>\r\n",
      "  </tr>\r\n",
      "  <tr>\r\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"115\" height=\"1\" alt=\"\"></td>\r\n",
      "    <td align=\"left\">\r\n",
      "\r\n",
      "<br clear=\"all\">\r\n",
      "<font size=\"2\">\r\n",
      " <span class=\"blackText\">\r\n",
      "<b>Links to more Health stories</b></span>\r\n",
      "<br>\r\n",
      "<form name=\"storyMenu\">\r\n",
      "<select name=\"storyLink\">\r\n",
      "<option value=\"#\">In This Section</option>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2770999.stm\">Heart risk link to big families</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2761469.stm\">Back pain drug 'may aid diabetics'</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/africa/2776719.stm\">Congo Ebola outbreak confirmed</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2772499.stm\">Vegetables ward off Alzheimer's</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/middle_east/2774951.stm\">Polio campaign launched in Iraq</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2760843.stm\">Gene defect explains high blood pressure</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2772263.stm\">Botox 'may cause new wrinkles'</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/in_depth/sci_tech/2003/denver_2003/2769875.stm\">Alien 'abductees' show real symptoms</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2760623.stm\">How sperm wriggle</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/south_asia/2770437.stm\">Bollywood told to stub it out</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2772005.stm\">Fears over tuna health risk to babies</OPTION>\r\n",
      "\r\n",
      "        <OPTION value=\"/2/hi/health/2758249.stm\">Public can be taught to spot strokes</OPTION>\r\n",
      "\r\n",
      "</select>\r\n",
      "<INPUT VALUE=\"Go\" TYPE=\"BUTTON\" onClick=\"window.location = document.storyMenu.storyLink.options[document.storyMenu.storyLink.options.selectedIndex].value\">\r\n",
      "</form>\r\n",
      "</font>\r\n",
      "\r\n",
      "</td>\r\n",
      "  </tr>\r\n",
      "</table>\r\n",
      "\r\n",
      "    \r\n",
      "    \r\n",
      "\r\n",
      "<br clear=\"ALL\">\r\n",
      "<table width=\"610\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\r\n",
      "<tr>\r\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"100\" height=\"1\"></td>\r\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"10\" height=\"1\"></td>\r\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"500\" height=\"1\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td colspan=\"3\"><img vspace=\"4\" alt=\"\" src=\"/shared/img/000000.gif\" width=\"610\" height=\"1\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td align=\"right\" valign=\"top\"><a href=\"/2/shared/bsp/hi/services/copyright/html/default.stm\"><img src=\"/nol/shared/img/specials_nav/copyright_bbc.gif\" alt=\"&copy; BBC\" border=\"0\"></a></td>\r\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"10\" height=\"1\"></td>\r\n",
      "<td>\r\n",
      "<font size=\"2\">\r\n",
      "<span class=\"footerarrow\">^^  </span>\r\n",
      "<span class=\"footer\"><a href=\"#top\">Back to top</a>\r\n",
      "<p>\r\n",
      "\r\n",
      "    <table width=\"500\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\r\n",
      "<tr>\r\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"500\" height=\"1\"></td>\r\n",
      "</tr>\r\n",
      "<tr>\r\n",
      "<td><b class=\"footer\"><span class=\"footerpiping\">\r\n",
      "<a href=\"/2/hi/default.stm\" class=\"index\">News Front Page</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/africa/default.stm\" class=\"index\">Africa</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/americas/default.stm\" class=\"index\">Americas</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/asia-pacific/default.stm\" class=\"index\">Asia-Pacific</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/europe/default.stm\" class=\"index\">Europe</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/middle_east/default.stm\" class=\"index\">Middle East</a>\r\n",
      " | \r\n",
      "<br>\r\n",
      "\r\n",
      "<a href=\"/2/hi/south_asia/default.stm\" class=\"index\">South Asia</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/uk_news/default.stm\" class=\"index\">UK</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/business/default.stm\" class=\"index\">Business</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/entertainment/default.stm\" class=\"index\">Entertainment</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/science/nature/default.stm\" class=\"index\">Science/Nature</a>\r\n",
      " | \r\n",
      "<br>\r\n",
      "\r\n",
      "<a href=\"/2/hi/technology/default.stm\" class=\"index\">Technology</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/health/default.stm\" class=\"index\">Health</a>\r\n",
      " | \r\n",
      "\r\n",
      "\r\n",
      "<a href=\"/2/hi/talking_point/default.stm\" class=\"index\">Talking Point</a>\r\n",
      " | \r\n",
      "\r\n",
      "<a href=\"/2/shared/bsp/hi/country_profiles/html/default.stm\" class=\"index\">Country Profiles</a>\r\n",
      "\r\n",
      " | \r\n",
      "\r\n",
      "<a href=\"/2/shared/bsp/hi/in_depth/html/default.stm\" class=\"index\">In Depth</a>\r\n",
      "\r\n",
      " | \r\n",
      "<br>\r\n",
      "\r\n",
      "<a href=\"/2/hi/programmes/default.stm\" class=\"index\">Programmes</a>\r\n",
      "\r\n",
      "\r\n",
      "</span></b></td>\r\n",
      "</tr>\r\n",
      "</table>\r\n",
      "    \r\n",
      "    \r\n",
      "</span></font></td>\r\n",
      "</tr>\r\n",
      "</table>\r\n",
      "    <table width=\"610\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\r\n",
      "    <tr>\r\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"110\" height=\"1\" alt=\"\"></td>\r\n",
      "    <!-- black line row -->\r\n",
      "    <td class=\"footer\" align=\"left\" valign=\"top\" width=\"600\" bgcolor=\"#FFFFFF\"><b><span style=\"color : #999999;\">----------------------------------------------------------------------------------\r\n",
      "</span>\r\n",
      "    <br>\r\n",
      "    <a class=\"index\" href=\"/sport2/\">To BBC Sport&gt;&gt;\r\n",
      "</a> <span style=\"color : #999999;\">|\r\n",
      "</span> <a class=\"index\" href=\"http://www.bbc.co.uk/weather/\">To BBC Weather&gt;&gt;\r\n",
      "</a> <span style=\"color : #999999;\">|\r\n",
      "</span> <a class=\"index\" href=\"http://www.bbc.co.uk/worldservice/index.shtml\">To BBC World Service&gt;&gt;\r\n",
      "</a>\r\n",
      "    <br>\r\n",
      "    <b><span style=\"color : #999999;\">----------------------------------------------------------------------------------\r\n",
      "</span>\r\n",
      "    <br>\r\n",
      "    <a class=\"footer\" href=\"/2/shared/bsp/hi/services/copyright/html/default.stm\"><span style=\"font-size : 10px\">&copy; MMIII\r\n",
      "</span></a> <font size=\"1\">|\r\n",
      "</font> <a class=\"footer\" href=\"/2/shared/bsp/hi/services/help/html/sources.stm\"><span style=\"font-size : 10px\">News Sources\r\n",
      "</span></a> <font size=\"1\">|\r\n",
      "</font> <a class=\"footer\" href=\"http://www.bbc.co.uk/privacy/\"><span style=\"font-size : 10px\">Privacy\r\n",
      "</span></a></b>\r\n",
      "    <br><br><br>\r\n",
      "    </td>\r\n",
      "    </tr>\r\n",
      "    </table>\r\n",
      "<!-- START RedMeasure V4 - Java v1.1  $Revision: 1.9 $ -->\r\n",
      "<!-- COPYRIGHT 2000 Red Sheriff Limited -->\r\n",
      "\r\n",
      "<script language=\"JavaScript\"><!--\r\n",
      "var pCid=\"uk_bbc_0\";\r\n",
      "var w0=1;\r\n",
      "var refR=escape(document.referrer);\r\n",
      "if (refR.length>=252) refR=refR.substring(0,252)+\"...\";\r\n",
      "//--></script>\r\n",
      "<script language=\"JavaScript1.1\"><!--\r\n",
      "var w0=0;\r\n",
      "//--></script>\r\n",
      "<script language=\"JavaScript1.1\" src=\"http://server-uk.imrworldwide.com/a1.js\">\r\n",
      "</script>\r\n",
      "<script language=\"JavaScript\"><!--\r\n",
      "if(w0){\r\n",
      "var imgN='<img src=\"http://server-uk.imrworldwide.com/cgi-bin/count?ref='+\r\n",
      "\trefR+'&cid='+pCid+'\" width=1 height=1>';\r\n",
      "if(navigator.userAgent.indexOf('Mac')!=-1){document.write(imgN);\r\n",
      "}else{\r\n",
      "\tdocument.write('<applet code=\"Measure.class\" '+\r\n",
      "\t'codebase=\"http://server-uk.imrworldwide.com/\"'+'width=1 height=2>'+\r\n",
      "\t'<param name=\"ref\" value=\"'+refR+'\">'+'<param name=\"cid\" value=\"'+pCid+\r\n",
      "\t'\"><textflow>'+imgN+'</textflow></applet>');\r\n",
      "\t}\r\n",
      "}\r\n",
      "document.write(\"<COMMENT>\");\r\n",
      "//-->\r\n",
      "</script>\r\n",
      "<noscript>\r\n",
      "<img src=\"http://server-uk.imrworldwide.com/cgi-bin/count?cid=uk_bbc_0\" width=1 height=1>\r\n",
      "</noscript>\r\n",
      "</COMMENT>\r\n",
      "\r\n",
      "<!-- END RedMeasure V4 -->\r\n",
      "\r\n",
      "<script>\r\n",
      "\tvar si = document.location+\"\";\r\n",
      "\tvar tsi = si.replace(\".stm\",\"\").substr(si.length-11, si.length);\r\n",
      "\tif (!tsi.match(/\\d\\d\\d\\d\\d\\d\\d/)) {tsi = 0;}\r\n",
      "\tdocument.write('<img src=\"http://stats.bbc.co.uk/o.gif?~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~' + tsi + '~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~(none)~RS~a~RS~International~RS~q~RS~~RS~z~RS~18~RS~\">');\r\n",
      "</script>\r\n",
      "<noscript>\r\n",
      "\t<img src=\"http://stats.bbc.co.uk/o.gif?~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~0~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~(none)~RS~a~RS~International~RS~q~RS~~RS~z~RS~18~RS~\">\r\n",
      "</noscript>\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "<br>\r\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"/nol/shared/stylesheets/uki_globalstylesheet.css\">\r\n",
      "\r\n",
      "</body>\r\n",
      "</html>\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get text out of HTML we will use a Python library called BeautifulSoup, available from http://www.crummy.com/software/BeautifulSoup/:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BBC',\n",
       " 'NEWS',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'NEWS',\n",
       " 'SPORT',\n",
       " 'WEATHER',\n",
       " 'WORLD',\n",
       " 'SERVICE',\n",
       " 'A-Z',\n",
       " 'INDEX',\n",
       " 'SEARCH',\n",
       " 'You',\n",
       " 'are',\n",
       " 'in',\n",
       " ':',\n",
       " 'Health',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " 'Africa',\n",
       " 'Americas',\n",
       " 'Asia-Pacific',\n",
       " 'Europe',\n",
       " 'Middle',\n",
       " 'East',\n",
       " 'South',\n",
       " 'Asia',\n",
       " 'UK',\n",
       " 'Business',\n",
       " 'Entertainment',\n",
       " 'Science/Nature',\n",
       " 'Technology',\n",
       " 'Health',\n",
       " 'Medical',\n",
       " 'notes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'SERVICES',\n",
       " 'Daily',\n",
       " 'E-mail',\n",
       " 'News',\n",
       " 'Ticker',\n",
       " 'Mobile/PDAs',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " 'Text',\n",
       " 'Only',\n",
       " 'Feedback',\n",
       " 'Help',\n",
       " 'EDITIONS',\n",
       " 'Change',\n",
       " 'to',\n",
       " 'UK',\n",
       " 'Friday',\n",
       " ',',\n",
       " '27',\n",
       " 'September',\n",
       " ',',\n",
       " '2002',\n",
       " ',',\n",
       " '11:51',\n",
       " 'GMT',\n",
       " '12:51',\n",
       " 'UK',\n",
       " 'Blondes',\n",
       " \"'to\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'in',\n",
       " '200',\n",
       " \"years'\",\n",
       " 'Scientists',\n",
       " 'believe',\n",
       " 'the',\n",
       " 'last',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'in',\n",
       " 'Finland',\n",
       " 'The',\n",
       " 'last',\n",
       " 'natural',\n",
       " 'blondes',\n",
       " 'will',\n",
       " 'die',\n",
       " 'out',\n",
       " 'within',\n",
       " '200',\n",
       " 'years',\n",
       " ',',\n",
       " 'scientists',\n",
       " 'believe',\n",
       " '.',\n",
       " 'A',\n",
       " 'study',\n",
       " 'by',\n",
       " 'experts',\n",
       " 'in',\n",
       " 'Germany',\n",
       " 'suggests',\n",
       " 'people',\n",
       " 'with',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'are',\n",
       " 'an',\n",
       " 'endangered',\n",
       " 'species',\n",
       " 'and',\n",
       " 'will',\n",
       " 'become',\n",
       " 'extinct',\n",
       " 'by',\n",
       " '2202',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'predict',\n",
       " 'the',\n",
       " 'last',\n",
       " 'truly',\n",
       " 'natural',\n",
       " 'blonde',\n",
       " 'will',\n",
       " 'be',\n",
       " 'born',\n",
       " 'in',\n",
       " 'Finland',\n",
       " '-',\n",
       " 'the',\n",
       " 'country',\n",
       " 'with',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'proportion',\n",
       " 'of',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " 'Prof',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'But',\n",
       " 'they',\n",
       " 'say',\n",
       " 'too',\n",
       " 'few',\n",
       " 'people',\n",
       " 'now',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'for',\n",
       " 'blondes',\n",
       " 'to',\n",
       " 'last',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'next',\n",
       " 'two',\n",
       " 'centuries',\n",
       " '.',\n",
       " 'The',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'that',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " 'is',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'a',\n",
       " 'recessive',\n",
       " 'gene',\n",
       " '.',\n",
       " 'In',\n",
       " 'order',\n",
       " 'for',\n",
       " 'a',\n",
       " 'child',\n",
       " 'to',\n",
       " 'have',\n",
       " 'blonde',\n",
       " 'hair',\n",
       " ',',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'on',\n",
       " 'both',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'the',\n",
       " 'family',\n",
       " 'in',\n",
       " 'the',\n",
       " 'grandparents',\n",
       " \"'\",\n",
       " 'generation',\n",
       " '.',\n",
       " 'Dyed',\n",
       " 'rivals',\n",
       " 'The',\n",
       " 'researchers',\n",
       " 'also',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'so-called',\n",
       " 'bottle',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'for',\n",
       " 'the',\n",
       " 'demise',\n",
       " 'of',\n",
       " 'their',\n",
       " 'natural',\n",
       " 'rivals',\n",
       " '.',\n",
       " 'They',\n",
       " 'suggest',\n",
       " 'that',\n",
       " 'dyed-blondes',\n",
       " 'are',\n",
       " 'more',\n",
       " 'attractive',\n",
       " 'to',\n",
       " 'men',\n",
       " 'who',\n",
       " 'choose',\n",
       " 'them',\n",
       " 'as',\n",
       " 'partners',\n",
       " 'over',\n",
       " 'true',\n",
       " 'blondes',\n",
       " '.',\n",
       " 'Bottle-blondes',\n",
       " 'like',\n",
       " 'Ann',\n",
       " 'Widdecombe',\n",
       " 'may',\n",
       " 'be',\n",
       " 'to',\n",
       " 'blame',\n",
       " 'But',\n",
       " 'Jonathan',\n",
       " 'Rees',\n",
       " ',',\n",
       " 'professor',\n",
       " 'of',\n",
       " 'dermatology',\n",
       " 'at',\n",
       " 'the',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'said',\n",
       " 'it',\n",
       " 'was',\n",
       " 'unlikely',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'die',\n",
       " 'out',\n",
       " 'completely',\n",
       " '.',\n",
       " '``',\n",
       " 'Genes',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'die',\n",
       " 'out',\n",
       " 'unless',\n",
       " 'there',\n",
       " 'is',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'of',\n",
       " 'having',\n",
       " 'that',\n",
       " 'gene',\n",
       " 'or',\n",
       " 'by',\n",
       " 'chance',\n",
       " '.',\n",
       " 'They',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " ',',\n",
       " \"''\",\n",
       " 'he',\n",
       " 'told',\n",
       " 'BBC',\n",
       " 'News',\n",
       " 'Online',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'only',\n",
       " 'reason',\n",
       " 'blondes',\n",
       " 'would',\n",
       " 'disappear',\n",
       " 'is',\n",
       " 'if',\n",
       " 'having',\n",
       " 'the',\n",
       " 'gene',\n",
       " 'was',\n",
       " 'a',\n",
       " 'disadvantage',\n",
       " 'and',\n",
       " 'I',\n",
       " 'do',\n",
       " 'not',\n",
       " 'think',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'case',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'frequency',\n",
       " 'of',\n",
       " 'blondes',\n",
       " 'may',\n",
       " 'drop',\n",
       " 'but',\n",
       " 'they',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'disappear',\n",
       " '.',\n",
       " \"''\",\n",
       " 'See',\n",
       " 'also',\n",
       " ':',\n",
       " '28',\n",
       " 'Mar',\n",
       " '01',\n",
       " '|',\n",
       " 'Education',\n",
       " 'What',\n",
       " 'is',\n",
       " 'it',\n",
       " 'about',\n",
       " 'blondes',\n",
       " '?',\n",
       " '09',\n",
       " 'Apr',\n",
       " '99',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Platinum',\n",
       " 'blondes',\n",
       " 'are',\n",
       " 'labelled',\n",
       " 'as',\n",
       " 'dumb',\n",
       " '17',\n",
       " 'Apr',\n",
       " '02',\n",
       " '|',\n",
       " 'Health',\n",
       " 'Hair',\n",
       " 'dye',\n",
       " 'cancer',\n",
       " 'alert',\n",
       " 'Internet',\n",
       " 'links',\n",
       " ':',\n",
       " 'University',\n",
       " 'of',\n",
       " 'Edinburgh',\n",
       " 'The',\n",
       " 'BBC',\n",
       " 'is',\n",
       " 'not',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'the',\n",
       " 'content',\n",
       " 'of',\n",
       " 'external',\n",
       " 'internet',\n",
       " 'sites',\n",
       " 'Top',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'now',\n",
       " ':',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'are',\n",
       " 'at',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'the',\n",
       " 'page',\n",
       " '.',\n",
       " 'E-mail',\n",
       " 'this',\n",
       " 'story',\n",
       " 'to',\n",
       " 'a',\n",
       " 'friend',\n",
       " 'Links',\n",
       " 'to',\n",
       " 'more',\n",
       " 'Health',\n",
       " 'stories',\n",
       " 'In',\n",
       " 'This',\n",
       " 'Section',\n",
       " 'Heart',\n",
       " 'risk',\n",
       " 'link',\n",
       " 'to',\n",
       " 'big',\n",
       " 'families',\n",
       " 'Back',\n",
       " 'pain',\n",
       " 'drug',\n",
       " \"'may\",\n",
       " 'aid',\n",
       " \"diabetics'\",\n",
       " 'Congo',\n",
       " 'Ebola',\n",
       " 'outbreak',\n",
       " 'confirmed',\n",
       " 'Vegetables',\n",
       " 'ward',\n",
       " 'off',\n",
       " \"Alzheimer's\",\n",
       " 'Polio',\n",
       " 'campaign',\n",
       " 'launched',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'Gene',\n",
       " 'defect',\n",
       " 'explains',\n",
       " 'high',\n",
       " 'blood',\n",
       " 'pressure',\n",
       " 'Botox',\n",
       " \"'may\",\n",
       " 'cause',\n",
       " 'new',\n",
       " \"wrinkles'\",\n",
       " 'Alien',\n",
       " \"'abductees\",\n",
       " \"'\",\n",
       " 'show',\n",
       " 'real',\n",
       " 'symptoms',\n",
       " 'How',\n",
       " 'sperm',\n",
       " 'wriggle',\n",
       " 'Bollywood',\n",
       " 'told',\n",
       " 'to',\n",
       " 'stub',\n",
       " 'it',\n",
       " 'out',\n",
       " 'Fears',\n",
       " 'over',\n",
       " 'tuna',\n",
       " 'health',\n",
       " 'risk',\n",
       " 'to',\n",
       " 'babies',\n",
       " 'Public',\n",
       " 'can',\n",
       " 'be',\n",
       " 'taught',\n",
       " 'to',\n",
       " 'spot',\n",
       " 'strokes',\n",
       " '^^',\n",
       " 'Back',\n",
       " 'to',\n",
       " 'top',\n",
       " 'News',\n",
       " 'Front',\n",
       " 'Page',\n",
       " '|',\n",
       " 'Africa',\n",
       " '|',\n",
       " 'Americas',\n",
       " '|',\n",
       " 'Asia-Pacific',\n",
       " '|',\n",
       " 'Europe',\n",
       " '|',\n",
       " 'Middle',\n",
       " 'East',\n",
       " '|',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '|',\n",
       " 'UK',\n",
       " '|',\n",
       " 'Business',\n",
       " '|',\n",
       " 'Entertainment',\n",
       " '|',\n",
       " 'Science/Nature',\n",
       " '|',\n",
       " 'Technology',\n",
       " '|',\n",
       " 'Health',\n",
       " '|',\n",
       " 'Talking',\n",
       " 'Point',\n",
       " '|',\n",
       " 'Country',\n",
       " 'Profiles',\n",
       " '|',\n",
       " 'In',\n",
       " 'Depth',\n",
       " '|',\n",
       " 'Programmes',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Sport',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'Weather',\n",
       " '>',\n",
       " '>',\n",
       " '|',\n",
       " 'To',\n",
       " 'BBC',\n",
       " 'World',\n",
       " 'Service',\n",
       " '>',\n",
       " '>',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '©',\n",
       " 'MMIII',\n",
       " '|',\n",
       " 'News',\n",
       " 'Sources',\n",
       " '|',\n",
       " 'Privacy',\n",
       " '<',\n",
       " '!',\n",
       " '--',\n",
       " 'var',\n",
       " 'pCid=',\n",
       " \"''\",\n",
       " 'uk_bbc_0',\n",
       " \"''\",\n",
       " ';',\n",
       " 'var',\n",
       " 'w0=1',\n",
       " ';',\n",
       " 'var',\n",
       " 'refR=escape',\n",
       " '(',\n",
       " 'document.referrer',\n",
       " ')',\n",
       " ';',\n",
       " 'if',\n",
       " '(',\n",
       " 'refR.length',\n",
       " '>',\n",
       " '=252',\n",
       " ')',\n",
       " 'refR=refR.substring',\n",
       " '(',\n",
       " '0,252',\n",
       " ')',\n",
       " '+',\n",
       " \"''\",\n",
       " '...',\n",
       " \"''\",\n",
       " ';',\n",
       " '//',\n",
       " '--',\n",
       " '>',\n",
       " '<',\n",
       " '!',\n",
       " '--',\n",
       " 'var',\n",
       " 'w0=0',\n",
       " ';',\n",
       " '//',\n",
       " '--',\n",
       " '>',\n",
       " '<',\n",
       " '!',\n",
       " '--',\n",
       " 'if',\n",
       " '(',\n",
       " 'w0',\n",
       " ')',\n",
       " '{',\n",
       " 'var',\n",
       " 'imgN=',\n",
       " \"'\",\n",
       " '<',\n",
       " 'img',\n",
       " 'src=',\n",
       " \"''\",\n",
       " 'http',\n",
       " ':',\n",
       " '//server-uk.imrworldwide.com/cgi-bin/count',\n",
       " '?',\n",
       " \"ref='+\",\n",
       " 'refR+',\n",
       " \"'\",\n",
       " '&',\n",
       " \"cid='+pCid+\",\n",
       " \"'\",\n",
       " \"''\",\n",
       " 'width=1',\n",
       " 'height=1',\n",
       " '>',\n",
       " \"'\",\n",
       " ';',\n",
       " 'if',\n",
       " '(',\n",
       " 'navigator.userAgent.indexOf',\n",
       " '(',\n",
       " \"'Mac\",\n",
       " \"'\",\n",
       " ')',\n",
       " '!',\n",
       " '=-1',\n",
       " ')',\n",
       " '{',\n",
       " 'document.write',\n",
       " '(',\n",
       " 'imgN',\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " 'else',\n",
       " '{',\n",
       " 'document.write',\n",
       " '(',\n",
       " \"'\",\n",
       " '<',\n",
       " 'applet',\n",
       " 'code=',\n",
       " \"''\",\n",
       " 'Measure.class',\n",
       " \"''\",\n",
       " \"'+\",\n",
       " \"'codebase=\",\n",
       " \"''\",\n",
       " 'http',\n",
       " ':',\n",
       " '//server-uk.imrworldwide.com/',\n",
       " \"''\",\n",
       " \"'+'width=1\",\n",
       " 'height=2',\n",
       " '>',\n",
       " \"'+\",\n",
       " \"'\",\n",
       " '<',\n",
       " 'param',\n",
       " 'name=',\n",
       " \"''\",\n",
       " 'ref',\n",
       " \"''\",\n",
       " 'value=',\n",
       " \"''\",\n",
       " \"'+refR+\",\n",
       " \"'\",\n",
       " \"''\",\n",
       " '>',\n",
       " \"'+\",\n",
       " \"'\",\n",
       " '<',\n",
       " 'param',\n",
       " 'name=',\n",
       " \"''\",\n",
       " 'cid',\n",
       " \"''\",\n",
       " 'value=',\n",
       " \"''\",\n",
       " \"'+pCid+\",\n",
       " \"'\",\n",
       " \"''\",\n",
       " '>',\n",
       " '<',\n",
       " 'textflow',\n",
       " '>',\n",
       " \"'+imgN+\",\n",
       " \"'\",\n",
       " '<',\n",
       " '/textflow',\n",
       " '>',\n",
       " '<',\n",
       " '/applet',\n",
       " '>',\n",
       " \"'\",\n",
       " ')',\n",
       " ';',\n",
       " '}',\n",
       " '}',\n",
       " 'document.write',\n",
       " '(',\n",
       " '``',\n",
       " '<',\n",
       " 'COMMENT',\n",
       " '>',\n",
       " \"''\",\n",
       " ')',\n",
       " ';',\n",
       " '//',\n",
       " '--',\n",
       " '>',\n",
       " 'var',\n",
       " 'si',\n",
       " '=',\n",
       " 'document.location+',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ';',\n",
       " 'var',\n",
       " 'tsi',\n",
       " '=',\n",
       " 'si.replace',\n",
       " '(',\n",
       " '``',\n",
       " '.stm',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ')',\n",
       " '.substr',\n",
       " '(',\n",
       " 'si.length-11',\n",
       " ',',\n",
       " 'si.length',\n",
       " ')',\n",
       " ';',\n",
       " 'if',\n",
       " '(',\n",
       " '!',\n",
       " 'tsi.match',\n",
       " '(',\n",
       " '/\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d/',\n",
       " ')',\n",
       " ')',\n",
       " '{',\n",
       " 'tsi',\n",
       " '=',\n",
       " '0',\n",
       " ';',\n",
       " '}',\n",
       " 'document.write',\n",
       " '(',\n",
       " \"'\",\n",
       " '<',\n",
       " 'img',\n",
       " 'src=',\n",
       " \"''\",\n",
       " 'http',\n",
       " ':',\n",
       " '//stats.bbc.co.uk/o.gif',\n",
       " '?',\n",
       " '~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~',\n",
       " \"'\",\n",
       " '+',\n",
       " 'tsi',\n",
       " '+',\n",
       " \"'~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~\",\n",
       " '(',\n",
       " 'none',\n",
       " ')',\n",
       " '~RS~a~RS~International~RS~q~RS~~RS~z~RS~18~RS~',\n",
       " \"''\",\n",
       " '>',\n",
       " \"'\",\n",
       " ')',\n",
       " ';']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This still contains unwanted material concerning site navigation and related stories. With some trial and error you can find the start and end indexes of the content and select the tokens of interest, and initialize a text as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokens[110:390]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UK', 'Blondes', \"'to\", 'die', 'out', 'in', '200', \"years'\", 'Scientists', 'believe', 'the', 'last', 'blondes', 'will', 'be', 'in', 'Finland', 'The', 'last', 'natural', 'blondes', 'will', 'die', 'out', 'within', '200', 'years', ',', 'scientists', 'believe', '.', 'A', 'study', 'by', 'experts', 'in', 'Germany', 'suggests', 'people', 'with', 'blonde', 'hair', 'are', 'an', 'endangered', 'species', 'and', 'will', 'become', 'extinct', 'by', '2202', '.', 'Researchers', 'predict', 'the', 'last', 'truly', 'natural', 'blonde', 'will', 'be', 'born', 'in', 'Finland', '-', 'the', 'country', 'with', 'the', 'highest', 'proportion', 'of', 'blondes', '.', 'The', 'frequency', 'of', 'blondes', 'may', 'drop', 'but', 'they', 'wo', \"n't\", 'disappear', 'Prof', 'Jonathan', 'Rees', ',', 'University', 'of', 'Edinburgh', 'But', 'they', 'say', 'too', 'few', 'people', 'now', 'carry', 'the', 'gene', 'for', 'blondes', 'to', 'last', 'beyond', 'the', 'next', 'two', 'centuries', '.', 'The', 'problem', 'is', 'that', 'blonde', 'hair', 'is', 'caused', 'by', 'a', 'recessive', 'gene', '.', 'In', 'order', 'for', 'a', 'child', 'to', 'have', 'blonde', 'hair', ',', 'it', 'must', 'have', 'the', 'gene', 'on', 'both', 'sides', 'of', 'the', 'family', 'in', 'the', 'grandparents', \"'\", 'generation', '.', 'Dyed', 'rivals', 'The', 'researchers', 'also', 'believe', 'that', 'so-called', 'bottle', 'blondes', 'may', 'be', 'to', 'blame', 'for', 'the', 'demise', 'of', 'their', 'natural', 'rivals', '.', 'They', 'suggest', 'that', 'dyed-blondes', 'are', 'more', 'attractive', 'to', 'men', 'who', 'choose', 'them', 'as', 'partners', 'over', 'true', 'blondes', '.', 'Bottle-blondes', 'like', 'Ann', 'Widdecombe', 'may', 'be', 'to', 'blame', 'But', 'Jonathan', 'Rees', ',', 'professor', 'of', 'dermatology', 'at', 'the', 'University', 'of', 'Edinburgh', 'said', 'it', 'was', 'unlikely', 'blondes', 'would', 'die', 'out', 'completely', '.', '``', 'Genes', 'do', \"n't\", 'die', 'out', 'unless', 'there', 'is', 'a', 'disadvantage', 'of', 'having', 'that', 'gene', 'or', 'by', 'chance', '.', 'They', 'do', \"n't\", 'disappear', ',', \"''\", 'he', 'told', 'BBC', 'News', 'Online', '.', '``', 'The', 'only', 'reason', 'blondes', 'would', 'disappear', 'is', 'if', 'having', 'the', 'gene', 'was', 'a', 'disadvantage', 'and', 'I', 'do', 'not', 'think', 'that', 'is', 'the', 'case', '.', '``']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we now take the further step of creating an NLTK text from this list, we can carry out all of the other linguistic processing we saw in Chapter 1., along with the regular list operations like slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "text.concordance('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Try to retreive some text from any web page in the form of HTML documents by using the above code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Wiki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = request.urlopen(url).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = BeautifulSoup(html, 'html.parser').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wiki',\n",
       " '-',\n",
       " 'Wikipedia',\n",
       " 'document.documentElement.className=',\n",
       " \"''\",\n",
       " 'client-js',\n",
       " \"''\",\n",
       " ';',\n",
       " 'RLCONF=',\n",
       " '{',\n",
       " '``',\n",
       " 'wgBreakFrames',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgSeparatorTransformTable',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgDigitTransformTable',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgDefaultDateFormat',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'dmy',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgMonthNames',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'January',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'February',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'March',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'April',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'May',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'June',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'July',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'August',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'September',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'October',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'November',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'December',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRequestId',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " '5cc695b1-a631-4797-9c55-8806dd93497a',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgCSPNonce',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgCanonicalNamespace',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgCanonicalSpecialPageName',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgNamespaceNumber',\n",
       " \"''\",\n",
       " ':0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPageName',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'Wiki',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgTitle',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'Wiki',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgCurRevisionId',\n",
       " \"''\",\n",
       " ':978135799',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRevisionId',\n",
       " \"''\",\n",
       " ':978135799',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgArticleId',\n",
       " \"''\",\n",
       " ':32851',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgIsArticle',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgIsRedirect',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgAction',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'view',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgUserName',\n",
       " \"''\",\n",
       " ':',\n",
       " 'null',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgUserGroups',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " '*',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgCategories',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " 'CS1',\n",
       " 'maint',\n",
       " ':',\n",
       " 'archived',\n",
       " 'copy',\n",
       " 'as',\n",
       " 'title',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'CS1',\n",
       " 'errors',\n",
       " ':',\n",
       " 'missing',\n",
       " 'periodical',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Pages',\n",
       " 'containing',\n",
       " 'links',\n",
       " 'to',\n",
       " 'subscription-only',\n",
       " 'content',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Webarchive',\n",
       " 'template',\n",
       " 'wayback',\n",
       " 'links',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Pages',\n",
       " 'with',\n",
       " 'citations',\n",
       " 'lacking',\n",
       " 'titles',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'CS1',\n",
       " ':',\n",
       " 'long',\n",
       " 'volume',\n",
       " 'value',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'indefinitely',\n",
       " 'semi-protected',\n",
       " 'pages',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'indefinitely',\n",
       " 'move-protected',\n",
       " 'pages',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'short',\n",
       " 'description',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Short',\n",
       " 'description',\n",
       " 'matches',\n",
       " 'Wikidata',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Use',\n",
       " 'mdy',\n",
       " 'dates',\n",
       " 'from',\n",
       " 'July',\n",
       " '2019',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'hAudio',\n",
       " 'microformats',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Pages',\n",
       " 'including',\n",
       " 'recorded',\n",
       " 'pronunciations',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'needing',\n",
       " 'additional',\n",
       " 'references',\n",
       " 'from',\n",
       " 'March',\n",
       " '2017',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'articles',\n",
       " 'needing',\n",
       " 'additional',\n",
       " 'references',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'articles',\n",
       " 'needing',\n",
       " 'examples',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'needing',\n",
       " 'examples',\n",
       " 'from',\n",
       " 'August',\n",
       " '2018',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'articles',\n",
       " 'with',\n",
       " 'unsourced',\n",
       " 'statements',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'unsourced',\n",
       " 'statements',\n",
       " 'from',\n",
       " 'July',\n",
       " '2013',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'unsourced',\n",
       " 'statements',\n",
       " 'from',\n",
       " 'April',\n",
       " '2020',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'articles',\n",
       " 'lacking',\n",
       " 'reliable',\n",
       " 'references',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'lacking',\n",
       " 'reliable',\n",
       " 'references',\n",
       " 'from',\n",
       " 'July',\n",
       " '2013',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'in',\n",
       " 'need',\n",
       " 'of',\n",
       " 'updating',\n",
       " 'from',\n",
       " 'July',\n",
       " '2013',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'in',\n",
       " 'need',\n",
       " 'of',\n",
       " 'updating',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Spoken',\n",
       " 'articles',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'Curlie',\n",
       " 'links',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'with',\n",
       " 'GND',\n",
       " 'identifiers',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'with',\n",
       " 'LCCN',\n",
       " 'identifiers',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'containing',\n",
       " 'video',\n",
       " 'clips',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikis',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Hawaiian',\n",
       " 'words',\n",
       " 'and',\n",
       " 'phrases',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Hypertext',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Self-organization',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Social',\n",
       " 'information',\n",
       " 'processing',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPageContentLanguage',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'en',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPageContentModel',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'wikitext',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRelevantPageName',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'Wiki',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRelevantArticleId',\n",
       " \"''\",\n",
       " ':32851',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgIsProbablyEditable',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRelevantPageIsProbablyEditable',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRestrictionEdit',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " 'autoconfirmed',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRestrictionMove',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " 'sysop',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgMediaViewerOnClick',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgMediaViewerEnabledByDefault',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPopupsReferencePreviews',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPopupsConflictsWithNavPopupGadget',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgVisualEditor',\n",
       " \"''\",\n",
       " ':',\n",
       " '{',\n",
       " '``',\n",
       " 'pageLanguageCode',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'en',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'pageLanguageDir',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ltr',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'pageVariantFallbacks',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'en',\n",
       " \"''\",\n",
       " '}',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgMFDisplayWikibaseDescriptions',\n",
       " \"''\",\n",
       " ':',\n",
       " '{',\n",
       " '``',\n",
       " 'search',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'nearby',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'watchlist',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'tagline',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " '}',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgWMESchemaEditAttemptStepOversample',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgULSCurrentAutonym',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'English',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgNoticeProject',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'wikipedia',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgCentralAuthMobileDomain',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgEditSubmitButtonLabelPublish',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgULSPosition',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'interlanguage',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgWikibaseItemId',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'Q171',\n",
       " \"''\",\n",
       " '}',\n",
       " ';',\n",
       " 'RLSTATE=',\n",
       " '{',\n",
       " '``',\n",
       " 'ext.globalCssJs.user.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'site.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'noscript',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'user.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.globalCssJs.user',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'user',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'user.options',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'loading',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.cite.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.pygments',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.tmh.thumbnail.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'skins.vector.styles.legacy',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'jquery.makeCollapsible.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mediawiki.toc.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.visualEditor.desktopArticleTarget.noscript',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.uls.interlanguage',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.wikimediaBadges',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wikibase.client.init',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready',\n",
       " \"''\",\n",
       " '}',\n",
       " ';',\n",
       " 'RLPAGEMODULES=',\n",
       " '[',\n",
       " '``',\n",
       " 'ext.cite.ux-enhancements',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mw.MediaWikiPlayer.loader',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mw.PopUpMediaTransform',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mw.TMHGalleryHook.js',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.scribunto.logs',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'site',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mediawiki.page.ready',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'jquery.makeCollapsible',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mediawiki.toc',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'skins.vector.legacy.js',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.gadget.ReferenceTooltips',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.gadget.charinsert',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.gadget.extra-toolbar-buttons',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.gadget.refToolbar',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.gadget.switcher',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.centralauth.centralautologin',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mmv.head',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'mmv.bootstrap.autostart',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.popups',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.visualEditor.desktopArticleTarget.init',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.visualEditor.targetLoader',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.eventLogging',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.wikimediaEvents',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.navigationTiming',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.uls.compactlinks',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.uls.interface',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.cx.eventlogging.campaigns',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.quicksurveys.init',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.centralNotice.geoIP',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'ext.centralNotice.startUp',\n",
       " \"''\",\n",
       " ']',\n",
       " ';',\n",
       " '(',\n",
       " 'RLQ=window.RLQ||',\n",
       " '[',\n",
       " ']',\n",
       " ')',\n",
       " '.push',\n",
       " '(',\n",
       " 'function',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " 'mw.loader.implement',\n",
       " '(',\n",
       " '``',\n",
       " 'user.options',\n",
       " '@',\n",
       " '1hzgi',\n",
       " \"''\",\n",
       " ',',\n",
       " 'function',\n",
       " '(',\n",
       " '$',\n",
       " ',',\n",
       " 'jQuery',\n",
       " ',',\n",
       " 'require',\n",
       " ',',\n",
       " 'module',\n",
       " ')',\n",
       " '{',\n",
       " '/*',\n",
       " '@',\n",
       " 'nomin*/mw.user.tokens.set',\n",
       " '(',\n",
       " '{',\n",
       " '``',\n",
       " 'patrolToken',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " '+\\\\\\\\',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'watchToken',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " '+\\\\\\\\',\n",
       " \"''\",\n",
       " ',',\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = tokens.index(\"articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = tokens.index(\"ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokens[327:695]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articles',\n",
       " 'needing',\n",
       " 'additional',\n",
       " 'references',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'articles',\n",
       " 'needing',\n",
       " 'examples',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'needing',\n",
       " 'examples',\n",
       " 'from',\n",
       " 'August',\n",
       " '2018',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'articles',\n",
       " 'with',\n",
       " 'unsourced',\n",
       " 'statements',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'unsourced',\n",
       " 'statements',\n",
       " 'from',\n",
       " 'July',\n",
       " '2013',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'unsourced',\n",
       " 'statements',\n",
       " 'from',\n",
       " 'April',\n",
       " '2020',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'articles',\n",
       " 'lacking',\n",
       " 'reliable',\n",
       " 'references',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'lacking',\n",
       " 'reliable',\n",
       " 'references',\n",
       " 'from',\n",
       " 'July',\n",
       " '2013',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'in',\n",
       " 'need',\n",
       " 'of',\n",
       " 'updating',\n",
       " 'from',\n",
       " 'July',\n",
       " '2013',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'All',\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'in',\n",
       " 'need',\n",
       " 'of',\n",
       " 'updating',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Spoken',\n",
       " 'articles',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'with',\n",
       " 'Curlie',\n",
       " 'links',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'with',\n",
       " 'GND',\n",
       " 'identifiers',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikipedia',\n",
       " 'articles',\n",
       " 'with',\n",
       " 'LCCN',\n",
       " 'identifiers',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Articles',\n",
       " 'containing',\n",
       " 'video',\n",
       " 'clips',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Wikis',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Hawaiian',\n",
       " 'words',\n",
       " 'and',\n",
       " 'phrases',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Hypertext',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Self-organization',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'Social',\n",
       " 'information',\n",
       " 'processing',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPageContentLanguage',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'en',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPageContentModel',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'wikitext',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRelevantPageName',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'Wiki',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRelevantArticleId',\n",
       " \"''\",\n",
       " ':32851',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgIsProbablyEditable',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRelevantPageIsProbablyEditable',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRestrictionEdit',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " 'autoconfirmed',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgRestrictionMove',\n",
       " \"''\",\n",
       " ':',\n",
       " '[',\n",
       " '``',\n",
       " 'sysop',\n",
       " \"''\",\n",
       " ']',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgMediaViewerOnClick',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgMediaViewerEnabledByDefault',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPopupsReferencePreviews',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgPopupsConflictsWithNavPopupGadget',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgVisualEditor',\n",
       " \"''\",\n",
       " ':',\n",
       " '{',\n",
       " '``',\n",
       " 'pageLanguageCode',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'en',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'pageLanguageDir',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ltr',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'pageVariantFallbacks',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'en',\n",
       " \"''\",\n",
       " '}',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgMFDisplayWikibaseDescriptions',\n",
       " \"''\",\n",
       " ':',\n",
       " '{',\n",
       " '``',\n",
       " 'search',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'nearby',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'watchlist',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'tagline',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " '}',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgWMESchemaEditAttemptStepOversample',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgULSCurrentAutonym',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'English',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgNoticeProject',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'wikipedia',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgCentralAuthMobileDomain',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '1',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgEditSubmitButtonLabelPublish',\n",
       " \"''\",\n",
       " ':',\n",
       " '!',\n",
       " '0',\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgULSPosition',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'interlanguage',\n",
       " \"''\",\n",
       " ',',\n",
       " \"''\",\n",
       " 'wgWikibaseItemId',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'Q171',\n",
       " \"''\",\n",
       " '}',\n",
       " ';',\n",
       " 'RLSTATE=',\n",
       " '{',\n",
       " '``',\n",
       " 'ext.globalCssJs.user.styles',\n",
       " \"''\",\n",
       " ':',\n",
       " \"''\",\n",
       " 'ready']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Local Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to read a local file, we need to use Python's built-in open() function, followed by the read() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose you have a file document.txt, you can load its contents like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('document.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The read() method creates a string with the contents of the entire file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time flies like an arrow.\\nFruit flies like a banana.\\nWhat are you doing?\\nWhy are you late?\\nWhich is the best one?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall that the '\\n' characters are newlines; this is equivalent to pressing Enter on a keyboard and starting a new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the strip() method to remove the newline character at the end of the input line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time flies like an arrow.\n",
      "Fruit flies like a banana.\n",
      "What are you doing?\n",
      "Why are you late?\n",
      "Which is the best one?\n"
     ]
    }
   ],
   "source": [
    "f=open('document.txt')\n",
    "for line in f:\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK's corpus files can also be accessed using these methods. We simply have to use nltk.data.find() to get the filename for any corpus item. Then we can open and read it in the way we just demonstrated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(path).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1220066"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar', 'School', ')', 'The', 'pale', 'Usher', '--', 'threadbare', 'in', 'coat', ',']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturig User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes we want to capture the text that a user inputs when she is interacting with our program. To prompt the user to type a line of input, call the Python function input(). After saving the input to a variable, we can manipulate it just as we have done for other strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text: How are you doing?\n"
     ]
    }
   ],
   "source": [
    "s = input(\"Enter some text: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You typed 5 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"You typed\", len(word_tokenize(s)), \"words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The NLP Pipeline (See Slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we tokenize a string we produce a list (of words), and this is Python's <list> type. Normalizing and sorting lists produces other lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw=open('document.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Time',\n",
       " 'flies',\n",
       " 'like',\n",
       " 'an',\n",
       " 'arrow',\n",
       " '.',\n",
       " 'Fruit',\n",
       " 'flies',\n",
       " 'like',\n",
       " 'a',\n",
       " 'banana',\n",
       " '.',\n",
       " 'What',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'Why',\n",
       " 'are',\n",
       " 'you',\n",
       " 'late',\n",
       " '?',\n",
       " 'Which',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'one',\n",
       " '?']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    " words = [w.lower() for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'flies',\n",
       " 'like',\n",
       " 'an',\n",
       " 'arrow',\n",
       " '.',\n",
       " 'fruit',\n",
       " 'flies',\n",
       " 'like',\n",
       " 'a',\n",
       " 'banana',\n",
       " '.',\n",
       " 'what',\n",
       " 'are',\n",
       " 'you',\n",
       " 'doing',\n",
       " '?',\n",
       " 'why',\n",
       " 'are',\n",
       " 'you',\n",
       " 'late',\n",
       " '?',\n",
       " 'which',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " 'one',\n",
       " '?']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=sorted(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " '?',\n",
       " 'a',\n",
       " 'an',\n",
       " 'are',\n",
       " 'arrow',\n",
       " 'banana',\n",
       " 'best',\n",
       " 'doing',\n",
       " 'flies',\n",
       " 'fruit',\n",
       " 'is',\n",
       " 'late',\n",
       " 'like',\n",
       " 'one',\n",
       " 'the',\n",
       " 'time',\n",
       " 'what',\n",
       " 'which',\n",
       " 'why',\n",
       " 'you']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The type of an object determines what operations you can perform on it. So, for example, we can append to a list but not to a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.append('blog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " '?',\n",
       " 'a',\n",
       " 'an',\n",
       " 'are',\n",
       " 'arrow',\n",
       " 'banana',\n",
       " 'best',\n",
       " 'doing',\n",
       " 'flies',\n",
       " 'fruit',\n",
       " 'is',\n",
       " 'late',\n",
       " 'like',\n",
       " 'one',\n",
       " 'the',\n",
       " 'time',\n",
       " 'what',\n",
       " 'which',\n",
       " 'why',\n",
       " 'you',\n",
       " 'blog']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Strings: Text Processing at the Lowest Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In earlier chapters we focused on a text as a list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We didn't look too closely at words and how they are handled in the programming language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The contents of a word, and of a file, are represented by programming languages as a fundamental data type known as a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section we explore strings in detail, and show the connection between strings, words, texts and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Operations with Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings are specified using single quotes [1] or double quotes [2], as shown below. If a string contains a single quote, we must backslash-escape the quote [3] so Python knows a literal quote character is intended, or else put the string in double quotes [2]. Otherwise, the quote inside the string [4] will be interpreted as a close quote, and the Python interpreter will report a syntax error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "monty = 'Monty Python' #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "circus = \"Monty Python's Flying Circus\" #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monty Python's Flying Circus\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "circus='Monty Python\\'s Flying Circus'# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Monty Python's Flying Circus\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "circus='Monty Pythons Flying Circus'  #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes strings go over several lines. Python provides us with various ways of entering them. In the next example, a sequence of two strings is joined into a single string. We need to use backslash [1] or parentheses [2] so that the interpreter knows that the statement is not complete after the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet = \"Shall I compare thee to a Summer's day?\"\\\n",
    "         \"Thou are more lovely and more temperate:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a Summer's day?Thou are more lovely and more temperate:\n"
     ]
    }
   ],
   "source": [
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet=(\"Rough winds do shake the darling buds of May,\"\n",
    "        \"And Summer's lease hath all too short a date:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately the above methods do not give us a newline between the two lines of the sonnet. Instead, we can use a triple-quoted string as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet =\"\"\"Shall I compare thee to a Summer's day?\n",
    "Thou are more lovely and more temperate:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a Summer's day?\n",
      "Thou are more lovely and more temperate:\n"
     ]
    }
   ],
   "source": [
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "couplet = '''Rough winds do shake the darling buds of May,\n",
    "And Summer's lease hath all too short a date:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rough winds do shake the darling buds of May,\n",
      "And Summer's lease hath all too short a date:\n"
     ]
    }
   ],
   "source": [
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we can define strings, we can try some simple operations on them. First let's look at the + operation, known as concatenation [1]. It produces a new string that is a copy of the two original strings pasted together end-to-end. Notice that concatenation doesn't do anything clever like insert a space between the words. We can even multiply strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'very' + 'very' + 'very'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veryveryvery'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'very' * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2. Try running the following code, then try to use your understanding of the string + and * operations to figure out how it works. Be careful to distinguish between the string ' ', which is a single whitespace character, and '', which is the empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    "for line in b:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We are printing a diamond shape by running the loop in a smart way to make the position for i for each line in a increasing order and after we reach the middle we start to decrease it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've seen that the addition and multiplication operations apply to strings, not just numbers. However, note that we cannot use subtraction or division with strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-aefd481ad5f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m'very'\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "'very'-'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-2595d7d5d93e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m'very'\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "'very'/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Character string and other string cannot have a division or a subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far, when we have wanted to look at the contents of a variable or see the result of a calculation, we have just typed the variable name into the interpreter. We can also see the contents of a variable using the print statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python\n"
     ]
    }
   ],
   "source": [
    "print(monty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that there are no quotation marks this time. When we inspect a variable by typing its name in the interpreter, the interpreter prints the Python representation of its value. Since it's a string, the result is quoted. However, when we tell the interpreter to print the contents of the variable, we don't see quotation characters since there are none inside the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print statement allows us to display more than one item on a line in various ways, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "grail = 'Holy Grail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty PythonHoly Grail\n"
     ]
    }
   ],
   "source": [
    "print(monty+grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python Holy Grail\n"
     ]
    }
   ],
   "source": [
    "print(monty,grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python and the Holy Grail\n"
     ]
    }
   ],
   "source": [
    "print(monty,'and the',grail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings are indexed, starting from zero. When we index a string, we get one of its characters (or letters). A single character is nothing special — it's just a string of length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See examples in slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we try to access an index that is outside of the string we get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-573d88a40a56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmonty\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "monty[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again as with lists, we can use negative indexes for strings, where -1 is the index of the last character [1]. Positive and negative indexes give us two ways to refer to any position in a string. In this case, when the string had a length of 12, indexes 5 and -7 both refer to the same character (a space). (Notice that 5 = len(monty) - 7.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can write for loops to iterate over the characters in strings. This print function includes the optional end=' ' parameter, which is how we tell Python to print a space instead of a newline at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'colorless green ideas sleep furiously'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c o l o r l e s s   g r e e n   i d e a s   s l e e p   f u r i o u s l y "
     ]
    }
   ],
   "source": [
    "for char in sent:\n",
    "    print(char, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can count individual characters as well. We should ignore the case distinction by normalizing everything to lowercase, and filter out non-alphabetic characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = gutenberg.raw('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e',\n",
       " 't',\n",
       " 'a',\n",
       " 'o',\n",
       " 'n',\n",
       " 'i',\n",
       " 's',\n",
       " 'h',\n",
       " 'r',\n",
       " 'l',\n",
       " 'd',\n",
       " 'u',\n",
       " 'm',\n",
       " 'c',\n",
       " 'w',\n",
       " 'f',\n",
       " 'g',\n",
       " 'p',\n",
       " 'b',\n",
       " 'y',\n",
       " 'v',\n",
       " 'k',\n",
       " 'q',\n",
       " 'j',\n",
       " 'x',\n",
       " 'z']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char for (char, count) in fdist.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Substrings (See Slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, the following code accesses the substring starting at index 6, up to (but not including) index 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pyth'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[6:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see the characters are 'P', 'y', 't', and 'h' which correspond to monty[6] ... monty[9] but not monty[10]. This is because a slice starts at the first index but finishes one before the end index.\n",
    "# We can also slice with negative indexes — the same basic rule of starting from the start index and stopping one before the end index applies; here we stop before the space character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[-12:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test if a string contains a particular substring using the in operator, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'And now for something completely different'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found \"thing\"\n"
     ]
    }
   ],
   "source": [
    "if 'thing' in phrase:\n",
    "    print('found \"thing\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.find('Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Make up a sentence and assign it to a variable, e.g. sent = 'my sentence...'. Now write slice expressions to pull out individual words. (This is obviously not a convenient way to process the words of a text!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"What a loevely day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a '"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oev'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[8:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ly '"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ay'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[16:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More operations on strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method  \tFunctionality\n",
    "#s.find(t)\tindex of first instance of string t inside s (-1 if not found)\n",
    "#s.rfind(t)\tindex of last instance of string t inside s (-1 if not found)\n",
    "#s.index(t)\tlike s.find(t) except it raises ValueError if not found\n",
    "#s.rindex(t)\tlike s.rfind(t) except it raises ValueError if not found\n",
    "#s.join(text)\tcombine the words of the text into a string using s as the glue\n",
    "#s.split(t)\tsplit s into a list wherever a t is found (whitespace by default)\n",
    "#s.splitlines()\tsplit s into a list of strings, one per line\n",
    "#s.lower()\ta lowercased version of the string s\n",
    "#s.upper()\tan uppercased version of the string s\n",
    "#s.title()\ta titlecased version of the string s\n",
    "#s.strip()\ta copy of s without leading or trailing whitespace\n",
    "#s.replace(t, u)\treplace instances of t with u inside s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Difference Between Lists and Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings and lists are both kinds of sequence. We can pull them apart by indexing and slicing them, and we can join them together by concatenating them. However, we cannot join strings and lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Who knows?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles=['John', 'Paul', 'George', 'Ringo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wh'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Paul']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings and lists are both kinds of sequence. We can pull them apart by indexing and slicing them, and we can join them together by concatenating them. However, we cannot join strings and lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Who knows? I don't\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query + \" I don't\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-e2b53fb6bc5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbeatles\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Brian'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "beatles + 'Brian'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Paul', 'George', 'Ringo', 'Brian']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles + ['Brian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists and strings do not have exactly the same functionality. Lists have the added power that you can change their elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles[0] = \"John Lennon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "del beatles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John Lennon', 'Paul', 'George']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-191-3c65520a997e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "query[0]='F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is because strings are immutable — you can't change a string once you have created it. However, lists are mutable, and their contents can be modified at any time. As a result, lists support operations that modify the original value rather than producing a new value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3   Regular Expressions for Detecting Word Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many linguistic processing tasks involve pattern matching. For example, we can find words ending with ed using endswith('ed'). We saw a variety of such \"word tests\" in 4.2. Regular expressions give us a more powerful and flexible method for describing the character patterns we are interested in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use regular expressions in Python we need to import the re library using: import re. We also need a list of words to search; we'll use the Words Corpus again (4). We will preprocess it to remove any proper names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist=[w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find words ending with ed using the regular expression «ed$». We will use the re.search(p, s) function to check whether the pattern p can be found somewhere inside the string s. We need to specify the characters of interest, and use the dollar sign which has a special behavior in the context of regular expressions in that it matches the end of the word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abaissed',\n",
       " 'abandoned',\n",
       " 'abased',\n",
       " 'abashed',\n",
       " 'abatised',\n",
       " 'abed',\n",
       " 'aborted',\n",
       " 'abridged',\n",
       " 'abscessed',\n",
       " 'absconded',\n",
       " 'absorbed',\n",
       " 'abstracted',\n",
       " 'abstricted',\n",
       " 'accelerated',\n",
       " 'accepted',\n",
       " 'accidented',\n",
       " 'accoladed',\n",
       " 'accolated',\n",
       " 'accomplished',\n",
       " 'accosted',\n",
       " 'accredited',\n",
       " 'accursed',\n",
       " 'accused',\n",
       " 'accustomed',\n",
       " 'acetated',\n",
       " 'acheweed',\n",
       " 'aciculated',\n",
       " 'aciliated',\n",
       " 'acknowledged',\n",
       " 'acorned',\n",
       " 'acquainted',\n",
       " 'acquired',\n",
       " 'acquisited',\n",
       " 'acred',\n",
       " 'aculeated',\n",
       " 'addebted',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addlebrained',\n",
       " 'addleheaded',\n",
       " 'addlepated',\n",
       " 'addorsed',\n",
       " 'adempted',\n",
       " 'adfected',\n",
       " 'adjoined',\n",
       " 'admired',\n",
       " 'admitted',\n",
       " 'adnexed',\n",
       " 'adopted',\n",
       " 'adossed',\n",
       " 'adreamed',\n",
       " 'adscripted',\n",
       " 'aduncated',\n",
       " 'advanced',\n",
       " 'advised',\n",
       " 'aeried',\n",
       " 'aethered',\n",
       " 'afeared',\n",
       " 'affected',\n",
       " 'affectioned',\n",
       " 'affined',\n",
       " 'afflicted',\n",
       " 'affricated',\n",
       " 'affrighted',\n",
       " 'affronted',\n",
       " 'aforenamed',\n",
       " 'afterfeed',\n",
       " 'aftershafted',\n",
       " 'afterthoughted',\n",
       " 'afterwitted',\n",
       " 'agazed',\n",
       " 'aged',\n",
       " 'agglomerated',\n",
       " 'aggrieved',\n",
       " 'agminated',\n",
       " 'agnamed',\n",
       " 'agonied',\n",
       " 'agreed',\n",
       " 'agueweed',\n",
       " 'ahungered',\n",
       " 'aiguilletted',\n",
       " 'ailweed',\n",
       " 'airbrained',\n",
       " 'airified',\n",
       " 'aiseweed',\n",
       " 'aisled',\n",
       " 'alarmed',\n",
       " 'alated',\n",
       " 'alimonied',\n",
       " 'aliped',\n",
       " 'alleyed',\n",
       " 'allied',\n",
       " 'alligatored',\n",
       " 'allseed',\n",
       " 'almsdeed',\n",
       " 'aloed',\n",
       " 'altared',\n",
       " 'alveolated',\n",
       " 'amazed',\n",
       " 'ameed',\n",
       " 'amiced',\n",
       " 'amphitheatered',\n",
       " 'ampullated',\n",
       " 'amused',\n",
       " 'anchored',\n",
       " 'angled',\n",
       " 'anguiped',\n",
       " 'anguished',\n",
       " 'angulated',\n",
       " 'angulinerved',\n",
       " 'anhungered',\n",
       " 'animated',\n",
       " 'aniseed',\n",
       " 'annodated',\n",
       " 'annulated',\n",
       " 'anomaliped',\n",
       " 'anserated',\n",
       " 'anteflected',\n",
       " 'anteflexed',\n",
       " 'antimoniated',\n",
       " 'antimoniureted',\n",
       " 'antimoniuretted',\n",
       " 'antiquated',\n",
       " 'antired',\n",
       " 'antiweed',\n",
       " 'antlered',\n",
       " 'apertured',\n",
       " 'apexed',\n",
       " 'apicifixed',\n",
       " 'apiculated',\n",
       " 'apocopated',\n",
       " 'apostrophied',\n",
       " 'appearanced',\n",
       " 'appellatived',\n",
       " 'appendaged',\n",
       " 'appendiculated',\n",
       " 'applied',\n",
       " 'appressed',\n",
       " 'aralkylated',\n",
       " 'arbored',\n",
       " 'arched',\n",
       " 'architraved',\n",
       " 'arcked',\n",
       " 'arcuated',\n",
       " 'ared',\n",
       " 'areolated',\n",
       " 'ariled',\n",
       " 'arillated',\n",
       " 'armchaired',\n",
       " 'armed',\n",
       " 'armied',\n",
       " 'armillated',\n",
       " 'armored',\n",
       " 'armoried',\n",
       " 'arpeggiated',\n",
       " 'arpeggioed',\n",
       " 'arrased',\n",
       " 'arrowed',\n",
       " 'arrowheaded',\n",
       " 'arrowweed',\n",
       " 'arseneted',\n",
       " 'arsenetted',\n",
       " 'arseniureted',\n",
       " 'articled',\n",
       " 'articulated',\n",
       " 'ashamed',\n",
       " 'ashlared',\n",
       " 'ashweed',\n",
       " 'aspersed',\n",
       " 'asphyxied',\n",
       " 'assented',\n",
       " 'assessed',\n",
       " 'assigned',\n",
       " 'assistanted',\n",
       " 'associated',\n",
       " 'assonanced',\n",
       " 'assorted',\n",
       " 'assumed',\n",
       " 'assured',\n",
       " 'asteriated',\n",
       " 'astonied',\n",
       " 'aswooned',\n",
       " 'atrophiated',\n",
       " 'atrophied',\n",
       " 'attached',\n",
       " 'attired',\n",
       " 'attrited',\n",
       " 'augmented',\n",
       " 'aurated',\n",
       " 'auricled',\n",
       " 'auriculated',\n",
       " 'authorized',\n",
       " 'autoinhibited',\n",
       " 'autosensitized',\n",
       " 'autosled',\n",
       " 'averted',\n",
       " 'avowed',\n",
       " 'awearied',\n",
       " 'awned',\n",
       " 'awninged',\n",
       " 'axed',\n",
       " 'axhammered',\n",
       " 'axised',\n",
       " 'axled',\n",
       " 'axseed',\n",
       " 'axweed',\n",
       " 'azoted',\n",
       " 'azured',\n",
       " 'babied',\n",
       " 'babished',\n",
       " 'babyfied',\n",
       " 'baccated',\n",
       " 'backboned',\n",
       " 'backed',\n",
       " 'backhanded',\n",
       " 'backwatered',\n",
       " 'baconweed',\n",
       " 'badgerweed',\n",
       " 'bagged',\n",
       " 'bagwigged',\n",
       " 'baked',\n",
       " 'balanced',\n",
       " 'balconied',\n",
       " 'baldachined',\n",
       " 'baldricked',\n",
       " 'balled',\n",
       " 'ballweed',\n",
       " 'balsamweed',\n",
       " 'balustered',\n",
       " 'balustraded',\n",
       " 'bandannaed',\n",
       " 'banded',\n",
       " 'bandoleered',\n",
       " 'bangled',\n",
       " 'banked',\n",
       " 'bankweed',\n",
       " 'bannered',\n",
       " 'barbated',\n",
       " 'barbed',\n",
       " 'barebacked',\n",
       " 'bareboned',\n",
       " 'barefaced',\n",
       " 'barefooted',\n",
       " 'barehanded',\n",
       " 'bareheaded',\n",
       " 'barelegged',\n",
       " 'barenecked',\n",
       " 'barmybrained',\n",
       " 'barred',\n",
       " 'barreled',\n",
       " 'bartizaned',\n",
       " 'basebred',\n",
       " 'based',\n",
       " 'basehearted',\n",
       " 'basifixed',\n",
       " 'basilweed',\n",
       " 'basined',\n",
       " 'basinerved',\n",
       " 'basqued',\n",
       " 'bastioned',\n",
       " 'bated',\n",
       " 'bathroomed',\n",
       " 'battered',\n",
       " 'batteried',\n",
       " 'battled',\n",
       " 'battlemented',\n",
       " 'bayed',\n",
       " 'bayoneted',\n",
       " 'beached',\n",
       " 'beaded',\n",
       " 'beaked',\n",
       " 'bealtared',\n",
       " 'beamed',\n",
       " 'beanweed',\n",
       " 'beaproned',\n",
       " 'bearded',\n",
       " 'beautied',\n",
       " 'beavered',\n",
       " 'beballed',\n",
       " 'bebannered',\n",
       " 'bebed',\n",
       " 'bebelted',\n",
       " 'bebled',\n",
       " 'bebothered',\n",
       " 'bebouldered',\n",
       " 'bebuttoned',\n",
       " 'becassocked',\n",
       " 'bechained',\n",
       " 'bechignoned',\n",
       " 'becircled',\n",
       " 'becoiffed',\n",
       " 'becombed',\n",
       " 'becousined',\n",
       " 'becrinolined',\n",
       " 'becuffed',\n",
       " 'becurtained',\n",
       " 'becushioned',\n",
       " 'bed',\n",
       " 'bedaggered',\n",
       " 'bedangled',\n",
       " 'bedded',\n",
       " 'bediademed',\n",
       " 'bediamonded',\n",
       " 'beedged',\n",
       " 'beefheaded',\n",
       " 'beeheaded',\n",
       " 'beeswinged',\n",
       " 'beetled',\n",
       " 'beetleheaded',\n",
       " 'beetleweed',\n",
       " 'beeweed',\n",
       " 'befamilied',\n",
       " 'befanned',\n",
       " 'befathered',\n",
       " 'beferned',\n",
       " 'befetished',\n",
       " 'befezzed',\n",
       " 'befilleted',\n",
       " 'befilmed',\n",
       " 'beforested',\n",
       " 'befountained',\n",
       " 'befrocked',\n",
       " 'befrogged',\n",
       " 'befurbelowed',\n",
       " 'befurred',\n",
       " 'begabled',\n",
       " 'begarlanded',\n",
       " 'begartered',\n",
       " 'beggarweed',\n",
       " 'beglobed',\n",
       " 'begoggled',\n",
       " 'begowned',\n",
       " 'behatted',\n",
       " 'behaviored',\n",
       " 'beheadlined',\n",
       " 'behooped',\n",
       " 'beinked',\n",
       " 'bekilted',\n",
       " 'beknived',\n",
       " 'beknotted',\n",
       " 'belaced',\n",
       " 'belated',\n",
       " 'belatticed',\n",
       " 'belavendered',\n",
       " 'beledgered',\n",
       " 'belfried',\n",
       " 'beliked',\n",
       " 'belimousined',\n",
       " 'belled',\n",
       " 'bellied',\n",
       " 'bellmouthed',\n",
       " 'bellweed',\n",
       " 'beloved',\n",
       " 'belozenged',\n",
       " 'belted',\n",
       " 'bemazed',\n",
       " 'bemedaled',\n",
       " 'bemedalled',\n",
       " 'bemitered',\n",
       " 'bemitred',\n",
       " 'bemused',\n",
       " 'bemuslined',\n",
       " 'bended',\n",
       " 'beneaped',\n",
       " 'beneficed',\n",
       " 'beneighbored',\n",
       " 'benempted',\n",
       " 'benighted',\n",
       " 'bennetweed',\n",
       " 'benumbed',\n",
       " 'benweed',\n",
       " 'benzoated',\n",
       " 'benzoinated',\n",
       " 'bepastured',\n",
       " 'bepatched',\n",
       " 'beperiwigged',\n",
       " 'bepewed',\n",
       " 'bepillared',\n",
       " 'bepistoled',\n",
       " 'beplaided',\n",
       " 'beplumed',\n",
       " 'beribanded',\n",
       " 'beribboned',\n",
       " 'beringed',\n",
       " 'beringleted',\n",
       " 'berobed',\n",
       " 'berouged',\n",
       " 'berried',\n",
       " 'berthed',\n",
       " 'beruffed',\n",
       " 'beruffled',\n",
       " 'beshawled',\n",
       " 'besieged',\n",
       " 'beslushed',\n",
       " 'besotted',\n",
       " 'bespecked',\n",
       " 'bespectacled',\n",
       " 'besped',\n",
       " 'bespeed',\n",
       " 'bespelled',\n",
       " 'bespurred',\n",
       " 'bestatued',\n",
       " 'bestayed',\n",
       " 'bestrapped',\n",
       " 'bestubbled',\n",
       " 'besweatered',\n",
       " 'betattered',\n",
       " 'betaxed',\n",
       " 'betowered',\n",
       " 'betrothed',\n",
       " 'betrousered',\n",
       " 'betted',\n",
       " 'betuckered',\n",
       " 'beturbaned',\n",
       " 'betusked',\n",
       " 'betutored',\n",
       " 'betwattled',\n",
       " 'beuniformed',\n",
       " 'beveled',\n",
       " 'bevelled',\n",
       " 'bevesseled',\n",
       " 'bevesselled',\n",
       " 'bevined',\n",
       " 'bevoiled',\n",
       " 'bewaitered',\n",
       " 'bewhiskered',\n",
       " 'bewigged',\n",
       " 'bewildered',\n",
       " 'bewinged',\n",
       " 'bewired',\n",
       " 'bewrathed',\n",
       " 'biangulated',\n",
       " 'biarcuated',\n",
       " 'biarticulated',\n",
       " 'bicarbureted',\n",
       " 'biciliated',\n",
       " 'bicolored',\n",
       " 'bicorned',\n",
       " 'bidented',\n",
       " 'bifanged',\n",
       " 'bifidated',\n",
       " 'biflected',\n",
       " 'biforked',\n",
       " 'biformed',\n",
       " 'bifronted',\n",
       " 'bifurcated',\n",
       " 'bigeminated',\n",
       " 'bighearted',\n",
       " 'bigmouthed',\n",
       " 'bigoted',\n",
       " 'bigwigged',\n",
       " 'bilamellated',\n",
       " 'bilaminated',\n",
       " 'billed',\n",
       " 'bilobated',\n",
       " 'bilobed',\n",
       " 'bilsted',\n",
       " 'bimaculated',\n",
       " 'bimotored',\n",
       " 'bindweed',\n",
       " 'bineweed',\n",
       " 'binominated',\n",
       " 'binucleated',\n",
       " 'biparted',\n",
       " 'bipectinated',\n",
       " 'biped',\n",
       " 'bipennated',\n",
       " 'bipinnated',\n",
       " 'bipinnatiparted',\n",
       " 'bipinnatisected',\n",
       " 'biradiated',\n",
       " 'birdmouthed',\n",
       " 'birdseed',\n",
       " 'birdweed',\n",
       " 'birostrated',\n",
       " 'birthbed',\n",
       " 'bisexed',\n",
       " 'bishopweed',\n",
       " 'bistered',\n",
       " 'bistipuled',\n",
       " 'bisubstituted',\n",
       " 'bitted',\n",
       " 'bitterhearted',\n",
       " 'bitterweed',\n",
       " 'bituberculated',\n",
       " 'bitumed',\n",
       " 'bivalved',\n",
       " 'bivaulted',\n",
       " 'bivocalized',\n",
       " 'blackhearted',\n",
       " 'blackseed',\n",
       " 'blackshirted',\n",
       " 'bladderseed',\n",
       " 'bladderweed',\n",
       " 'bladed',\n",
       " 'blakeberyed',\n",
       " 'blamed',\n",
       " 'blanked',\n",
       " 'blanketed',\n",
       " 'blanketweed',\n",
       " 'blasted',\n",
       " 'bleached',\n",
       " 'bleared',\n",
       " 'bleed',\n",
       " 'blended',\n",
       " 'blessed',\n",
       " 'blighted',\n",
       " 'blinded',\n",
       " 'blindfolded',\n",
       " 'blindweed',\n",
       " 'blinked',\n",
       " 'blinkered',\n",
       " 'blistered',\n",
       " 'blisterweed',\n",
       " 'blithehearted',\n",
       " 'bloated',\n",
       " 'blobbed',\n",
       " 'blocked',\n",
       " 'blockheaded',\n",
       " 'blooded',\n",
       " 'bloodied',\n",
       " 'bloodshed',\n",
       " 'bloodstained',\n",
       " 'bloodweed',\n",
       " 'blossomed',\n",
       " 'blotched',\n",
       " 'bloused',\n",
       " 'blowzed',\n",
       " 'bludgeoned',\n",
       " 'bluebelled',\n",
       " 'bluehearted',\n",
       " 'blueweed',\n",
       " 'blunderheaded',\n",
       " 'blunthearted',\n",
       " 'blurred',\n",
       " 'bobbed',\n",
       " 'bobsled',\n",
       " 'bobtailed',\n",
       " 'bodiced',\n",
       " 'bodied',\n",
       " 'boiled',\n",
       " 'boldhearted',\n",
       " 'bolectioned',\n",
       " 'boled',\n",
       " 'boleweed',\n",
       " 'bolled',\n",
       " 'bombed',\n",
       " 'bonded',\n",
       " 'boned',\n",
       " 'boneheaded',\n",
       " 'bonneted',\n",
       " 'booked',\n",
       " 'booted',\n",
       " 'bootied',\n",
       " 'boozed',\n",
       " 'bordered',\n",
       " 'bordured',\n",
       " 'bosomed',\n",
       " 'bossed',\n",
       " 'bosselated',\n",
       " 'botched',\n",
       " 'botherheaded',\n",
       " 'bothsided',\n",
       " 'bottled',\n",
       " 'bottomed',\n",
       " 'boughed',\n",
       " 'bounded',\n",
       " 'bountied',\n",
       " 'bowed',\n",
       " 'boweled',\n",
       " 'bowlegged',\n",
       " 'bowstringed',\n",
       " 'braced',\n",
       " 'braceleted',\n",
       " 'brackened',\n",
       " 'bracted',\n",
       " 'braided',\n",
       " 'brambled',\n",
       " 'branched',\n",
       " 'branded',\n",
       " 'brandied',\n",
       " 'brangled',\n",
       " 'bravehearted',\n",
       " 'brawned',\n",
       " 'brazenfaced',\n",
       " 'breasted',\n",
       " 'breastweed',\n",
       " 'breathed',\n",
       " 'brecciated',\n",
       " 'bred',\n",
       " 'breeched',\n",
       " 'breed',\n",
       " 'breviped',\n",
       " 'bridebed',\n",
       " 'brideweed',\n",
       " 'bridged',\n",
       " 'bridled',\n",
       " 'briered',\n",
       " 'brimmed',\n",
       " 'bristled',\n",
       " 'broadhearted',\n",
       " 'brocaded',\n",
       " 'brocked',\n",
       " 'brokenhearted',\n",
       " 'bromoiodized',\n",
       " 'bronzed',\n",
       " 'brooked',\n",
       " 'brookweed',\n",
       " 'broomweed',\n",
       " 'broozled',\n",
       " 'browed',\n",
       " 'brownweed',\n",
       " 'bruckled',\n",
       " 'brushed',\n",
       " 'buboed',\n",
       " 'bucked',\n",
       " 'buckled',\n",
       " 'buckskinned',\n",
       " 'buffed',\n",
       " 'bugled',\n",
       " 'bugleweed',\n",
       " 'bugseed',\n",
       " 'bugweed',\n",
       " 'bulbed',\n",
       " 'bulked',\n",
       " 'bulkheaded',\n",
       " 'bullated',\n",
       " 'bulldogged',\n",
       " 'bulleted',\n",
       " 'bulletheaded',\n",
       " 'bullheaded',\n",
       " 'bullweed',\n",
       " 'bummed',\n",
       " 'bundlerooted',\n",
       " 'bundweed',\n",
       " 'bunted',\n",
       " 'buried',\n",
       " 'burled',\n",
       " 'burned',\n",
       " 'burnoosed',\n",
       " 'burntweed',\n",
       " 'burred',\n",
       " 'burroweed',\n",
       " 'burseed',\n",
       " 'burweed',\n",
       " 'bushed',\n",
       " 'busied',\n",
       " 'busked',\n",
       " 'buskined',\n",
       " 'busted',\n",
       " 'bustled',\n",
       " 'busybodied',\n",
       " 'buttered',\n",
       " 'butterfingered',\n",
       " 'butterweed',\n",
       " 'butteryfingered',\n",
       " 'buttocked',\n",
       " 'buttoned',\n",
       " 'buttonweed',\n",
       " 'cabled',\n",
       " 'caboshed',\n",
       " 'caddiced',\n",
       " 'caddised',\n",
       " 'cadenced',\n",
       " 'cadweed',\n",
       " 'caftaned',\n",
       " 'caged',\n",
       " 'cairned',\n",
       " 'caissoned',\n",
       " 'calced',\n",
       " 'calcified',\n",
       " 'calcined',\n",
       " 'calculated',\n",
       " 'calibered',\n",
       " 'calicoed',\n",
       " 'caligated',\n",
       " 'calpacked',\n",
       " 'calved',\n",
       " 'calycled',\n",
       " 'calyculated',\n",
       " 'camailed',\n",
       " 'camerated',\n",
       " 'cammed',\n",
       " 'campanulated',\n",
       " 'campshed',\n",
       " 'camused',\n",
       " 'canaliculated',\n",
       " 'cancellated',\n",
       " 'cancered',\n",
       " 'cancerweed',\n",
       " 'candied',\n",
       " 'candlelighted',\n",
       " 'candlesticked',\n",
       " 'candyweed',\n",
       " 'canioned',\n",
       " 'cankered',\n",
       " 'cankerweed',\n",
       " 'canned',\n",
       " 'cannelated',\n",
       " 'cannelured',\n",
       " 'cannoned',\n",
       " 'cannulated',\n",
       " 'canted',\n",
       " 'cantilevered',\n",
       " 'cantoned',\n",
       " 'cantred',\n",
       " 'caped',\n",
       " 'capernoited',\n",
       " 'capeweed',\n",
       " 'capitaled',\n",
       " 'capitated',\n",
       " 'capped',\n",
       " 'capriped',\n",
       " 'capsulated',\n",
       " 'capuched',\n",
       " 'carapaced',\n",
       " 'carbolated',\n",
       " 'carboyed',\n",
       " 'carbuncled',\n",
       " 'carcaneted',\n",
       " 'carded',\n",
       " 'carinated',\n",
       " 'carkled',\n",
       " 'carnaged',\n",
       " 'carnationed',\n",
       " 'carpetweed',\n",
       " 'carried',\n",
       " 'carrotweed',\n",
       " 'carucated',\n",
       " 'carunculated',\n",
       " 'cased',\n",
       " 'casemated',\n",
       " 'casemented',\n",
       " 'caseweed',\n",
       " 'casqued',\n",
       " 'castellated',\n",
       " 'castled',\n",
       " 'castorized',\n",
       " 'catamited',\n",
       " 'cataracted',\n",
       " 'catarrhed',\n",
       " 'catchweed',\n",
       " 'catenated',\n",
       " 'caterpillared',\n",
       " 'catfaced',\n",
       " 'catfooted',\n",
       " 'cathedraled',\n",
       " 'caudated',\n",
       " 'caverned',\n",
       " 'cavitied',\n",
       " 'cayenned',\n",
       " 'cedared',\n",
       " 'ceilinged',\n",
       " 'celebrated',\n",
       " 'cellated',\n",
       " 'celled',\n",
       " 'cellulated',\n",
       " 'celluloided',\n",
       " 'centered',\n",
       " 'centriffed',\n",
       " 'centuried',\n",
       " 'cerated',\n",
       " 'cered',\n",
       " 'certified',\n",
       " 'chafeweed',\n",
       " 'chaffseed',\n",
       " 'chaffweed',\n",
       " 'chafted',\n",
       " 'chained',\n",
       " 'chaliced',\n",
       " 'chambered',\n",
       " 'chamberleted',\n",
       " 'chamberletted',\n",
       " 'chanceled',\n",
       " 'channeled',\n",
       " 'channelled',\n",
       " 'chaped',\n",
       " 'chapleted',\n",
       " 'chapournetted',\n",
       " 'chapped',\n",
       " 'charioted',\n",
       " 'charqued',\n",
       " 'chartered',\n",
       " 'chasmed',\n",
       " 'chasteweed',\n",
       " 'chasubled',\n",
       " 'checked',\n",
       " 'checkered',\n",
       " 'checkrowed',\n",
       " 'cheered',\n",
       " 'cheliped',\n",
       " 'cherried',\n",
       " 'chickenbreasted',\n",
       " 'chickenhearted',\n",
       " 'chickenweed',\n",
       " 'chickweed',\n",
       " 'chicqued',\n",
       " 'chiggerweed',\n",
       " 'chignoned',\n",
       " 'childbed',\n",
       " 'childed',\n",
       " 'chilled',\n",
       " 'chined',\n",
       " 'chinned',\n",
       " 'chipped',\n",
       " 'chiseled',\n",
       " 'chitinized',\n",
       " 'chokered',\n",
       " 'chokeweed',\n",
       " 'cholterheaded',\n",
       " 'chopped',\n",
       " 'choppered',\n",
       " 'chorded',\n",
       " 'chowderheaded',\n",
       " 'christened',\n",
       " 'chubbed',\n",
       " 'chuckleheaded',\n",
       " 'churchified',\n",
       " 'churled',\n",
       " 'ciliated',\n",
       " 'cingulated',\n",
       " 'cinnamoned',\n",
       " 'cinquefoiled',\n",
       " 'circled',\n",
       " 'circumscribed',\n",
       " 'circumstanced',\n",
       " 'cirrated',\n",
       " 'cirrhosed',\n",
       " 'cirriped',\n",
       " 'cisted',\n",
       " 'citied',\n",
       " 'citified',\n",
       " 'citrated',\n",
       " 'civilized',\n",
       " 'clammed',\n",
       " 'clammyweed',\n",
       " 'clanned',\n",
       " 'clapped',\n",
       " 'classed',\n",
       " 'classified',\n",
       " 'clavated',\n",
       " 'clavellated',\n",
       " 'clawed',\n",
       " 'claybrained',\n",
       " 'clayweed',\n",
       " 'cleaded',\n",
       " 'cleanhanded',\n",
       " 'cleanhearted',\n",
       " 'clearheaded',\n",
       " 'clearhearted',\n",
       " 'clearweed',\n",
       " 'cled',\n",
       " 'cleeked',\n",
       " 'clefted',\n",
       " 'clerestoried',\n",
       " 'cliented',\n",
       " 'cliffed',\n",
       " 'cliffweed',\n",
       " 'clipped',\n",
       " 'cloaked',\n",
       " 'clocked',\n",
       " 'clodpated',\n",
       " 'cloistered',\n",
       " 'closed',\n",
       " 'closefisted',\n",
       " 'closehanded',\n",
       " 'closehearted',\n",
       " 'closemouthed',\n",
       " 'clotweed',\n",
       " 'clouded',\n",
       " 'clouted',\n",
       " 'clovered',\n",
       " 'clubbed',\n",
       " 'clubfisted',\n",
       " 'clubfooted',\n",
       " 'clubweed',\n",
       " 'clustered',\n",
       " 'coaged',\n",
       " 'coaggregated',\n",
       " 'coated',\n",
       " 'coattailed',\n",
       " 'cobbed',\n",
       " 'cocashweed',\n",
       " 'cochleated',\n",
       " 'cockaded',\n",
       " 'cocked',\n",
       " 'cockeyed',\n",
       " 'cockled',\n",
       " 'cockneybred',\n",
       " 'cockscombed',\n",
       " 'cockweed',\n",
       " 'codheaded',\n",
       " 'coed',\n",
       " 'coelongated',\n",
       " 'coembedded',\n",
       " 'coequated',\n",
       " 'coexpanded',\n",
       " 'coffeeweed',\n",
       " 'cogged',\n",
       " 'coifed',\n",
       " 'coiled',\n",
       " 'coldhearted',\n",
       " 'coleseed',\n",
       " 'colicweed',\n",
       " 'collared',\n",
       " 'collected',\n",
       " 'collied',\n",
       " 'colloped',\n",
       " 'colonnaded',\n",
       " 'colored',\n",
       " 'columnated',\n",
       " 'columned',\n",
       " 'combed',\n",
       " 'combined',\n",
       " 'compacted',\n",
       " 'complected',\n",
       " 'complexioned',\n",
       " 'complicated',\n",
       " 'componed',\n",
       " 'componented',\n",
       " 'composed',\n",
       " 'compressed',\n",
       " 'comprised',\n",
       " 'compulsed',\n",
       " 'conamed',\n",
       " 'concamerated',\n",
       " 'concealed',\n",
       " 'conceded',\n",
       " 'conceited',\n",
       " 'concentrated',\n",
       " 'concerned',\n",
       " 'concerted',\n",
       " 'conched',\n",
       " 'conchyliated',\n",
       " 'condemned',\n",
       " 'condensed',\n",
       " 'conditioned',\n",
       " 'conduplicated',\n",
       " 'coned',\n",
       " 'confated',\n",
       " 'conferted',\n",
       " 'confined',\n",
       " 'confirmed',\n",
       " 'conflated',\n",
       " 'confounded',\n",
       " 'confused',\n",
       " 'congested',\n",
       " 'conjoined',\n",
       " 'conjugated',\n",
       " 'connected',\n",
       " 'conred',\n",
       " 'consecrated',\n",
       " 'considered',\n",
       " 'consolidated',\n",
       " 'constrained',\n",
       " 'constricted',\n",
       " 'consumpted',\n",
       " 'contagioned',\n",
       " 'contented',\n",
       " 'contextured',\n",
       " 'continued',\n",
       " 'contorted',\n",
       " 'contortioned',\n",
       " 'contracted',\n",
       " 'contractured',\n",
       " 'contusioned',\n",
       " 'converted',\n",
       " 'convexed',\n",
       " 'convinced',\n",
       " 'convoluted',\n",
       " 'coolheaded',\n",
       " 'coolweed',\n",
       " 'copied',\n",
       " 'copleased',\n",
       " 'copped',\n",
       " 'coppernosed',\n",
       " 'copperytailed',\n",
       " 'coppiced',\n",
       " 'coppled',\n",
       " 'copsewooded',\n",
       " 'copygraphed',\n",
       " 'coraled',\n",
       " 'corded',\n",
       " 'corduroyed',\n",
       " 'cored',\n",
       " 'coreflexed',\n",
       " 'corked',\n",
       " 'cornered',\n",
       " 'cornified',\n",
       " 'cornuated',\n",
       " 'cornuted',\n",
       " 'corollated',\n",
       " 'coronaled',\n",
       " 'coronated',\n",
       " 'coroneted',\n",
       " 'coronetted',\n",
       " 'corpusculated',\n",
       " 'corrected',\n",
       " 'correlated',\n",
       " 'corridored',\n",
       " ...]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('ed$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The . wildcard symbol matches any single character. Suppose we have room in a crossword puzzle for an 8-letter word with j as its third letter and t as its sixth letter. In place of each blank cell we use a period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abjectly',\n",
       " 'adjuster',\n",
       " 'dejected',\n",
       " 'dejectly',\n",
       " 'injector',\n",
       " 'majestic',\n",
       " 'objectee',\n",
       " 'objector',\n",
       " 'rejecter',\n",
       " 'rejector',\n",
       " 'unjilted',\n",
       " 'unjolted',\n",
       " 'unjustly']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^..j..t..$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Exercise 4: The caret symbol ^ matches the start of a string, just like the $ matches the end. What results do we get with the above example if we leave out both of these, and search for «..j..t..»?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abjectedness',\n",
       " 'abjection',\n",
       " 'abjective',\n",
       " 'abjectly',\n",
       " 'abjectness',\n",
       " 'adjection',\n",
       " 'adjectional',\n",
       " 'adjectival',\n",
       " 'adjectivally',\n",
       " 'adjective',\n",
       " 'adjectively',\n",
       " 'adjectivism',\n",
       " 'adjectivitis',\n",
       " 'adjustable',\n",
       " 'adjustably',\n",
       " 'adjustage',\n",
       " 'adjustation',\n",
       " 'adjuster',\n",
       " 'adjustive',\n",
       " 'adjustment',\n",
       " 'antejentacular',\n",
       " 'antiprojectivity',\n",
       " 'bijouterie',\n",
       " 'coadjustment',\n",
       " 'cojusticiar',\n",
       " 'conjective',\n",
       " 'conjecturable',\n",
       " 'conjecturably',\n",
       " 'conjectural',\n",
       " 'conjecturalist',\n",
       " 'conjecturality',\n",
       " 'conjecturally',\n",
       " 'conjecture',\n",
       " 'conjecturer',\n",
       " 'coprojector',\n",
       " 'counterobjection',\n",
       " 'dejected',\n",
       " 'dejectedly',\n",
       " 'dejectedness',\n",
       " 'dejectile',\n",
       " 'dejection',\n",
       " 'dejectly',\n",
       " 'dejectory',\n",
       " 'dejecture',\n",
       " 'disjection',\n",
       " 'guanajuatite',\n",
       " 'inadjustability',\n",
       " 'inadjustable',\n",
       " 'injectable',\n",
       " 'injection',\n",
       " 'injector',\n",
       " 'injustice',\n",
       " 'insubjection',\n",
       " 'interjection',\n",
       " 'interjectional',\n",
       " 'interjectionalize',\n",
       " 'interjectionally',\n",
       " 'interjectionary',\n",
       " 'interjectionize',\n",
       " 'interjectiveness',\n",
       " 'interjector',\n",
       " 'interjectorily',\n",
       " 'interjectory',\n",
       " 'interjectural',\n",
       " 'interobjective',\n",
       " 'intersubjective',\n",
       " 'introjection',\n",
       " 'introjective',\n",
       " 'majestic',\n",
       " 'majestical',\n",
       " 'majestically',\n",
       " 'majesticalness',\n",
       " 'majesticness',\n",
       " 'majestious',\n",
       " 'majestyship',\n",
       " 'maladjusted',\n",
       " 'maladjustive',\n",
       " 'maladjustment',\n",
       " 'microinjection',\n",
       " 'microprojector',\n",
       " 'misconjecture',\n",
       " 'munjistin',\n",
       " 'nonadjectival',\n",
       " 'nonadjustable',\n",
       " 'nonadjustive',\n",
       " 'nonadjustment',\n",
       " 'nonconjectural',\n",
       " 'nonejection',\n",
       " 'nonobjection',\n",
       " 'nonobjective',\n",
       " 'nonprojection',\n",
       " 'nonprojective',\n",
       " 'nonprojectively',\n",
       " 'nonrejection',\n",
       " 'nonsubjective',\n",
       " 'objectable',\n",
       " 'objectation',\n",
       " 'objectative',\n",
       " 'objectee',\n",
       " 'objecthood',\n",
       " 'objectification',\n",
       " 'objectify',\n",
       " 'objection',\n",
       " 'objectionability',\n",
       " 'objectionable',\n",
       " 'objectionableness',\n",
       " 'objectionably',\n",
       " 'objectional',\n",
       " 'objectioner',\n",
       " 'objectionist',\n",
       " 'objectival',\n",
       " 'objectivate',\n",
       " 'objectivation',\n",
       " 'objective',\n",
       " 'objectively',\n",
       " 'objectiveness',\n",
       " 'objectivism',\n",
       " 'objectivist',\n",
       " 'objectivistic',\n",
       " 'objectivity',\n",
       " 'objectivize',\n",
       " 'objectization',\n",
       " 'objectize',\n",
       " 'objectless',\n",
       " 'objectlessly',\n",
       " 'objectlessness',\n",
       " 'objector',\n",
       " 'outjetting',\n",
       " 'overjutting',\n",
       " 'overobjectify',\n",
       " 'preadjectival',\n",
       " 'preadjective',\n",
       " 'preadjustable',\n",
       " 'preadjustment',\n",
       " 'preconjecture',\n",
       " 'prejustification',\n",
       " 'prejustify',\n",
       " 'preobjection',\n",
       " 'preobjective',\n",
       " 'prerejection',\n",
       " 'presubjection',\n",
       " 'projectable',\n",
       " 'projectedly',\n",
       " 'projectile',\n",
       " 'projecting',\n",
       " 'projectingly',\n",
       " 'projection',\n",
       " 'projectional',\n",
       " 'projectionist',\n",
       " 'projective',\n",
       " 'projectively',\n",
       " 'projectivity',\n",
       " 'projector',\n",
       " 'projectress',\n",
       " 'projectrix',\n",
       " 'projecture',\n",
       " 'readjustable',\n",
       " 'readjuster',\n",
       " 'readjustment',\n",
       " 'rejectable',\n",
       " 'rejectableness',\n",
       " 'rejectage',\n",
       " 'rejectamenta',\n",
       " 'rejecter',\n",
       " 'rejectingly',\n",
       " 'rejection',\n",
       " 'rejective',\n",
       " 'rejectment',\n",
       " 'rejector',\n",
       " 'rejustification',\n",
       " 'rejustify',\n",
       " 'reobjectivization',\n",
       " 'reobjectivize',\n",
       " 'resubjection',\n",
       " 'retrojection',\n",
       " 'semiadjectively',\n",
       " 'subjectability',\n",
       " 'subjectable',\n",
       " 'subjectdom',\n",
       " 'subjected',\n",
       " 'subjectedly',\n",
       " 'subjectedness',\n",
       " 'subjecthood',\n",
       " 'subjectibility',\n",
       " 'subjectible',\n",
       " 'subjectification',\n",
       " 'subjectify',\n",
       " 'subjectile',\n",
       " 'subjection',\n",
       " 'subjectional',\n",
       " 'subjectist',\n",
       " 'subjective',\n",
       " 'subjectively',\n",
       " 'subjectiveness',\n",
       " 'subjectivism',\n",
       " 'subjectivist',\n",
       " 'subjectivistic',\n",
       " 'subjectivistically',\n",
       " 'subjectivity',\n",
       " 'subjectivize',\n",
       " 'subjectivoidealistic',\n",
       " 'subjectless',\n",
       " 'subjectlike',\n",
       " 'subjectness',\n",
       " 'subjectship',\n",
       " 'superdejection',\n",
       " 'superinjustice',\n",
       " 'superjustification',\n",
       " 'superobjection',\n",
       " 'superobjectionable',\n",
       " 'teleobjective',\n",
       " 'trajectile',\n",
       " 'trajection',\n",
       " 'trajectitious',\n",
       " 'trajectory',\n",
       " 'transsubjective',\n",
       " 'unadjectived',\n",
       " 'unadjustably',\n",
       " 'unadjusted',\n",
       " 'unadjustment',\n",
       " 'unconjecturable',\n",
       " 'unconjectured',\n",
       " 'undejected',\n",
       " 'underadjustment',\n",
       " 'unejected',\n",
       " 'uninjectable',\n",
       " 'uninjected',\n",
       " 'uninterjected',\n",
       " 'unjesting',\n",
       " 'unjilted',\n",
       " 'unjolted',\n",
       " 'unjostled',\n",
       " 'unjustice',\n",
       " 'unjusticiable',\n",
       " 'unjustifiable',\n",
       " 'unjustifiableness',\n",
       " 'unjustifiably',\n",
       " 'unjustified',\n",
       " 'unjustifiedly',\n",
       " 'unjustifiedness',\n",
       " 'unjustify',\n",
       " 'unjustled',\n",
       " 'unjustly',\n",
       " 'unjustness',\n",
       " 'unmajestic',\n",
       " 'unobjected',\n",
       " 'unobjectionable',\n",
       " 'unobjectionableness',\n",
       " 'unobjectionably',\n",
       " 'unobjectional',\n",
       " 'unobjective',\n",
       " 'unprojected',\n",
       " 'unprojecting',\n",
       " 'unrejectable',\n",
       " 'unsubjectable',\n",
       " 'unsubjected',\n",
       " 'unsubjectedness',\n",
       " 'unsubjection',\n",
       " 'unsubjective',\n",
       " 'unsubjectlike']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('..j..t..', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J is no longer the third letter and t is no longer the six letter and the end letter could be anything, the length of the word could be anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the ? symbol specifies that the previous character is optional. Thus «^e-?mail$» will match both email and e-mail. We could count the total number of occurrences of this word (in either spelling) in a text using sum(1 for w in text if re.search('^e-?mail$', w))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^e-?mail$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for w in wordlist if re.search('^e-?mail$', w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Operator\tBehavior\n",
    "#.\t        Wildcard, matches any character\n",
    "#^abc\t    Matches some pattern abc at the start of a string\n",
    "#abc$\t    Matches some pattern abc at the end of a string\n",
    "#[abc]\t    Matches one of a set of characters\n",
    "#[A-Z0-9]\tMatches one of a range of characters\n",
    "#ed|ing|s\tMatches one of the specified strings (disjunction)\n",
    "#*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
    "#+\t        One or more of previous item, e.g. a+, [a-z]+\n",
    "#?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
    "#{n}\t    Exactly n repeats where n is a non-negative integer\n",
    "#{n,}\t    At least n repeats\n",
    "#{,n}\t    No more than n repeats\n",
    "#{m,n}\t    At least m and no more than n repeats\n",
    "#a(b|c)+\tParentheses that indicate the scope of the operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranges and Closures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The T9 system is used for entering text on mobile phones (see 3.5). Two or more words that are entered with the same sequence of keystrokes are known as textonyms. For example, both hole and golf are entered by pressing the sequence 4653. What other words could be produced with the same sequence? Here we use the regular expression «^[ghi][mno][jlk][def]$»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gold', 'golf', 'hold', 'hole']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Look for some \"finger-twisters\", by searching for words that only use part of the number-pad. For example «^[ghijklmno]+$», or more concisely, «^[g-o]+$», will match words that only use keys 4, 5, 6 in the center row, and «^[a-fj-o]+$» will match words that use keys 2, 3, 5, 6 in the top-right corner. What do - and + mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g',\n",
       " 'ghoom',\n",
       " 'gig',\n",
       " 'giggling',\n",
       " 'gigolo',\n",
       " 'gilim',\n",
       " 'gill',\n",
       " 'gilling',\n",
       " 'gilo',\n",
       " 'gim',\n",
       " 'gin',\n",
       " 'ging',\n",
       " 'gingili',\n",
       " 'gink',\n",
       " 'ginkgo',\n",
       " 'ginning',\n",
       " 'gio',\n",
       " 'glink',\n",
       " 'glom',\n",
       " 'glonoin',\n",
       " 'gloom',\n",
       " 'glooming',\n",
       " 'gnomon',\n",
       " 'go',\n",
       " 'gog',\n",
       " 'gogo',\n",
       " 'goi',\n",
       " 'going',\n",
       " 'gol',\n",
       " 'goli',\n",
       " 'gon',\n",
       " 'gong',\n",
       " 'gonion',\n",
       " 'goo',\n",
       " 'googol',\n",
       " 'gook',\n",
       " 'gool',\n",
       " 'goon',\n",
       " 'h',\n",
       " 'hi',\n",
       " 'high',\n",
       " 'hill',\n",
       " 'him',\n",
       " 'hin',\n",
       " 'hing',\n",
       " 'hinoki',\n",
       " 'ho',\n",
       " 'hog',\n",
       " 'hoggin',\n",
       " 'hogling',\n",
       " 'hoi',\n",
       " 'hoin',\n",
       " 'holing',\n",
       " 'holl',\n",
       " 'hollin',\n",
       " 'hollo',\n",
       " 'hollong',\n",
       " 'holm',\n",
       " 'homo',\n",
       " 'homologon',\n",
       " 'hong',\n",
       " 'honk',\n",
       " 'hook',\n",
       " 'hoon',\n",
       " 'i',\n",
       " 'igloo',\n",
       " 'ihi',\n",
       " 'ilk',\n",
       " 'ill',\n",
       " 'imi',\n",
       " 'imino',\n",
       " 'immi',\n",
       " 'in',\n",
       " 'ing',\n",
       " 'ingoing',\n",
       " 'inion',\n",
       " 'ink',\n",
       " 'inkling',\n",
       " 'inlook',\n",
       " 'inn',\n",
       " 'inning',\n",
       " 'io',\n",
       " 'ion',\n",
       " 'j',\n",
       " 'jhool',\n",
       " 'jig',\n",
       " 'jing',\n",
       " 'jingling',\n",
       " 'jingo',\n",
       " 'jinjili',\n",
       " 'jink',\n",
       " 'jinn',\n",
       " 'jinni',\n",
       " 'jo',\n",
       " 'jog',\n",
       " 'johnin',\n",
       " 'join',\n",
       " 'joining',\n",
       " 'joll',\n",
       " 'joom',\n",
       " 'k',\n",
       " 'kiki',\n",
       " 'kil',\n",
       " 'kilhig',\n",
       " 'kilim',\n",
       " 'kill',\n",
       " 'killing',\n",
       " 'kiln',\n",
       " 'kilo',\n",
       " 'kim',\n",
       " 'kimono',\n",
       " 'kin',\n",
       " 'king',\n",
       " 'kingling',\n",
       " 'kink',\n",
       " 'kino',\n",
       " 'klom',\n",
       " 'knoll',\n",
       " 'ko',\n",
       " 'kohl',\n",
       " 'koi',\n",
       " 'koil',\n",
       " 'koilon',\n",
       " 'koinon',\n",
       " 'kokil',\n",
       " 'kokio',\n",
       " 'koko',\n",
       " 'kokoon',\n",
       " 'kolo',\n",
       " 'kolokolo',\n",
       " 'kon',\n",
       " 'kongoni',\n",
       " 'konini',\n",
       " 'l',\n",
       " 'li',\n",
       " 'lignin',\n",
       " 'liin',\n",
       " 'likin',\n",
       " 'liking',\n",
       " 'liknon',\n",
       " 'lill',\n",
       " 'lim',\n",
       " 'liming',\n",
       " 'limn',\n",
       " 'limonin',\n",
       " 'lin',\n",
       " 'ling',\n",
       " 'lingo',\n",
       " 'linin',\n",
       " 'lining',\n",
       " 'link',\n",
       " 'linking',\n",
       " 'linn',\n",
       " 'lino',\n",
       " 'linolin',\n",
       " 'linon',\n",
       " 'lion',\n",
       " 'lo',\n",
       " 'log',\n",
       " 'loggin',\n",
       " 'logging',\n",
       " 'login',\n",
       " 'logion',\n",
       " 'logoi',\n",
       " 'loin',\n",
       " 'loll',\n",
       " 'long',\n",
       " 'longing',\n",
       " 'loo',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'loom',\n",
       " 'looming',\n",
       " 'loon',\n",
       " 'm',\n",
       " 'mho',\n",
       " 'mi',\n",
       " 'mig',\n",
       " 'miglio',\n",
       " 'mignon',\n",
       " 'mijl',\n",
       " 'mil',\n",
       " 'milk',\n",
       " 'milking',\n",
       " 'mill',\n",
       " 'milling',\n",
       " 'million',\n",
       " 'milo',\n",
       " 'mim',\n",
       " 'min',\n",
       " 'ming',\n",
       " 'minikin',\n",
       " 'minim',\n",
       " 'mining',\n",
       " 'minion',\n",
       " 'mink',\n",
       " 'minning',\n",
       " 'mino',\n",
       " 'mo',\n",
       " 'mog',\n",
       " 'mogo',\n",
       " 'moho',\n",
       " 'moil',\n",
       " 'moiling',\n",
       " 'moio',\n",
       " 'mojo',\n",
       " 'moki',\n",
       " 'moko',\n",
       " 'momo',\n",
       " 'mon',\n",
       " 'mong',\n",
       " 'monk',\n",
       " 'mono',\n",
       " 'moo',\n",
       " 'mooing',\n",
       " 'mool',\n",
       " 'moon',\n",
       " 'mooning',\n",
       " 'n',\n",
       " 'ni',\n",
       " 'nig',\n",
       " 'niggling',\n",
       " 'nigh',\n",
       " 'nil',\n",
       " 'nim',\n",
       " 'ninon',\n",
       " 'niog',\n",
       " 'no',\n",
       " 'nog',\n",
       " 'noggin',\n",
       " 'nogging',\n",
       " 'noil',\n",
       " 'noll',\n",
       " 'nolo',\n",
       " 'non',\n",
       " 'nonillion',\n",
       " 'nonion',\n",
       " 'nook',\n",
       " 'nooking',\n",
       " 'noon',\n",
       " 'nooning',\n",
       " 'o',\n",
       " 'oh',\n",
       " 'ohm',\n",
       " 'oho',\n",
       " 'oii',\n",
       " 'oil',\n",
       " 'oki',\n",
       " 'olio',\n",
       " 'olm',\n",
       " 'om',\n",
       " 'on',\n",
       " 'ongoing',\n",
       " 'onion',\n",
       " 'onlook',\n",
       " 'onlooking',\n",
       " 'oolong']"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wordlist if re.search('^[g-o]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the + symbol a bit further. Notice that it can be applied to individual letters, or to bracketed sets of letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " 'miiiiiinnnnnnnnnneeeeeeee',\n",
       " 'mine',\n",
       " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^m+i+n+e+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'aaaaaaaaaaaaaaaaa',\n",
       " 'aaahhhh',\n",
       " 'ah',\n",
       " 'ahah',\n",
       " 'ahahah',\n",
       " 'ahh',\n",
       " 'ahhahahaha',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhhh',\n",
       " 'ahhhhhhhhhhhhhh',\n",
       " 'h',\n",
       " 'ha',\n",
       " 'haaa',\n",
       " 'hah',\n",
       " 'haha',\n",
       " 'hahaaa',\n",
       " 'hahah',\n",
       " 'hahaha',\n",
       " 'hahahaa',\n",
       " 'hahahah',\n",
       " 'hahahaha',\n",
       " 'hahahahaaa',\n",
       " 'hahahahahaha',\n",
       " 'hahahahahahaha',\n",
       " 'hahahahahahahahahahahahahahahaha',\n",
       " 'hahahhahah',\n",
       " 'hahhahahaha']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^[ha]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kleene closures (*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It should be clear that + simply means \"one or more instances of the preceding item\", which could be an individual character like m, a set like [fed] or a range like [d-f]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's replace + with *, which means \"zero or more instances of the preceding item\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regular expression «^m*i*n*e*$» will match everything that we found using «^m+i+n+e+$», but also words where some of the letters don't appear at all, e.g. me, min, and mmmmm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the + and * symbols are sometimes referred to as Kleene closures, or simply closures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'e',\n",
       " 'i',\n",
       " 'in',\n",
       " 'm',\n",
       " 'me',\n",
       " 'meeeeeeeeeeeee',\n",
       " 'mi',\n",
       " 'miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " 'miiiiiinnnnnnnnnneeeeeeee',\n",
       " 'min',\n",
       " 'mine',\n",
       " 'mm',\n",
       " 'mmm',\n",
       " 'mmmm',\n",
       " 'mmmmm',\n",
       " 'mmmmmm',\n",
       " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee',\n",
       " 'mmmmmmmmmm',\n",
       " 'mmmmmmmmmmmmm',\n",
       " 'mmmmmmmmmmmmmm',\n",
       " 'n',\n",
       " 'ne']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^m*i*n*e*$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ^ operator has another function when it appears as the first character inside square brackets. For example «[^aeiouAEIOU]» matches any character other than a vowel. We can search the NPS Chat Corpus for words that are made up entirely of non-vowel characters using «^[^aeiouAEIOU]+$» to find items like these: :):):), grrr, cyb3r and zzzzzzzz. Notice this includes non-alphabetic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '!!',\n",
       " '!!!',\n",
       " '!!!!',\n",
       " '!!!!!',\n",
       " '!!!!!!',\n",
       " '!!!!!!!',\n",
       " '!!!!!!!!',\n",
       " '!!!!!!!!!',\n",
       " '!!!!!!!!!!',\n",
       " '!!!!!!!!!!!',\n",
       " '!!!!!!!!!!!!!',\n",
       " '!!!!!!!!!!!!!!!!',\n",
       " '!!!!!!!!!!!!!!!!!!!!!!',\n",
       " '!!!!!!!!!!!!!!!!!!!!!!!',\n",
       " '!!!!!!!!!!!!!!!!!!!!!!!!!!!',\n",
       " '!!!!!!!!!!!!!!!!!!!!!!!!!!!!',\n",
       " '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!',\n",
       " '!!!!!!.',\n",
       " '!!!!!.',\n",
       " '!!!!....',\n",
       " '!!!.',\n",
       " '!!.',\n",
       " '!!...',\n",
       " '!.',\n",
       " '!...',\n",
       " '!=',\n",
       " '!?',\n",
       " '!??',\n",
       " '!???',\n",
       " '\"',\n",
       " '\"...',\n",
       " '\"?',\n",
       " '\"s',\n",
       " '#',\n",
       " '###',\n",
       " '####',\n",
       " '$',\n",
       " '$$',\n",
       " '$27',\n",
       " '&',\n",
       " '&^',\n",
       " \"'\",\n",
       " \"''\",\n",
       " \"'.\",\n",
       " \"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'n'\",\n",
       " \"'s\",\n",
       " '(',\n",
       " '(((',\n",
       " '((((',\n",
       " '(((((',\n",
       " '((((((',\n",
       " '(((((((',\n",
       " '((((((((',\n",
       " '(((((((((',\n",
       " '((((((((((',\n",
       " '(((((((((((',\n",
       " '((((((((((((',\n",
       " '(((((((((((((',\n",
       " '((((((((((((((',\n",
       " '(((((((((((((((',\n",
       " '(((((((((((((((((',\n",
       " '((((((((((((((((((',\n",
       " '((((((((((((((((((((',\n",
       " '(((((((((((((((((((((',\n",
       " '(((((((((((((((((((((((',\n",
       " '((((((((((((((((((((((((',\n",
       " '(((((((((((((((((((((((((',\n",
       " '((((((((((((((((((((((((((',\n",
       " '(((((..',\n",
       " '(*&(^',\n",
       " '(.',\n",
       " ')',\n",
       " ')))',\n",
       " '))))',\n",
       " ')))))',\n",
       " ')))))))',\n",
       " '))))))))',\n",
       " ')))))))))',\n",
       " '))))))))))',\n",
       " ')))))))))))',\n",
       " '))))))))))))',\n",
       " ')))))))))))))',\n",
       " '))))))))))))))',\n",
       " ')))))))))))))))',\n",
       " ')))))))))))))))))',\n",
       " ')))))))))))))))))))',\n",
       " ')))))))))))))))))))))',\n",
       " '))))))))))))))))))))))',\n",
       " '))))))))))))))))))))))))))))',\n",
       " ')))))))))))))))))))))))))))))))',\n",
       " ')?',\n",
       " '*',\n",
       " '******',\n",
       " '*VBS*',\n",
       " '+',\n",
       " '+*+*+*+*',\n",
       " '++',\n",
       " ',',\n",
       " ',,',\n",
       " ',,,',\n",
       " ',,,,',\n",
       " ',,,,,',\n",
       " ',,,,,,,',\n",
       " ',,,,,,,,,,,',\n",
       " '-',\n",
       " '-(',\n",
       " '--',\n",
       " '-------------',\n",
       " '--------------------',\n",
       " '--------->',\n",
       " '-->',\n",
       " '-...)...-',\n",
       " '-17',\n",
       " '-21',\n",
       " '-6',\n",
       " '-_-',\n",
       " '-s',\n",
       " '.',\n",
       " '. .',\n",
       " '. . .',\n",
       " '. ...',\n",
       " '.(.',\n",
       " '.(..(.vMp3 v1.7.4.).)',\n",
       " '.)',\n",
       " '.).',\n",
       " '..',\n",
       " '.. .',\n",
       " '..(..',\n",
       " '...',\n",
       " '....',\n",
       " '.....',\n",
       " '......',\n",
       " '.......',\n",
       " '........',\n",
       " '.........',\n",
       " '..........',\n",
       " '...........',\n",
       " '............',\n",
       " '.............',\n",
       " '................',\n",
       " '..................',\n",
       " '...................',\n",
       " '....................',\n",
       " '........................',\n",
       " '..............................',\n",
       " '.45',\n",
       " '.:',\n",
       " '.;)',\n",
       " '/',\n",
       " '//',\n",
       " '0',\n",
       " '05.',\n",
       " '06.',\n",
       " '1',\n",
       " '1.98',\n",
       " '1.99',\n",
       " '10',\n",
       " '100',\n",
       " '100%',\n",
       " '1012.',\n",
       " '1016.',\n",
       " '102.6',\n",
       " '10:49',\n",
       " '10th',\n",
       " '11',\n",
       " '12',\n",
       " '12%',\n",
       " '1200',\n",
       " '121.7',\n",
       " '1299',\n",
       " '13',\n",
       " '138',\n",
       " '14',\n",
       " '14-16',\n",
       " '147.7',\n",
       " '15',\n",
       " '16',\n",
       " '16.',\n",
       " '17',\n",
       " '18',\n",
       " '185',\n",
       " '18ST',\n",
       " '19',\n",
       " '1900',\n",
       " '1930',\n",
       " '1980',\n",
       " '1985',\n",
       " '1996',\n",
       " '2',\n",
       " '2.3',\n",
       " '20',\n",
       " '20.',\n",
       " '2006',\n",
       " '20S',\n",
       " '20s',\n",
       " '21',\n",
       " '22',\n",
       " '220',\n",
       " '224',\n",
       " '23',\n",
       " '24',\n",
       " '246',\n",
       " '247',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '280',\n",
       " '28147',\n",
       " '29',\n",
       " '29.88.',\n",
       " '295',\n",
       " '29803',\n",
       " '2:55',\n",
       " '2nd',\n",
       " '3',\n",
       " '30',\n",
       " '30.',\n",
       " '30.00.',\n",
       " '300',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '3333333',\n",
       " '33982',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '360',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '39.3',\n",
       " '396',\n",
       " '3:45',\n",
       " '3~<-..4@.',\n",
       " '4',\n",
       " '4.20',\n",
       " '41',\n",
       " '423',\n",
       " '43',\n",
       " '43.',\n",
       " '45',\n",
       " '45.5',\n",
       " '453',\n",
       " '46',\n",
       " '46.',\n",
       " '47',\n",
       " '47.',\n",
       " '49',\n",
       " '4:03',\n",
       " '5',\n",
       " '50',\n",
       " '51',\n",
       " '53',\n",
       " '55',\n",
       " '55%',\n",
       " '55.',\n",
       " '56',\n",
       " '56.',\n",
       " '57',\n",
       " '57401',\n",
       " '579',\n",
       " '59',\n",
       " '59%',\n",
       " '6',\n",
       " '60',\n",
       " '60s',\n",
       " '64.8',\n",
       " '65%',\n",
       " '68%',\n",
       " '69',\n",
       " '6:38',\n",
       " '6:41',\n",
       " '6:51',\n",
       " '6:53',\n",
       " '7',\n",
       " '70%',\n",
       " '700',\n",
       " '73%',\n",
       " '73042',\n",
       " '75',\n",
       " '75%',\n",
       " '76%',\n",
       " '77',\n",
       " '7:45',\n",
       " '8',\n",
       " '80',\n",
       " '8082653953',\n",
       " '818',\n",
       " '85%',\n",
       " '9',\n",
       " '9.53',\n",
       " '90',\n",
       " '92129',\n",
       " '92780',\n",
       " '93',\n",
       " '93%',\n",
       " '95953',\n",
       " '98.5',\n",
       " '98.6',\n",
       " '99',\n",
       " '99701',\n",
       " '99703',\n",
       " '9:10',\n",
       " ':',\n",
       " ':(',\n",
       " ':)',\n",
       " ':):):)',\n",
       " ':-(',\n",
       " ':-)',\n",
       " ':-@',\n",
       " ':.',\n",
       " ':/',\n",
       " ':@',\n",
       " ':D',\n",
       " ':P',\n",
       " ':]',\n",
       " ':p',\n",
       " ':|',\n",
       " ';',\n",
       " '; ..',\n",
       " ';)',\n",
       " ';-(',\n",
       " ';-)',\n",
       " ';0',\n",
       " ';]',\n",
       " ';p',\n",
       " '<',\n",
       " '<,',\n",
       " '<-',\n",
       " '<--',\n",
       " '<---',\n",
       " '<----',\n",
       " '<----------',\n",
       " '<3',\n",
       " \"<3's\",\n",
       " '<33',\n",
       " '<333',\n",
       " '<3333',\n",
       " '<33333',\n",
       " '<333333333',\n",
       " '<3333333333333333',\n",
       " '<33333333333333333',\n",
       " '<<',\n",
       " '<<<',\n",
       " '<<<<',\n",
       " '<<<<,',\n",
       " '<<<<<',\n",
       " '<<<<<<',\n",
       " '<<<<<<,',\n",
       " '<<<<<<<',\n",
       " '<<<<<<<<<<<<<<',\n",
       " '<~~~',\n",
       " '=',\n",
       " \"='s\",\n",
       " '=(',\n",
       " '=)',\n",
       " '=-\\\\',\n",
       " '=/',\n",
       " '=D',\n",
       " '=[',\n",
       " '=]',\n",
       " '=p',\n",
       " '>',\n",
       " '>.>',\n",
       " '>.>->',\n",
       " '>:->',\n",
       " '>>>',\n",
       " '>>>>>>>>>>',\n",
       " '>>>>>>>>>>>',\n",
       " '>>>>>>>>>>>>',\n",
       " '>?',\n",
       " '>_>',\n",
       " '?',\n",
       " '?!',\n",
       " '?!?!',\n",
       " '?!?!?',\n",
       " \"?'\",\n",
       " '?.',\n",
       " '?..',\n",
       " '?....',\n",
       " '??',\n",
       " '??!!',\n",
       " '??!?!??!',\n",
       " '???',\n",
       " '????',\n",
       " '?????',\n",
       " '??????',\n",
       " '???????',\n",
       " '????????',\n",
       " '?????????',\n",
       " '??@',\n",
       " '@',\n",
       " '@$$',\n",
       " \"@-,'~\",\n",
       " \"@..3-,'~.\",\n",
       " 'B',\n",
       " 'C',\n",
       " 'CDT',\n",
       " 'CST',\n",
       " 'CT',\n",
       " 'Cry',\n",
       " 'Ct',\n",
       " 'Ctrl',\n",
       " 'D',\n",
       " 'DJ',\n",
       " 'DVD',\n",
       " 'Dr',\n",
       " 'Dr.',\n",
       " 'F',\n",
       " 'F5',\n",
       " 'FF',\n",
       " 'FL',\n",
       " 'G',\n",
       " 'GN',\n",
       " 'GNG',\n",
       " 'GrlZ',\n",
       " 'Gs',\n",
       " 'H',\n",
       " 'H0rny',\n",
       " 'Hmm',\n",
       " 'JRZ',\n",
       " 'K',\n",
       " 'LPN',\n",
       " 'M',\n",
       " 'MD',\n",
       " 'MP3',\n",
       " 'MSN',\n",
       " 'MY',\n",
       " 'Mmm',\n",
       " 'Mp3',\n",
       " 'Ms',\n",
       " 'My',\n",
       " 'N',\n",
       " 'N\"T',\n",
       " \"N'T\",\n",
       " 'NC',\n",
       " 'NTMN',\n",
       " 'NY',\n",
       " 'P',\n",
       " 'P.',\n",
       " 'PDT',\n",
       " 'PM',\n",
       " \"PM's\",\n",
       " 'PMSL',\n",
       " 'PMs',\n",
       " 'PS',\n",
       " 'PST',\n",
       " 'Plssss',\n",
       " 'PmS',\n",
       " 'QQ',\n",
       " 'R',\n",
       " \"RN's\",\n",
       " 'S',\n",
       " 'S.M.R.',\n",
       " 'S3x0r',\n",
       " 'St',\n",
       " 'TC',\n",
       " 'TX',\n",
       " 'TY',\n",
       " 'TYPR',\n",
       " 'Ty',\n",
       " 'W',\n",
       " 'WHY',\n",
       " 'WTF',\n",
       " 'Wb',\n",
       " 'Why',\n",
       " 'Wtf',\n",
       " 'X',\n",
       " 'XXXXXXXXXX',\n",
       " '[[[[[[[[[[[[[[[[[[',\n",
       " '\\\\',\n",
       " '\\\\ty',\n",
       " ']:)',\n",
       " ']]]]]]]]]]]]]]]]]]]]]',\n",
       " '^',\n",
       " '^^',\n",
       " '^^^',\n",
       " '^_^',\n",
       " '_',\n",
       " '`',\n",
       " 'b',\n",
       " 'b/c',\n",
       " 'b4',\n",
       " 'bbl',\n",
       " 'bbs',\n",
       " 'bc',\n",
       " 'bf',\n",
       " 'bj',\n",
       " 'brb',\n",
       " 'brbbb',\n",
       " 'brrrrrrr',\n",
       " 'brwn',\n",
       " 'btw',\n",
       " 'by',\n",
       " 'byb',\n",
       " 'c',\n",
       " \"c'm\",\n",
       " 'chp',\n",
       " 'ck',\n",
       " 'cpr',\n",
       " 'cry',\n",
       " 'cyb3r',\n",
       " 'd',\n",
       " 'd=',\n",
       " 'dd',\n",
       " 'dj',\n",
       " 'dl',\n",
       " 'dr',\n",
       " 'dry',\n",
       " 'dsklgjsdk',\n",
       " 'f',\n",
       " 'f.',\n",
       " 'fck',\n",
       " 'fl',\n",
       " 'fly',\n",
       " 'frm',\n",
       " 'frst',\n",
       " 'ft',\n",
       " 'ft.',\n",
       " 'fwd',\n",
       " \"g'\",\n",
       " 'gf',\n",
       " 'gm',\n",
       " 'gn',\n",
       " 'grrl',\n",
       " 'grrr',\n",
       " 'grrrrrrrr',\n",
       " 'grrrrrrrrr',\n",
       " 'grrrrrrrrrrrrrrrrr',\n",
       " 'gtg',\n",
       " 'h',\n",
       " 'h.s',\n",
       " 'hb',\n",
       " 'hfglhs',\n",
       " 'hgfhgfjgf',\n",
       " 'hm',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hmmmm',\n",
       " 'hmmmmm',\n",
       " 'hmmmmmmm',\n",
       " 'hmmmmmmmm',\n",
       " 'hmmmmmmmmmm',\n",
       " 'hmph',\n",
       " 'hr',\n",
       " 'hrs',\n",
       " 'http',\n",
       " 'hx',\n",
       " 'hyy',\n",
       " 'j',\n",
       " 'j/k',\n",
       " 'j/p',\n",
       " 'jk',\n",
       " 'jr',\n",
       " 'jw',\n",
       " 'k',\n",
       " \"k's\",\n",
       " 'kc',\n",
       " 'kmph',\n",
       " 'knw',\n",
       " 'kts',\n",
       " 'ky',\n",
       " 'l',\n",
       " 'lb',\n",
       " 'lbs',\n",
       " 'ldskdlsf',\n",
       " 'll',\n",
       " 'ltnc',\n",
       " 'ltns',\n",
       " 'ltr',\n",
       " 'm',\n",
       " 'md',\n",
       " 'mhm',\n",
       " 'mm',\n",
       " 'mmhmm',\n",
       " 'mmm',\n",
       " 'mmmm',\n",
       " 'mmmmk',\n",
       " 'mmmmm',\n",
       " 'mmmmmm',\n",
       " 'mmmmmmmmmm',\n",
       " 'mmmmmmmmmmmmm',\n",
       " 'mmmmmmmmmmmmmm',\n",
       " 'mp3',\n",
       " 'ms',\n",
       " 'ms.',\n",
       " 'msg',\n",
       " 'msn',\n",
       " 'my',\n",
       " 'n',\n",
       " 'n\"t',\n",
       " \"n't\",\n",
       " 'n.n',\n",
       " 'n/',\n",
       " 'n;t',\n",
       " 'nbc',\n",
       " 'nc',\n",
       " 'nd',\n",
       " 'nj',\n",
       " 'nm',\n",
       " 'ny',\n",
       " 'nyc',\n",
       " 'nz',\n",
       " 'p',\n",
       " 'pc',\n",
       " 'pffft',\n",
       " 'pfft',\n",
       " 'plz',\n",
       " 'pm',\n",
       " \"pm'n\",\n",
       " \"pm's\",\n",
       " 'pms',\n",
       " 'pmsl',\n",
       " 'pp',\n",
       " 'ppl',\n",
       " 'pr',\n",
       " 'prrty',\n",
       " 'ps2',\n",
       " 'psh',\n",
       " 'pssssh',\n",
       " 'pssst',\n",
       " 'pvt',\n",
       " 'pwns',\n",
       " 'px',\n",
       " 'r',\n",
       " 's',\n",
       " \"s'\",\n",
       " 'sdlfkjsj',\n",
       " 'sf',\n",
       " 'shhhh',\n",
       " 'sky',\n",
       " 'sldfjlsdf',\n",
       " 'slkfjsldkfjs',\n",
       " 'sp',\n",
       " 'sry',\n",
       " 'st',\n",
       " 'sw',\n",
       " 'syck',\n",
       " 't',\n",
       " 't/c',\n",
       " 't/y',\n",
       " 'tc',\n",
       " 'td',\n",
       " 'tdr',\n",
       " 'thnx',\n",
       " 'thx',\n",
       " 'tks',\n",
       " 'try',\n",
       " 'tv',\n",
       " 'tx',\n",
       " 'ty',\n",
       " 'tyvm',\n",
       " 'vm',\n",
       " 'vs.',\n",
       " 'w',\n",
       " 'w/',\n",
       " 'w/b',\n",
       " 'wb',\n",
       " 'wc',\n",
       " 'why',\n",
       " 'whys',\n",
       " 'wtf',\n",
       " 'wth',\n",
       " 'wv',\n",
       " 'wz',\n",
       " 'x',\n",
       " 'xD',\n",
       " 'xxxxxx',\n",
       " 'y',\n",
       " \"y'\",\n",
       " 'y/w',\n",
       " 'yr',\n",
       " 'yrs',\n",
       " 'ysssssssss',\n",
       " 'yvw',\n",
       " 'yw',\n",
       " \"yw's\",\n",
       " 'zzzzzzzz',\n",
       " '~',\n",
       " '~!']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in chat_words if re.search('^[^aeiouAEIOU]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some more examples of regular expressions being used to find tokens that match a particular pattern, illustrating the use of some new symbols: \\, {}, (), and |:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You probably worked out that a backslash means that the following character is deprived of its special powers and must literally match a specific character in the word. Thus, while . is special, \\. only matches a period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The braced expressions, like {3,5}, specify the number of repeats of the previous item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pipe character indicates a choice between the material on its left or its right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parentheses indicate the scope of an operator: they can be used together with the pipe (or disjunction) symbol like this: «w(i|e|ai|oo)t», matching wit, wet, wait, and woot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0085',\n",
       " '0.05',\n",
       " '0.1',\n",
       " '0.16',\n",
       " '0.2',\n",
       " '0.25',\n",
       " '0.28',\n",
       " '0.3',\n",
       " '0.4',\n",
       " '0.5',\n",
       " '0.50',\n",
       " '0.54',\n",
       " '0.56',\n",
       " '0.60',\n",
       " '0.7',\n",
       " '0.82',\n",
       " '0.84',\n",
       " '0.9',\n",
       " '0.95',\n",
       " '0.99',\n",
       " '1.01',\n",
       " '1.1',\n",
       " '1.125',\n",
       " '1.14',\n",
       " '1.1650',\n",
       " '1.17',\n",
       " '1.18',\n",
       " '1.19',\n",
       " '1.2',\n",
       " '1.20',\n",
       " '1.24',\n",
       " '1.25',\n",
       " '1.26',\n",
       " '1.28',\n",
       " '1.35',\n",
       " '1.39',\n",
       " '1.4',\n",
       " '1.457',\n",
       " '1.46',\n",
       " '1.49',\n",
       " '1.5',\n",
       " '1.50',\n",
       " '1.55',\n",
       " '1.56',\n",
       " '1.5755',\n",
       " '1.5805',\n",
       " '1.6',\n",
       " '1.61',\n",
       " '1.637',\n",
       " '1.64',\n",
       " '1.65',\n",
       " '1.7',\n",
       " '1.75',\n",
       " '1.76',\n",
       " '1.8',\n",
       " '1.82',\n",
       " '1.8415',\n",
       " '1.85',\n",
       " '1.8500',\n",
       " '1.9',\n",
       " '1.916',\n",
       " '1.92',\n",
       " '10.19',\n",
       " '10.2',\n",
       " '10.5',\n",
       " '107.03',\n",
       " '107.9',\n",
       " '109.73',\n",
       " '11.10',\n",
       " '11.5',\n",
       " '11.57',\n",
       " '11.6',\n",
       " '11.72',\n",
       " '11.95',\n",
       " '112.9',\n",
       " '113.2',\n",
       " '116.3',\n",
       " '116.4',\n",
       " '116.7',\n",
       " '116.9',\n",
       " '118.6',\n",
       " '12.09',\n",
       " '12.5',\n",
       " '12.52',\n",
       " '12.68',\n",
       " '12.7',\n",
       " '12.82',\n",
       " '12.97',\n",
       " '120.7',\n",
       " '1206.26',\n",
       " '121.6',\n",
       " '126.1',\n",
       " '126.15',\n",
       " '127.03',\n",
       " '129.91',\n",
       " '13.1',\n",
       " '13.15',\n",
       " '13.5',\n",
       " '13.50',\n",
       " '13.625',\n",
       " '13.65',\n",
       " '13.73',\n",
       " '13.8',\n",
       " '13.90',\n",
       " '130.6',\n",
       " '130.7',\n",
       " '131.01',\n",
       " '132.9',\n",
       " '133.7',\n",
       " '133.8',\n",
       " '14.00',\n",
       " '14.13',\n",
       " '14.26',\n",
       " '14.28',\n",
       " '14.43',\n",
       " '14.5',\n",
       " '14.53',\n",
       " '14.54',\n",
       " '14.6',\n",
       " '14.75',\n",
       " '14.99',\n",
       " '141.9',\n",
       " '142.84',\n",
       " '142.85',\n",
       " '143.08',\n",
       " '143.80',\n",
       " '143.93',\n",
       " '148.9',\n",
       " '149.9',\n",
       " '15.5',\n",
       " '150.00',\n",
       " '153.3',\n",
       " '154.2',\n",
       " '16.05',\n",
       " '16.09',\n",
       " '16.125',\n",
       " '16.2',\n",
       " '16.5',\n",
       " '16.68',\n",
       " '16.7',\n",
       " '16.9',\n",
       " '169.9',\n",
       " '17.3',\n",
       " '17.4',\n",
       " '17.5',\n",
       " '17.95',\n",
       " '1738.1',\n",
       " '176.1',\n",
       " '18.3',\n",
       " '18.6',\n",
       " '18.95',\n",
       " '185.9',\n",
       " '188.84',\n",
       " '19.3',\n",
       " '19.50',\n",
       " '19.6',\n",
       " '19.94',\n",
       " '19.95',\n",
       " '191.9',\n",
       " '2.07',\n",
       " '2.1',\n",
       " '2.15',\n",
       " '2.19',\n",
       " '2.2',\n",
       " '2.25',\n",
       " '2.29',\n",
       " '2.3',\n",
       " '2.30',\n",
       " '2.35',\n",
       " '2.375',\n",
       " '2.4',\n",
       " '2.42',\n",
       " '2.44',\n",
       " '2.46',\n",
       " '2.47',\n",
       " '2.5',\n",
       " '2.50',\n",
       " '2.6',\n",
       " '2.62',\n",
       " '2.65',\n",
       " '2.7',\n",
       " '2.75',\n",
       " '2.8',\n",
       " '2.80',\n",
       " '2.87',\n",
       " '2.875',\n",
       " '2.9',\n",
       " '2.95',\n",
       " '20.07',\n",
       " '20.5',\n",
       " '21.1',\n",
       " '21.9',\n",
       " '2141.7',\n",
       " '2160.1',\n",
       " '2163.2',\n",
       " '22.75',\n",
       " '220.45',\n",
       " '221.4',\n",
       " '225.6',\n",
       " '23.25',\n",
       " '23.4',\n",
       " '23.5',\n",
       " '23.72',\n",
       " '234.4',\n",
       " '236.74',\n",
       " '236.79',\n",
       " '24.95',\n",
       " '25.50',\n",
       " '25.6',\n",
       " '251.2',\n",
       " '26.2',\n",
       " '26.5',\n",
       " '26.8',\n",
       " '263.07',\n",
       " '2645.90',\n",
       " '2691.19',\n",
       " '27.1',\n",
       " '27.4',\n",
       " '273.5',\n",
       " '278.7',\n",
       " '28.25',\n",
       " '28.36',\n",
       " '28.4',\n",
       " '28.5',\n",
       " '28.53',\n",
       " '28.6',\n",
       " '29.3',\n",
       " '29.4',\n",
       " '29.9',\n",
       " '292.32',\n",
       " '3.01',\n",
       " '3.04',\n",
       " '3.1',\n",
       " '3.16',\n",
       " '3.18',\n",
       " '3.19',\n",
       " '3.2',\n",
       " '3.20',\n",
       " '3.23',\n",
       " '3.253',\n",
       " '3.28',\n",
       " '3.3',\n",
       " '3.35',\n",
       " '3.375',\n",
       " '3.4',\n",
       " '3.42',\n",
       " '3.43',\n",
       " '3.5',\n",
       " '3.55',\n",
       " '3.6',\n",
       " '3.61',\n",
       " '3.625',\n",
       " '3.7',\n",
       " '3.75',\n",
       " '3.8',\n",
       " '3.80',\n",
       " '3.9',\n",
       " '30.6',\n",
       " '30.9',\n",
       " '319.75',\n",
       " '32.8',\n",
       " '334.5',\n",
       " '34.625',\n",
       " '341.20',\n",
       " '3436.58',\n",
       " '35.2',\n",
       " '35.7',\n",
       " '352.7',\n",
       " '352.9',\n",
       " '35500.64',\n",
       " '35564.43',\n",
       " '36.9',\n",
       " '361.8',\n",
       " '3648.82',\n",
       " '37.3',\n",
       " '37.5',\n",
       " '372.14',\n",
       " '372.9',\n",
       " '374.19',\n",
       " '374.20',\n",
       " '377.60',\n",
       " '38.3',\n",
       " '38.375',\n",
       " '38.5',\n",
       " '38.875',\n",
       " '387.8',\n",
       " '4.1',\n",
       " '4.10',\n",
       " '4.2',\n",
       " '4.25',\n",
       " '4.3',\n",
       " '4.4',\n",
       " '4.5',\n",
       " '4.55',\n",
       " '4.6',\n",
       " '4.7',\n",
       " '4.75',\n",
       " '4.8',\n",
       " '4.875',\n",
       " '4.898',\n",
       " '4.9',\n",
       " '40.21',\n",
       " '41.60',\n",
       " '415.6',\n",
       " '415.8',\n",
       " '42.1',\n",
       " '42.5',\n",
       " '422.5',\n",
       " '43.875',\n",
       " '434.4',\n",
       " '436.01',\n",
       " '446.62',\n",
       " '449.04',\n",
       " '45.2',\n",
       " '45.3',\n",
       " '45.75',\n",
       " '456.64',\n",
       " '46.1',\n",
       " '47.1',\n",
       " '47.125',\n",
       " '47.5',\n",
       " '47.6',\n",
       " '49.9',\n",
       " '494.50',\n",
       " '497.34',\n",
       " '5.1',\n",
       " '5.2180',\n",
       " '5.276',\n",
       " '5.29',\n",
       " '5.3',\n",
       " '5.39',\n",
       " '5.4',\n",
       " '5.435',\n",
       " '5.5',\n",
       " '5.57',\n",
       " '5.6',\n",
       " '5.63',\n",
       " '5.7',\n",
       " '5.70',\n",
       " '5.8',\n",
       " '5.82',\n",
       " '5.9',\n",
       " '5.92',\n",
       " '50.1',\n",
       " '50.38',\n",
       " '50.45',\n",
       " '51.25',\n",
       " '51.6',\n",
       " '55.1',\n",
       " '566.54',\n",
       " '57.50',\n",
       " '57.6',\n",
       " '57.7',\n",
       " '58.64',\n",
       " '59.6',\n",
       " '59.9',\n",
       " '6.03',\n",
       " '6.1',\n",
       " '6.20',\n",
       " '6.21',\n",
       " '6.25',\n",
       " '6.4',\n",
       " '6.40',\n",
       " '6.44',\n",
       " '6.5',\n",
       " '6.50',\n",
       " '6.53',\n",
       " '6.6',\n",
       " '6.7',\n",
       " '6.70',\n",
       " '6.79',\n",
       " '6.84',\n",
       " '6.9',\n",
       " '60.36',\n",
       " '618.1',\n",
       " '62.1',\n",
       " '62.5',\n",
       " '62.625',\n",
       " '63.79',\n",
       " '630.9',\n",
       " '64.5',\n",
       " '66.5',\n",
       " '7.15',\n",
       " '7.2',\n",
       " '7.20',\n",
       " '7.272',\n",
       " '7.3',\n",
       " '7.4',\n",
       " '7.40',\n",
       " '7.422',\n",
       " '7.45',\n",
       " '7.458',\n",
       " '7.5',\n",
       " '7.50',\n",
       " '7.52',\n",
       " '7.55',\n",
       " '7.60',\n",
       " '7.62',\n",
       " '7.63',\n",
       " '7.65',\n",
       " '7.74',\n",
       " '7.78',\n",
       " '7.79',\n",
       " '7.8',\n",
       " '7.80',\n",
       " '7.84',\n",
       " '7.88',\n",
       " '7.90',\n",
       " '7.95',\n",
       " '70.2',\n",
       " '70.7',\n",
       " '705.6',\n",
       " '72.7',\n",
       " '734.9',\n",
       " '737.5',\n",
       " '77.56',\n",
       " '77.6',\n",
       " '77.70',\n",
       " '8.04',\n",
       " '8.06',\n",
       " '8.07',\n",
       " '8.1',\n",
       " '8.12',\n",
       " '8.14',\n",
       " '8.15',\n",
       " '8.19',\n",
       " '8.2',\n",
       " '8.22',\n",
       " '8.25',\n",
       " '8.30',\n",
       " '8.35',\n",
       " '8.45',\n",
       " '8.467',\n",
       " '8.47',\n",
       " '8.48',\n",
       " '8.5',\n",
       " '8.50',\n",
       " '8.53',\n",
       " '8.55',\n",
       " '8.56',\n",
       " '8.575',\n",
       " '8.60',\n",
       " '8.64',\n",
       " '8.65',\n",
       " '8.70',\n",
       " '8.75',\n",
       " '8.9',\n",
       " '80.50',\n",
       " '80.8',\n",
       " '81.8',\n",
       " '811.9',\n",
       " '83.4',\n",
       " '84.29',\n",
       " '84.9',\n",
       " '85.1',\n",
       " '85.7',\n",
       " '86.12',\n",
       " '87.5',\n",
       " '88.32',\n",
       " '89.7',\n",
       " '89.9',\n",
       " '9.3',\n",
       " '9.32',\n",
       " '9.37',\n",
       " '9.45',\n",
       " '9.5',\n",
       " '9.625',\n",
       " '9.75',\n",
       " '9.8',\n",
       " '9.82',\n",
       " '9.9',\n",
       " '92.9',\n",
       " '93.3',\n",
       " '93.9',\n",
       " '94.2',\n",
       " '94.8',\n",
       " '95.09',\n",
       " '96.4',\n",
       " '98.3',\n",
       " '99.1',\n",
       " '99.3']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C$', 'US$']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[A-Z]+\\$$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1614',\n",
       " '1637',\n",
       " '1787',\n",
       " '1901',\n",
       " '1903',\n",
       " '1917',\n",
       " '1925',\n",
       " '1929',\n",
       " '1933',\n",
       " '1934',\n",
       " '1948',\n",
       " '1953',\n",
       " '1955',\n",
       " '1956',\n",
       " '1961',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1979',\n",
       " '1980',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '2000',\n",
       " '2005',\n",
       " '2009',\n",
       " '2017',\n",
       " '2019',\n",
       " '2029',\n",
       " '3057',\n",
       " '8300']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]{4}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10-day',\n",
       " '10-lap',\n",
       " '10-year',\n",
       " '100-share',\n",
       " '12-point',\n",
       " '12-year',\n",
       " '14-hour',\n",
       " '15-day',\n",
       " '150-point',\n",
       " '190-point',\n",
       " '20-point',\n",
       " '20-stock',\n",
       " '21-month',\n",
       " '237-seat',\n",
       " '240-page',\n",
       " '27-year',\n",
       " '30-day',\n",
       " '30-point',\n",
       " '30-share',\n",
       " '30-year',\n",
       " '300-day',\n",
       " '36-day',\n",
       " '36-store',\n",
       " '42-year',\n",
       " '50-state',\n",
       " '500-stock',\n",
       " '52-week',\n",
       " '69-point',\n",
       " '84-month',\n",
       " '87-store',\n",
       " '90-day']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black-and-white',\n",
       " 'bread-and-butter',\n",
       " 'father-in-law',\n",
       " 'machine-gun-toting',\n",
       " 'savings-and-loan']"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['62%-owned',\n",
       " 'Absorbed',\n",
       " 'According',\n",
       " 'Adopting',\n",
       " 'Advanced',\n",
       " 'Advancing',\n",
       " 'Alfred',\n",
       " 'Allied',\n",
       " 'Annualized',\n",
       " 'Anything',\n",
       " 'Arbitrage-related',\n",
       " 'Arbitraging',\n",
       " 'Asked',\n",
       " 'Assuming',\n",
       " 'Atlanta-based',\n",
       " 'Baking',\n",
       " 'Banking',\n",
       " 'Beginning',\n",
       " 'Beijing',\n",
       " 'Being',\n",
       " 'Bermuda-based',\n",
       " 'Betting',\n",
       " 'Boeing',\n",
       " 'Broadcasting',\n",
       " 'Bucking',\n",
       " 'Buying',\n",
       " 'Calif.-based',\n",
       " 'Change-ringing',\n",
       " 'Citing',\n",
       " 'Concerned',\n",
       " 'Confronted',\n",
       " 'Conn.based',\n",
       " 'Consolidated',\n",
       " 'Continued',\n",
       " 'Continuing',\n",
       " 'Declining',\n",
       " 'Defending',\n",
       " 'Depending',\n",
       " 'Designated',\n",
       " 'Determining',\n",
       " 'Developed',\n",
       " 'Died',\n",
       " 'During',\n",
       " 'Encouraged',\n",
       " 'Encouraging',\n",
       " 'English-speaking',\n",
       " 'Estimated',\n",
       " 'Everything',\n",
       " 'Excluding',\n",
       " 'Exxon-owned',\n",
       " 'Faulding',\n",
       " 'Fed',\n",
       " 'Feeding',\n",
       " 'Filling',\n",
       " 'Filmed',\n",
       " 'Financing',\n",
       " 'Following',\n",
       " 'Founded',\n",
       " 'Fracturing',\n",
       " 'Francisco-based',\n",
       " 'Fred',\n",
       " 'Funded',\n",
       " 'Funding',\n",
       " 'Generalized',\n",
       " 'Germany-based',\n",
       " 'Getting',\n",
       " 'Guaranteed',\n",
       " 'Having',\n",
       " 'Heating',\n",
       " 'Heightened',\n",
       " 'Holding',\n",
       " 'Housing',\n",
       " 'Illuminating',\n",
       " 'Indeed',\n",
       " 'Indexing',\n",
       " 'Irving',\n",
       " 'Jersey-based',\n",
       " 'Judging',\n",
       " 'Knowing',\n",
       " 'Learning',\n",
       " 'Legislating',\n",
       " 'Leming',\n",
       " 'Limited',\n",
       " 'London-based',\n",
       " 'Manfred',\n",
       " 'Manufacturing',\n",
       " 'Melamed',\n",
       " 'Miami-based',\n",
       " 'Mich.-based',\n",
       " 'Mining',\n",
       " 'Minneapolis-based',\n",
       " 'Mo.-based',\n",
       " 'Mortgage-Backed',\n",
       " 'Moving',\n",
       " 'Muzzling',\n",
       " 'N.J.-based',\n",
       " 'NBC-owned',\n",
       " 'NIH-appointed',\n",
       " 'Named',\n",
       " 'No-Smoking',\n",
       " 'Observing',\n",
       " 'Offering',\n",
       " 'Ohio-based',\n",
       " 'Orleans-based',\n",
       " 'Packaging',\n",
       " 'Performing',\n",
       " 'Philadelphia-based',\n",
       " 'Posted',\n",
       " 'Provided',\n",
       " 'Publishing',\n",
       " 'Purchasing',\n",
       " 'Rated',\n",
       " 'Reached',\n",
       " 'Red',\n",
       " 'Red-blooded',\n",
       " 'Reducing',\n",
       " 'Reed',\n",
       " 'Regarded',\n",
       " 'Rekindled',\n",
       " 'Related',\n",
       " 'Ringing',\n",
       " 'Rolling',\n",
       " 'Sacramento-based',\n",
       " 'Scoring',\n",
       " 'Seattle-based',\n",
       " 'Seed',\n",
       " 'Skilled',\n",
       " 'Smelting',\n",
       " 'Something',\n",
       " 'Spending',\n",
       " 'Standardized',\n",
       " 'Standing',\n",
       " 'Starting',\n",
       " 'Sterling',\n",
       " 'Taking',\n",
       " 'Texas-based',\n",
       " 'Toronto-based',\n",
       " 'Traded',\n",
       " 'Trading',\n",
       " 'Troubled',\n",
       " 'U.N.-supervised',\n",
       " 'U.S.-backed',\n",
       " 'United',\n",
       " 'Used',\n",
       " 'Varying',\n",
       " 'Washington-based',\n",
       " 'Whiting',\n",
       " 'Wilfred',\n",
       " 'Winning',\n",
       " 'Xiaoping',\n",
       " 'York-based',\n",
       " 'Zayed',\n",
       " 'abandoned',\n",
       " 'abating',\n",
       " 'abolishing',\n",
       " 'abortion-related',\n",
       " 'abounding',\n",
       " 'abridging',\n",
       " 'absorbed',\n",
       " 'acceded',\n",
       " 'accelerated',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'according',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accrued',\n",
       " 'accumulated',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'achieved',\n",
       " 'achieving',\n",
       " 'acknowledging',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acquisition-minded',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addressing',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'adopted',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advised',\n",
       " 'advocated',\n",
       " 'advocating',\n",
       " 'affecting',\n",
       " 'afflicted',\n",
       " 'aggravated',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'ailing',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aired',\n",
       " 'airline-related',\n",
       " 'alarmed',\n",
       " 'alienated',\n",
       " 'alleged',\n",
       " 'alleging',\n",
       " 'allocated',\n",
       " 'allowed',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amounted',\n",
       " 'amusing',\n",
       " 'angered',\n",
       " 'announced',\n",
       " 'annoyed',\n",
       " 'annualized',\n",
       " 'answered',\n",
       " 'anti-dumping',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anything',\n",
       " 'apologizing',\n",
       " 'appealing',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'applied',\n",
       " 'appointed',\n",
       " 'approached',\n",
       " 'appropriated',\n",
       " 'approved',\n",
       " 'arched',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'arising',\n",
       " 'armed',\n",
       " 'arranged',\n",
       " 'arrested',\n",
       " 'arrived',\n",
       " 'asbestos-related',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'assassinated',\n",
       " 'assembled',\n",
       " 'asserted',\n",
       " 'asserting',\n",
       " 'assessed',\n",
       " 'assigned',\n",
       " 'assisted',\n",
       " 'associated',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assured',\n",
       " 'attached',\n",
       " 'attacking',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attracted',\n",
       " 'attracting',\n",
       " 'attributed',\n",
       " 'auctioned',\n",
       " 'authorized',\n",
       " 'authorizing',\n",
       " 'automated',\n",
       " 'automotive-lighting',\n",
       " 'averaged',\n",
       " 'averted',\n",
       " 'avoiding',\n",
       " 'awarded',\n",
       " 'awarding',\n",
       " 'backed',\n",
       " 'backing',\n",
       " 'balanced',\n",
       " 'bald-faced',\n",
       " 'balkanized',\n",
       " 'balked',\n",
       " 'balloting',\n",
       " 'bank-backed',\n",
       " 'banking',\n",
       " 'banned',\n",
       " 'banning',\n",
       " 'barking',\n",
       " 'barred',\n",
       " 'based',\n",
       " 'battered',\n",
       " 'battery-operated',\n",
       " 'batting',\n",
       " 'bearing',\n",
       " 'becoming',\n",
       " 'bedding',\n",
       " 'befuddled',\n",
       " 'beginning',\n",
       " 'behaving',\n",
       " 'beheading',\n",
       " 'being',\n",
       " 'beleaguered',\n",
       " 'believed',\n",
       " 'bell-ringing',\n",
       " 'belonging',\n",
       " 'benefited',\n",
       " 'best-selling',\n",
       " 'betting',\n",
       " 'bickering',\n",
       " 'bidding',\n",
       " 'billed',\n",
       " 'billing',\n",
       " 'blamed',\n",
       " 'bled',\n",
       " 'blessing',\n",
       " 'blighted',\n",
       " 'blocked',\n",
       " 'blurred',\n",
       " 'boarding',\n",
       " 'bolstered',\n",
       " 'bombarding',\n",
       " 'booked',\n",
       " 'booming',\n",
       " 'boosted',\n",
       " 'boosting',\n",
       " 'borrowed',\n",
       " 'borrowing',\n",
       " 'botched',\n",
       " 'bothered',\n",
       " 'bounced',\n",
       " 'bowed',\n",
       " 'breaking',\n",
       " 'breathed',\n",
       " 'breathtaking',\n",
       " 'breed',\n",
       " 'bribed',\n",
       " 'bribing',\n",
       " 'briefing',\n",
       " 'brightened',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'broad-based',\n",
       " 'broadcasting',\n",
       " 'broadened',\n",
       " 'brokering',\n",
       " 'brushed',\n",
       " 'budding',\n",
       " 'building',\n",
       " 'bundling',\n",
       " 'buoyed',\n",
       " 'burned',\n",
       " 'buying',\n",
       " 'calculated',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'campaigning',\n",
       " 'cancer-causing',\n",
       " 'capitalized',\n",
       " 'capped',\n",
       " 'captivating',\n",
       " 'cared',\n",
       " 'carried',\n",
       " 'carrying',\n",
       " 'cascading',\n",
       " 'casting',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'cautioned',\n",
       " 'ceiling',\n",
       " 'centralized',\n",
       " 'certified',\n",
       " 'chaired',\n",
       " 'challenging',\n",
       " 'championing',\n",
       " 'change-ringing',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'characterized',\n",
       " 'characterizing',\n",
       " 'charged',\n",
       " 'charging',\n",
       " 'chastised',\n",
       " 'cheating',\n",
       " 'checking',\n",
       " 'cheerleading',\n",
       " 'chilled',\n",
       " 'choosing',\n",
       " 'chopped',\n",
       " 'circulated',\n",
       " 'cited',\n",
       " 'citing',\n",
       " 'citizen-sparked',\n",
       " 'city-owned',\n",
       " 'claimed',\n",
       " 'claiming',\n",
       " 'clamped',\n",
       " 'clarified',\n",
       " 'clashed',\n",
       " 'classed',\n",
       " 'classified',\n",
       " 'cleaned',\n",
       " 'cleaner-burning',\n",
       " 'cleared',\n",
       " 'clearing',\n",
       " 'clicked',\n",
       " 'climbed',\n",
       " 'climbing',\n",
       " 'clipped',\n",
       " 'clobbered',\n",
       " 'closed',\n",
       " 'closing',\n",
       " 'clothing',\n",
       " 'clouding',\n",
       " 'cluttered',\n",
       " 'co-founded',\n",
       " 'coaching',\n",
       " 'coal-fired',\n",
       " 'coated',\n",
       " 'codified',\n",
       " 'collaborated',\n",
       " 'collapsed',\n",
       " 'collected',\n",
       " 'collecting',\n",
       " 'collective-bargaining',\n",
       " 'colored',\n",
       " 'combined',\n",
       " 'coming',\n",
       " 'commanded',\n",
       " 'commenting',\n",
       " 'committed',\n",
       " 'committing',\n",
       " 'compared',\n",
       " 'compelling',\n",
       " 'competed',\n",
       " 'competing',\n",
       " 'compiled',\n",
       " 'complained',\n",
       " 'complaining',\n",
       " 'completed',\n",
       " 'completing',\n",
       " 'complicated',\n",
       " 'composed',\n",
       " 'composting',\n",
       " 'compressed',\n",
       " 'computer-aided',\n",
       " 'computer-assisted',\n",
       " 'computer-generated',\n",
       " 'computerized',\n",
       " 'computing',\n",
       " 'conceding',\n",
       " 'concentrated',\n",
       " 'concentrating',\n",
       " 'concerned',\n",
       " 'concluded',\n",
       " 'condemned',\n",
       " 'condemning',\n",
       " 'conducted',\n",
       " 'conducting',\n",
       " 'confined',\n",
       " 'confirmed',\n",
       " 'confused',\n",
       " 'connected',\n",
       " 'consented',\n",
       " 'considered',\n",
       " 'considering',\n",
       " 'consisting',\n",
       " 'construed',\n",
       " 'consulting',\n",
       " 'contacted',\n",
       " 'contained',\n",
       " 'containing',\n",
       " 'contesting',\n",
       " 'continued',\n",
       " 'continuing',\n",
       " 'contracted',\n",
       " 'contributed',\n",
       " 'contributing',\n",
       " 'controlled',\n",
       " 'controlling',\n",
       " 'converted',\n",
       " 'converting',\n",
       " 'convicted',\n",
       " 'convinced',\n",
       " 'cooled',\n",
       " 'cooperating',\n",
       " 'copied',\n",
       " 'copying',\n",
       " 'corn-buying',\n",
       " 'corrected',\n",
       " 'correcting',\n",
       " 'cost-cutting',\n",
       " 'cost-sharing',\n",
       " 'counseling',\n",
       " 'counting',\n",
       " 'coupled',\n",
       " 'court-ordered',\n",
       " 'covered',\n",
       " 'covering',\n",
       " 'cranked',\n",
       " 'crashing',\n",
       " 'created',\n",
       " 'creating',\n",
       " 'credit-rating',\n",
       " 'crippled',\n",
       " 'criticized',\n",
       " 'crossed',\n",
       " 'crossing',\n",
       " 'crowded',\n",
       " 'cruising',\n",
       " 'crushed',\n",
       " 'crying',\n",
       " 'cultivated',\n",
       " 'curbed',\n",
       " 'curbing',\n",
       " 'curled',\n",
       " 'current-carrying',\n",
       " 'curtailed',\n",
       " 'cushioned',\n",
       " 'customized',\n",
       " 'cutting',\n",
       " 'damaged',\n",
       " 'damaging',\n",
       " 'dancing',\n",
       " 'darned',\n",
       " 'dashed',\n",
       " 'dating',\n",
       " 'dead-eyed',\n",
       " 'dealing',\n",
       " 'decided',\n",
       " 'declared',\n",
       " 'declaring',\n",
       " 'declined',\n",
       " 'declining',\n",
       " 'decorated',\n",
       " 'decried',\n",
       " 'deducting',\n",
       " 'deemed',\n",
       " 'defeated',\n",
       " 'defended',\n",
       " 'defined',\n",
       " 'defying',\n",
       " 'delayed',\n",
       " 'deliberating',\n",
       " 'delisted',\n",
       " 'delivered',\n",
       " 'delivering',\n",
       " 'demanding',\n",
       " 'demonstrating',\n",
       " 'denied',\n",
       " 'denouncing',\n",
       " 'denying',\n",
       " 'depended',\n",
       " 'depending',\n",
       " 'depleted',\n",
       " 'depressed',\n",
       " 'deprived',\n",
       " 'derived',\n",
       " 'descending',\n",
       " 'described',\n",
       " 'deserving',\n",
       " 'designated',\n",
       " 'designed',\n",
       " 'designing',\n",
       " 'desired',\n",
       " 'despised',\n",
       " 'detailed',\n",
       " 'deteriorated',\n",
       " 'deteriorating',\n",
       " 'determined',\n",
       " 'deterring',\n",
       " 'devastating',\n",
       " 'developed',\n",
       " 'developing',\n",
       " 'devised',\n",
       " 'devoted',\n",
       " 'devouring',\n",
       " 'diagnosed',\n",
       " 'died',\n",
       " 'diluted',\n",
       " 'diming',\n",
       " 'diminished',\n",
       " 'directed',\n",
       " 'directing',\n",
       " 'disaffected',\n",
       " 'disagreed',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'disapproved',\n",
       " 'discarded',\n",
       " 'disciplined',\n",
       " 'disclosed',\n",
       " 'disclosing',\n",
       " 'discontinued',\n",
       " 'discontinuing',\n",
       " 'discouraging',\n",
       " 'discovered',\n",
       " 'discussed',\n",
       " 'discussing',\n",
       " 'disembodied',\n",
       " 'dismayed',\n",
       " 'dismissed',\n",
       " 'disposed',\n",
       " 'disputed',\n",
       " 'disseminating',\n",
       " 'distinguished',\n",
       " 'distorted',\n",
       " 'distributed',\n",
       " 'disturbing',\n",
       " 'diversified',\n",
       " 'diversifying',\n",
       " 'divided',\n",
       " 'dividing',\n",
       " 'documented',\n",
       " 'doing',\n",
       " 'doling',\n",
       " 'dollar-denominated',\n",
       " 'dominated',\n",
       " 'dominating',\n",
       " 'doubled',\n",
       " 'doubted',\n",
       " 'downgraded',\n",
       " 'downgrading',\n",
       " 'drafted',\n",
       " 'drawing',\n",
       " 'dreamed',\n",
       " 'dressed',\n",
       " 'drifted',\n",
       " 'drinking',\n",
       " 'driving',\n",
       " 'drooled',\n",
       " 'dropped',\n",
       " 'dubbed',\n",
       " 'duckling',\n",
       " 'dumbfounded',\n",
       " 'dumped',\n",
       " 'during',\n",
       " 'dwindling',\n",
       " 'earned',\n",
       " 'earning',\n",
       " 'eased',\n",
       " 'easing',\n",
       " 'eating',\n",
       " 'echoed',\n",
       " 'edged',\n",
       " 'editing',\n",
       " 'educated',\n",
       " 'elected',\n",
       " 'eliminated',\n",
       " 'eliminating',\n",
       " 'embarrassing',\n",
       " 'embroiled',\n",
       " 'emerged',\n",
       " 'emerging',\n",
       " 'emphasized',\n",
       " 'employed',\n",
       " 'empowered',\n",
       " 'enabled',\n",
       " 'enabling',\n",
       " 'enacted',\n",
       " 'encircling',\n",
       " 'enclosed',\n",
       " 'encouraging',\n",
       " 'encroaching',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'endorsed',\n",
       " 'engaged',\n",
       " 'engaging',\n",
       " 'engineered',\n",
       " 'engineering',\n",
       " 'enhanced',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enlarged',\n",
       " 'enraged',\n",
       " 'ensnarled',\n",
       " 'entangled',\n",
       " 'entered',\n",
       " 'entering',\n",
       " 'entertaining',\n",
       " 'enticed',\n",
       " 'entitled',\n",
       " 'entrenched',\n",
       " 'entrusted',\n",
       " 'equaling',\n",
       " 'equipped',\n",
       " 'escalated',\n",
       " 'escaped',\n",
       " 'established',\n",
       " 'establishing',\n",
       " 'estimated',\n",
       " 'evaluated',\n",
       " 'evaluating',\n",
       " 'evaporated',\n",
       " 'evening',\n",
       " 'everything',\n",
       " 'evoking',\n",
       " 'evolved',\n",
       " 'exacerbated',\n",
       " 'examined',\n",
       " 'exceed',\n",
       " 'exceeded',\n",
       " 'exceeding',\n",
       " 'exchanging',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'executed',\n",
       " 'executing',\n",
       " 'exercised',\n",
       " 'exerting',\n",
       " 'exhausted',\n",
       " 'exhibited',\n",
       " 'existed',\n",
       " 'existing',\n",
       " 'expanded',\n",
       " 'expanding',\n",
       " 'expected',\n",
       " 'expecting',\n",
       " 'expedited',\n",
       " 'expelled',\n",
       " 'experienced',\n",
       " 'experiencing',\n",
       " 'expired',\n",
       " 'explained',\n",
       " 'explaining',\n",
       " 'exploded',\n",
       " 'export-oriented',\n",
       " 'exposed',\n",
       " 'expressed',\n",
       " 'expressing',\n",
       " 'expunged',\n",
       " 'extended',\n",
       " 'extending',\n",
       " 'exuded',\n",
       " 'eyeing',\n",
       " 'fabled',\n",
       " 'faced',\n",
       " 'facing',\n",
       " 'factoring',\n",
       " 'faded',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'fainting',\n",
       " 'falling',\n",
       " 'faltered',\n",
       " 'famed',\n",
       " 'family-planning',\n",
       " 'fared',\n",
       " 'fashioned',\n",
       " 'fast-growing',\n",
       " 'fastest-growing',\n",
       " 'fattened',\n",
       " 'favored',\n",
       " 'fawning',\n",
       " 'feared',\n",
       " 'featured',\n",
       " 'featuring',\n",
       " 'fed',\n",
       " 'feed',\n",
       " 'feeling',\n",
       " 'fetching',\n",
       " 'fielded',\n",
       " 'fighting',\n",
       " 'filed',\n",
       " 'filing',\n",
       " 'filled',\n",
       " 'filling',\n",
       " 'finalized',\n",
       " 'financed',\n",
       " 'financing',\n",
       " 'finding',\n",
       " 'fined',\n",
       " 'finished',\n",
       " 'fired',\n",
       " 'firmed',\n",
       " 'fixed',\n",
       " 'fizzled',\n",
       " 'fled',\n",
       " 'fledgling',\n",
       " 'fleeting',\n",
       " 'flirted',\n",
       " 'floated',\n",
       " 'flooded',\n",
       " 'focused',\n",
       " 'focusing',\n",
       " 'folded',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'forced',\n",
       " 'forcing',\n",
       " 'forecasting',\n",
       " 'foreign-led',\n",
       " 'formed',\n",
       " 'forthcoming',\n",
       " 'founded',\n",
       " 'foundering',\n",
       " 'fretted',\n",
       " 'frightened',\n",
       " 'frustrating',\n",
       " 'fueled',\n",
       " 'fueling',\n",
       " 'full-fledged',\n",
       " 'fuming',\n",
       " 'functioning',\n",
       " 'funded',\n",
       " 'funding',\n",
       " 'fundraising',\n",
       " 'futures-related',\n",
       " 'gained',\n",
       " 'gaining',\n",
       " 'galling',\n",
       " 'galvanized',\n",
       " 'gambling',\n",
       " 'gauging',\n",
       " 'generated',\n",
       " 'getting',\n",
       " 'giving',\n",
       " 'going',\n",
       " 'good-hearted',\n",
       " 'good-natured',\n",
       " 'gored',\n",
       " 'government-certified',\n",
       " 'government-funded',\n",
       " 'government-owned',\n",
       " 'graduated',\n",
       " 'granted',\n",
       " 'granting',\n",
       " 'greed',\n",
       " 'gripping',\n",
       " 'growing',\n",
       " 'guaranteed',\n",
       " 'guarding',\n",
       " 'guided',\n",
       " 'gut-wrenching',\n",
       " 'hailed',\n",
       " 'hailing',\n",
       " 'halted',\n",
       " 'hampered',\n",
       " 'handed',\n",
       " 'handled',\n",
       " 'handling',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'hard-charging',\n",
       " 'hard-drinking',\n",
       " 'hard-hitting',\n",
       " 'harmed',\n",
       " 'harped',\n",
       " 'harvested',\n",
       " 'hauled',\n",
       " 'hauling',\n",
       " 'having',\n",
       " 'headed',\n",
       " 'heading',\n",
       " 'headlined',\n",
       " 'healing',\n",
       " 'hearing',\n",
       " 'heated',\n",
       " 'heating',\n",
       " 'hedging',\n",
       " 'heightened',\n",
       " 'helped',\n",
       " 'helping',\n",
       " 'high-flying',\n",
       " 'high-minded',\n",
       " 'high-polluting',\n",
       " 'high-priced',\n",
       " 'high-rolling',\n",
       " 'high-speed',\n",
       " 'higher-salaried',\n",
       " 'highest-pitched',\n",
       " 'hired',\n",
       " 'hitting',\n",
       " 'holding',\n",
       " 'hoped',\n",
       " 'hosted',\n",
       " 'housing',\n",
       " 'hugging',\n",
       " 'hundred',\n",
       " 'hunted',\n",
       " 'hurting',\n",
       " 'identified',\n",
       " 'ignored',\n",
       " 'ignoring',\n",
       " 'impaired',\n",
       " 'impeding',\n",
       " 'impending',\n",
       " 'implemented',\n",
       " 'implied',\n",
       " 'imported',\n",
       " 'imposed',\n",
       " 'imposing',\n",
       " 'impressed',\n",
       " 'improved',\n",
       " 'improving',\n",
       " 'incentive-backed',\n",
       " 'inched',\n",
       " 'inching',\n",
       " 'included',\n",
       " 'including',\n",
       " 'incorporated',\n",
       " 'increased',\n",
       " 'increasing',\n",
       " 'incurred',\n",
       " 'indeed',\n",
       " 'index-related',\n",
       " 'indicated',\n",
       " 'indicating',\n",
       " 'indulging',\n",
       " 'industrialized',\n",
       " 'industry-supported',\n",
       " 'inflated',\n",
       " 'influenced',\n",
       " 'influencing',\n",
       " 'infringed',\n",
       " 'inherited',\n",
       " 'initialing',\n",
       " 'initiated',\n",
       " 'initiating',\n",
       " 'injecting',\n",
       " 'injuring',\n",
       " 'inkling',\n",
       " 'inquiring',\n",
       " 'inserted',\n",
       " 'insider-trading',\n",
       " 'insinuating',\n",
       " 'insisted',\n",
       " 'inspired',\n",
       " 'installed',\n",
       " 'installing',\n",
       " 'instituted',\n",
       " 'instructed',\n",
       " 'insured',\n",
       " 'integrated',\n",
       " 'intended',\n",
       " 'intentioned',\n",
       " 'interest-bearing',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'interrogated',\n",
       " 'interviewed',\n",
       " 'intriguing',\n",
       " 'introduced',\n",
       " 'introducing',\n",
       " 'invented',\n",
       " 'inverted',\n",
       " 'invested',\n",
       " 'investigating',\n",
       " 'investing',\n",
       " 'inviting',\n",
       " 'involved',\n",
       " 'involving',\n",
       " 'issued',\n",
       " 'issuing',\n",
       " 'jeopardizing',\n",
       " 'joined',\n",
       " 'joining',\n",
       " 'judged',\n",
       " 'jumped',\n",
       " 'jumping',\n",
       " 'justified',\n",
       " 'justifying',\n",
       " 'keeping',\n",
       " 'kicked',\n",
       " 'kidnapping',\n",
       " 'killed',\n",
       " 'killing',\n",
       " 'knitted',\n",
       " 'knocked',\n",
       " 'labeled',\n",
       " 'labeling',\n",
       " 'labor-backed',\n",
       " 'lacked',\n",
       " 'lagging',\n",
       " 'land-idling',\n",
       " 'landing',\n",
       " 'lasted',\n",
       " 'lasting',\n",
       " 'lauded',\n",
       " 'laughing',\n",
       " 'launched',\n",
       " 'lawmaking',\n",
       " 'laying',\n",
       " 'leading',\n",
       " 'learned',\n",
       " 'learning',\n",
       " 'leasing',\n",
       " 'leaving',\n",
       " 'led',\n",
       " 'lending',\n",
       " 'lengthened',\n",
       " 'lessening',\n",
       " 'letter-writing',\n",
       " 'letting',\n",
       " 'leveling',\n",
       " 'leveraged',\n",
       " 'leveraging',\n",
       " 'licensed',\n",
       " 'licensing',\n",
       " 'lifted',\n",
       " ...]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('(ed|ing)$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4   Useful Applications of Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To the Python interpreter, a regular expression is just like any other string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the string contains a backslash followed by particular characters, it will interpret these specially.  For example \\b would be interpreted as the backspace character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In general, when using regular expressions containing backslash, we should instruct the interpreter not to look inside the string at all, but simply to pass it directly to the re library for processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do this by prefixing the string with the letter r, to indicate that it is a raw string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, the raw string r'\\band\\b' contains two \\b symbols that are interpreted by the re library as matching word boundaries instead of backspace characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get into the habit of using r'...' for regular expressions — as we will do from now on — you will avoid having to think about these complications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above examples all involved searching for words w that match some regular expression regexp using re.search(regexp, w)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apart from checking if a regular expression matches a word, we can use regular expressions to extract material from words, or to modify words in specific ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Word Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The re.findall() (\"find all\") method finds all (non-overlapping) matches of the given regular expression. Let's find all the vowels in a word, then count them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'supercalifragilisticexpialidocious'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'o',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[aeiou]', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(r'[aeiou]', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look for all sequences of two or more vowels in some text, and determine their relative frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(vs for word in wsj\n",
    "                      for vs in re.findall(r'[aeiou]{2,}', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 549),\n",
       " ('ea', 476),\n",
       " ('ie', 331),\n",
       " ('ou', 329),\n",
       " ('ai', 261),\n",
       " ('ia', 253),\n",
       " ('ee', 217),\n",
       " ('oo', 174),\n",
       " ('ua', 109),\n",
       " ('au', 106),\n",
       " ('ue', 105),\n",
       " ('ui', 95)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing More with Word Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we can use re.findall() to extract material from words, there's interesting things to do with the pieces, like glue them back together or plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is sometimes noted that English text is highly redundant, and it is still easy to read when word-internal vowels are left out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, declaration becomes dclrtn, and inalienable becomes inlnble, retaining any initial or final vowel sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regular expression in our next example matches initial vowel sequences, final vowel sequences, and all consonants; everything else is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This three-way disjunction is processed left-to-right, if one of the three parts matches the word, any later parts of the regular expression are ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use re.findall() to extract all the matching pieces, and ''.join() to join them together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.tokenwrap():Pretty print a list of text tokens, breaking lines on whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universal Declaration of Human Rights Preamble Whereas recognition of\n",
      "the inherent dignity and of the equal and inalienable rights of all\n",
      "members of the human family is the foundation of freedom , justice and\n",
      "peace in the world , Whereas disregard and contempt for human rights\n",
      "have resulted in barbarous acts which have outraged the conscience of\n",
      "mankind , and the advent of a world in which human beings shall enjoy\n",
      "freedom of speech and\n"
     ]
    }
   ],
   "source": [
    "print(nltk.tokenwrap(w for w in english_udhr[:75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    }
   ],
   "source": [
    "print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's combine regular expressions with conditional frequency distributions. Here we will extract all consonant-vowel sequences from the words of Rotokas, such as ka and si. Since each of these is a pair, it can be used to initialize a conditional frequency distribution. We then tabulate the frequency of each pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to be able to inspect the words behind the numbers in the above table, it would be helpful to have an index, allowing us to quickly find the list of words that contains a given consonant-vowel pair, e.g. cv_index['su'] should give us all words containing su. Here's how we can do this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words\n",
    "                 for cv in re.findall(r'[ptksvr][aeiou]', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_index = nltk.Index(cv_word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kasuari']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_index['su']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaapo',\n",
       " 'kaapopato',\n",
       " 'kaipori',\n",
       " 'kaiporipie',\n",
       " 'kaiporivira',\n",
       " 'kapo',\n",
       " 'kapoa',\n",
       " 'kapokao',\n",
       " 'kapokapo',\n",
       " 'kapokapo',\n",
       " 'kapokapoa',\n",
       " 'kapokapoa',\n",
       " 'kapokapora',\n",
       " 'kapokapora',\n",
       " 'kapokaporo',\n",
       " 'kapokaporo',\n",
       " 'kapokari',\n",
       " 'kapokarito',\n",
       " 'kapokoa',\n",
       " 'kapoo',\n",
       " 'kapooto',\n",
       " 'kapoovira',\n",
       " 'kapopaa',\n",
       " 'kaporo',\n",
       " 'kaporo',\n",
       " 'kaporopa',\n",
       " 'kaporoto',\n",
       " 'kapoto',\n",
       " 'karokaropo',\n",
       " 'karopo',\n",
       " 'kepo',\n",
       " 'kepoi',\n",
       " 'keposi',\n",
       " 'kepoto']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " cv_index['po']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Word Stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are various ways we can pull out the stem of a word. Here's a simple-minded approach which just strips off anything that looks like a suffix:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "     for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although we will ultimately use NLTK's built-in stemmers, it's interesting to see how we can use regular expressions for this task. Our first step is to build up a disjunction of all the suffixes. We need to enclose it in parentheses in order to limit the scope of the disjunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ing']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, re.findall() just gave us the suffix even though the regular expression matched the entire word. This is because the parentheses have a second function, to select substrings to be extracted. If we want to use the parentheses to specify the scope of the disjunction, but not to select the material to be output, we have to add ?:, which is just one of many arcane subtleties of regular expressions. Here's the revised version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processing']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, we'd actually like to split the word into stem and suffix. So we should just parenthesize both parts of the regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'ing')]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks promising, but still has a problem. Let's look at a different word, processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processe', 's')]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regular expression incorrectly found an -s suffix instead of an -es suffix. This demonstrates another subtlety: the star operator is \"greedy\" and the .* part of the expression tries to consume as much of the input as possible. If we use the \"non-greedy\" version of the star operator, written *?, we get what we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'es')]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works even when we allow an empty suffix, by making the content of the second parentheses optional:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', '')]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$', 'language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This approach still has many problems (can you spot them?) .Now we will move on to define a function to perform stemming, and apply it to a whole text:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):  \n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "   is no basis for a system of government.  Supreme executive power derives from\n",
    " a mandate from the masses, not from some farcical aquatic ceremony.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'women',\n",
       " 'ly',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'i',\n",
       " 'no',\n",
       " 'basi',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'execut',\n",
       " 'power',\n",
       " 'deriv',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that our regular expression removed the s from ponds but also from is and basis. It produced some non-words like distribut and deriv, but these are acceptable stems in some applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching Tokenized Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use a special kind of regular expression for searching across multiple words in a text (where a text is a list of tokens). For example, \"<a> <man>\" finds all instances of a man in the text. The angle brackets are used to mark token boundaries, and any whitespace between the angle brackets is ignored (behaviors that are unique to NLTK's findall() method for texts). In the following example, we include <.*> [1] which will match any single token, and enclose it in parentheses so only the matched word (e.g. monied) and not the matched phrase (e.g. a monied man) is produced. The second example finds three-word phrases ending with the word bro [2]. The last example finds sequences of three or more words starting with the letter l [3].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg, nps_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n"
     ]
    }
   ],
   "source": [
    "moby.findall(r\"<a> (<.*>) <man>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = nltk.Text(nps_chat.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<.*> <.*> <bro>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<l.*>{3,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is easy to build search patterns when the linguistic phenomenon we're studying is tied to particular words. In some cases, a little creativity will go a long way. For instance, searching a large text corpus for expressions of the form x and other ys allows us to discover hypernyms (cf 5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobbies_learned = nltk.Text(brown.words(categories=['hobbies', 'learned']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "hobbies_learned.findall(r\"<\\w*> <and> <other> <\\w*s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With enough text, this approach would give us a useful store of information about the taxonomy of objects, without the need for any manual labor. However, our search results will usually contain false positives, i.e. cases that we would want to exclude. For example, the result: demands and other factors suggests that demand is an instance of the type factor, but this sentence is actually about wage demands. Nevertheless, we could construct our own ontology of English concepts by manually correcting the output of such searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5  Normalizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In earlier program examples we have often converted text to lowercase before doing anything with its words, e.g. set(w.lower() for w in text). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using lower(), we have normalized the text to lowercase so that the distinction between The and the is ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often we want to go further than this, and strip off any affixes, a task known as stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A further step is to make sure that the resulting form is a known word in a dictionary, a task known as lemmatization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords is no basis for a system of government.  Supreme executive power derives from\n",
    " a mandate from the masses, not from some farcical aquatic ceremony.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK includes several off-the-shelf stemmers, and if you ever need a stemmer you should use one of these in preference to crafting your own using regular expressions, since these handle a wide range of irregular cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Porter and Lancaster stemmers follow their own rules for stripping affixes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that the Porter stemmer correctly handles the word lying (mapping it to lie), while the Lancaster stemmer does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['denni',\n",
       " ':',\n",
       " 'listen',\n",
       " ',',\n",
       " 'strang',\n",
       " 'women',\n",
       " 'lie',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basi',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'power',\n",
       " 'deriv',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandat',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcic',\n",
       " 'aquat',\n",
       " 'ceremoni',\n",
       " '.']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['den',\n",
       " ':',\n",
       " 'list',\n",
       " ',',\n",
       " 'strange',\n",
       " 'wom',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distribut',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'bas',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'govern',\n",
       " '.',\n",
       " 'suprem',\n",
       " 'execut',\n",
       " 'pow',\n",
       " 'der',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mand',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'som',\n",
       " 'farc',\n",
       " 'aqu',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lancaster.stem(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The WordNet lemmatizer only removes affixes if the resulting word is in its dictionary. This additional checking process makes the lemmatizer slower than the above stemmers. Notice that it doesn't handle lying, but it converts women to woman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DENNIS',\n",
       " ':',\n",
       " 'Listen',\n",
       " ',',\n",
       " 'strange',\n",
       " 'woman',\n",
       " 'lying',\n",
       " 'in',\n",
       " 'pond',\n",
       " 'distributing',\n",
       " 'sword',\n",
       " 'is',\n",
       " 'no',\n",
       " 'basis',\n",
       " 'for',\n",
       " 'a',\n",
       " 'system',\n",
       " 'of',\n",
       " 'government',\n",
       " '.',\n",
       " 'Supreme',\n",
       " 'executive',\n",
       " 'power',\n",
       " 'derives',\n",
       " 'from',\n",
       " 'a',\n",
       " 'mandate',\n",
       " 'from',\n",
       " 'the',\n",
       " 'mass',\n",
       " ',',\n",
       " 'not',\n",
       " 'from',\n",
       " 'some',\n",
       " 'farcical',\n",
       " 'aquatic',\n",
       " 'ceremony',\n",
       " '.']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wnl.lemmatize(t) for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 Regular Expressions for Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization is the task of cutting a string into identifiable linguistic units that constitute a piece of language data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although it is a fundamental task, we have been able to delay it until now because many corpora are already tokenized, and because NLTK includes some tokenizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that you are familiar with regular expressions, you can learn how to use them to tokenize text, and to have much more control over the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Approaches to Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The very simplest method for tokenizing text is to split on whitespace. Consider the following text from Alice's Adventures in Wonderland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    "though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    "well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could split this raw text on whitespace using raw.split(). To do the same using a regular expression, it is not enough to match any space characters in the string [1] since this results in tokens that contain a \\n newline character; instead we need to match any number of spaces, tabs, or newlines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone\\nthough),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very\\nwell',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r' ', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " re.split(r'[ \\t\\n]+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The regular expression «[ \\t\\n]+» matches one or more space, tab (\\t) or newline (\\n). Other whitespace characters, such as carriage-return and form-feed should really be included too. Instead, we will use a built-in re abbreviation, \\s, which means any whitespace character. The above statement can be rewritten as re.split(r'\\s+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,'...\"]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'\\s+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to prefix regular expressions with the letter r (meaning \"raw\"), which instructs the Python interpreter to treat the string literally, rather than processing any backslashed characters it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting on whitespace gives us tokens like '(not' and 'herself,'. An alternative is to use the fact that Python provides us with a character class \\w for word characters, equivalent to [a-zA-Z0-9_]. It also defines the complement of this class \\W, i.e. all characters other than letters, digits or underscore. We can use \\W in a simple regular expression to split the input on anything other than a word character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'When',\n",
       " 'I',\n",
       " 'M',\n",
       " 'a',\n",
       " 'Duchess',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " 'I',\n",
       " 'won',\n",
       " 't',\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'Maybe',\n",
       " 'it',\n",
       " 's',\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " 'tempered',\n",
       " '']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " re.split(r'\\W+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we're matching the words, we're in a position to extend the regular expression to cover a wider range of cases. The regular expression «\\w+|\\S\\w*» will first try to match any sequence of word characters. If no match is found, it will try to match any non-whitespace character (\\S is the complement of \\s) followed by further word characters. This means that punctuation is grouped with any following letters (e.g. 's) but that sequences of two or more punctuation characters are separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " 'I',\n",
       " \"'M\",\n",
       " 'a',\n",
       " 'Duchess',\n",
       " ',',\n",
       " \"'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " ',',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " ')',\n",
       " ',',\n",
       " \"'I\",\n",
       " 'won',\n",
       " \"'t\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " '.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " '-',\n",
       " '-Maybe',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " '-tempered',\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w+|\\S\\w*', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generalize the \\w+ in the above expression to permit word-internal hyphens and apostrophes: «\\w+([-']\\w+)*». This expression means \\w+ followed by zero or more instances of [-']\\w+; it would match hot-tempered and it's. (We need to include ?: in this expression for reasons discussed earlier.) We'll also add a pattern to match quote characters so these are kept separate from the text they enclose.# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'When', \"I'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'\", 'I', \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '--', 'Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', 'hot-tempered', ',', \"'\", '...']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Expression Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Symbol \tFunction\n",
    "#\\b \tWord boundary (zero width)\n",
    "#\\d \tAny decimal digit (equivalent to [0-9])\n",
    "#\\D \tAny non-digit character (equivalent to [^0-9])\n",
    "#\\s \tAny whitespace character (equivalent to [ \\t\\n\\r\\f\\v])\n",
    "#\\S \tAny non-whitespace character (equivalent to [^ \\t\\n\\r\\f\\v])\n",
    "#\\w \tAny alphanumeric character (equivalent to [a-zA-Z0-9_])\n",
    "#\\W \tAny non-alphanumeric character (equivalent to [^a-zA-Z0-9_])\n",
    "#\\t \tThe tab character\n",
    "#\\n \tThe newline character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7  Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization is an instance of a more general problem of segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulating texts at the level of individual words often presupposes the ability to divide a text into individual sentences. As we have seen, some corpora already provide access at the sentence level. In the following example, we compute the average number of words per sentence in the Brown Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In other cases, the text is only available as a stream of characters. Before tokenizing the text into words, we need to segment it into sentences. NLTK facilitates this by including the Punkt sentence segmenter (Kiss & Strunk, 2006). Here is an example of its use in segmenting the text of a novel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Nonsense!\"',\n",
      " 'said Gregory, who was very rational when anyone else\\nattempted paradox.',\n",
      " '\"Why do all the clerks and navvies in the\\n'\n",
      " 'railway trains look so sad and tired, so very sad and tired?',\n",
      " 'I will\\ntell you.',\n",
      " 'It is because they know that the train is going right.',\n",
      " 'It\\n'\n",
      " 'is because they know that whatever place they have taken a ticket\\n'\n",
      " 'for that place they will reach.',\n",
      " 'It is because after they have\\n'\n",
      " 'passed Sloane Square they know that the next station must be\\n'\n",
      " 'Victoria, and nothing but Victoria.',\n",
      " 'Oh, their wild rapture!',\n",
      " 'oh,\\n'\n",
      " 'their eyes like stars and their souls again in Eden, if the next\\n'\n",
      " 'station were unaccountably Baker Street!\"',\n",
      " '\"It is you who are unpoetical,\" replied the poet Syme.']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sents[79:89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence segmentation is difficult because period is used to mark abbreviations, and some periods simultaneously mark an abbreviation and terminate a sentence, as often happens with acronyms like U.S.A.For another approach to sentence segmentation, see Chapter 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.8   Formatting: From Lists to Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Lists to Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The simplest kind of structured object we use for text processing is lists of words. When we want to output these to a display or a file, we must convert these lists into strings. To do this in Python we use the join() method, and specify the string to be used as the \"glue\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We called him Tortoise because he taught us .'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(silly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We;called;him;Tortoise;because;he;taught;us;.'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "';'.join(silly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WecalledhimTortoisebecausehetaughtus.'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(silly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings and Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have seen that there are two ways to display the contents of an object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"hello\n",
    "world\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello\\nworld'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print command yields Python's attempt to produce the most human-readable form of an object. The second method — naming the variable at a prompt — shows us a string that can be used to recreate this object. It is important to keep in mind that both of these are just strings, displayed for the benefit of you, the user. They do not give us any clue as to the actual internal representation of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many other useful ways to display an object as a string of characters. This may be for the benefit of a human reader, or because we want to export our data to a particular file format for use in an external program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatted output typically contains a combination of variables and pre-specified strings, e.g. given a frequency distribution fdist we could do:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(['dog', 'cat', 'dog', 'cat', 'dog', 'snake', 'dog', 'cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat -> 3; dog -> 4; snake -> 1; "
     ]
    }
   ],
   "source": [
    "for word in sorted(fdist):\n",
    "    print(word, '->', fdist[word], end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statements that contain alternating variables and constants can be difficult to read and maintain. Another solution is to use string formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat->3; dog->4; snake->1; "
     ]
    }
   ],
   "source": [
    "for word in sorted(fdist):\n",
    "    print('{}->{};'.format(word, fdist[word]), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand what is going on here, let's test out the format string on its own. (By now this will be your usual method of exploring new syntax.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The curly brackets '{}' mark the presence of a replacement field: this acts as a placeholder for the string values of objects that are passed to the str.format() method. We can embed occurrences of '{}' inside a string, then replace them with strings by calling format() with appropriate arguments. A string containing replacement fields is called a format string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat->3;'"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}->{};'.format ('cat', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{}'.format(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want a coffee right now'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'I want a {} right now'.format('coffee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can have any number of placeholders, but the str.format method must be called with exactly the same number of arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lee wants a sandwich for lunch'"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{} wants a {} {}'.format ('Lee', 'sandwich', 'for lunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-344-339b7c04a9c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m'{} wants a {} {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'sandwich'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'for lunch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "'{} wants a {} {}'.format ('sandwich', 'for lunch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The field name in a format string can start with a number, which refers to a positional argument of format(). Something like 'from {} to {}' is equivalent to 'from {0} to {1}', but we can use the numbers to get non-default orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from B to A'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'from {1} to {0}'.format('A', 'B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also provide the values for the placeholders indirectly. Here's an example using a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'Lee wants a {} right now'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = ['sandwich', 'spam fritter', 'pancake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lee wants a sandwich right now\n",
      "Lee wants a spam fritter right now\n",
      "Lee wants a pancake right now\n"
     ]
    }
   ],
   "source": [
    " for snack in menu:\n",
    "    print(template.format(snack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lining Things Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is right-justified by default for numbers, but we can precede the width specifier with a '<' alignment option to make numbers left-justified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    41'"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41    '"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:<6}'.format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings are left-justified by default, but can be right-justified with the '>' alignment option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog   '"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   dog'"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:>6}'.format('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other control characters can be used to specify the sign and precision of floating point numbers; for example {:.4f} indicates that four digits should be displayed after the decimal point for a floating point number.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    " import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1416'"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:.4f}'.format(math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The string formatting is smart enough to know that if you include a '%' in your format specification, then you want to represent the value as a percentage; there's no need to multiply by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, total = 3205, 9375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy for 9375 words: 34.1867%'"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"accuracy for {} words: {:.4%}\".format(total, count / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a format string '{:{width}}' and bound a value to the width parameter in format() allows us to specify the width of a field using a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python   '"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:{width}}'.format('Monty Python', width=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could use this to automatically customize the column to be just wide enough to accommodate all the words, using width = max(len(w) for w in words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Results to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is often useful to write output to files as well. The following code opens a file output.txt for writing, and saves the program output to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('output.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.genesis.words('english-kjv.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in sorted(words):\n",
    "    print(word, file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the output of our program is text-like, instead of tabular, it will usually be necessary to wrap it so that it can be displayed conveniently. Consider the following output, which overflows its line, and which uses a complicated print statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',\n",
    "         'more', 'is', 'said', 'than', 'done', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5), all (3), is (2), said (4), and (3), done (4), , (1), more (4), is (2), said (4), than (4), done (4), . (1), "
     ]
    }
   ],
   "source": [
    "for word in saying:\n",
    "    print(word, '(' + str(len(word)) + '),', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take care of line wrapping with the help of Python's textwrap module. For maximum clarity we will separate each step onto its own line:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = [\"{} {}\".format(word, len(word)) for word in saying]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ' '.join(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = fill(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 all 3 is 2 said 4 and 3 done 4 , 1 more 4 is 2 said 4 than 4\n",
      "done 4 . 1\n"
     ]
    }
   ],
   "source": [
    "print(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
