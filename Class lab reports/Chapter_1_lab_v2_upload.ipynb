{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes are from Natural Language Processing with Python, by Steven Bird, Ewan Klein, and Edward Loper. O'Reilly Media, 978-0-596-51649-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Computing with Language: Texts and Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Getting Started with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1:Enter two more expressions of your own. You can use asterisk (*) for multiplication and slash (/) for division, and parentheses for bracketing expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8*5)/4+(4-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Getting Started with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the NLTK Book Collection: browse the available packages using nltk.download()\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the data is downloaded to your machine, you can load some of it using the Python interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first step is to type a special command at the Python prompt which tells the interpreter to load some texts for us to explore: from nltk.book import *. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The book module contains all the data you will need as you read this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any time we want to find out about these texts, we just have to enter their names at the Python prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Searching Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many ways to examine the context of a text apart from simply reading it. A concordance view shows us every occurrence of a given word, together with some context. Here we look up the word monstrous in Moby Dick by entering text1 followed by a period, then the term concordance, and then placing \"monstrous\" in parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: \n",
    "# 1) Search \"Sense and Sensibility\" for the word \"affection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 79 matches:\n",
      ", however , and , as a mark of his affection for the three girls , he left them\n",
      "t . It was very well known that no affection was ever supposed to exist between\n",
      "deration of politeness or maternal affection on the side of the former , the tw\n",
      "d the suspicion -- the hope of his affection for me may warrant , without impru\n",
      "hich forbade the indulgence of his affection . She knew that his mother neither\n",
      "rd she gave one with still greater affection . Though her late conversation wit\n",
      " can never hope to feel or inspire affection again , and if her home be uncomfo\n",
      "m of the sense , elegance , mutual affection , and domestic comfort of the fami\n",
      ", and which recommended him to her affection beyond every thing else . His soci\n",
      "ween the parties might forward the affection of Mr . Willoughby , an equally st\n",
      " the most pointed assurance of her affection . Elinor could not be surprised at\n",
      "he natural consequence of a strong affection in a young and ardent mind . This \n",
      " opinion . But by an appeal to her affection for her mother , by representing t\n",
      " every alteration of a place which affection had established as perfect with hi\n",
      "e will always have one claim of my affection , which no other can possibly shar\n",
      "f the evening declared at once his affection and happiness . \" Shall we see you\n",
      "ause he took leave of us with less affection than his usual behaviour has shewn\n",
      "ness .\" \" I want no proof of their affection ,\" said Elinor ; \" but of their en\n",
      "onths , without telling her of his affection ;-- that they should part without \n",
      "ould be the natural result of your affection for her . She used to be all unres\n",
      "distinguished Elinor by no mark of affection . Marianne saw and listened with i\n",
      "th no inclination for expense , no affection for strangers , no profession , an\n",
      "till distinguished her by the same affection which once she had felt no doubt o\n",
      "al of her confidence in Edward ' s affection , to the remembrance of every mark\n",
      " was made ? Had he never owned his affection to yourself ?\" \" Oh , no ; but if \n"
     ]
    }
   ],
   "source": [
    "text2.concordance(\"affection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2:\n",
    "# 2) Search \"The Book of Genesis\" to find out how long some people \"lived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 38 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "text3.concordance(\"lived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A concordance permits us to see words in context. For example, we saw that monstrous occurred in contexts such as the ___ pictures and a ___ size . What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe that we get different results for different texts. Austen (the author for text2) uses this word quite differently from Melville (the author for text 1); for her, monstrous has positive connotations, and sometimes functions as an intensifier like the word \"very\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149797"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Counting Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the length of a text from start to finish, in terms of the words and punctuation symbols that appear. We use the term len to get the length of something, which we'll apply here to the book of Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So Genesis has 44,764 words and punctuation symbols, or \"tokens.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A token is the technical name for a sequence of characters — such as hairy, his, or :) — that we want to treat as a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many distinct words does the book of Genesis contain? In Python, we can obtain the vocabulary items of text3 with the command: set (text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By wrapping sorted() around the Python expression set(text3) [1], we obtain a sorted list of vocabulary items, beginning with various punctuation symbols and continuing with words starting with A. All capitalized words precede lowercase words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We discover the size of the vocabulary indirectly, by asking for the number of items in the set, and again we can use len to obtain this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although it has 44,764 tokens, this book has only 2,789 distinct words, or \"word types.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A word type is the form or spelling of the word independently of its specific occurrences in a text — that is, the word considered as a unique item of vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our count of 2,789 items will include punctuation symbols, so we will generally call these unique items types instead of word types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's calculate a measure of the lexical richness of the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next example shows us that the number of distinct words is just 6% of the total number of words, or equivalently that each word is used 16 times on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3)) / len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's focus on particular words. We can count how often a word occurs in a text, and compute what percentage of the text is taken up by a specific word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2184"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4.count('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.457973123627309"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text4.count('a') / len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: How many times does the word “lol” appear in text5? How much is this as a percentage of the total number of words in this text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.count(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5640968673628082"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100* text5.count(\"lol\")/len(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to repeat such calculations on several texts, but it is tedious to keep retyping the formula. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, you can come up with your own name for a task, like \"lexical_diversity\" or \"percentage\", and associate it with a block of code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two new functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This parameter is a \"placeholder\" for the actual text whose lexical diversity we want to compute, and reoccurs in the block of code that will run when the function is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, percentage( ) is defined to take two parameters, named count and total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(count, total):\n",
    "    return 100* count/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once Python knows that lexical_diversity() and percentage() are the names for specific blocks of codes, we can go ahead and use these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.457973123627309"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Use the function lexical_diversity () to calculate the Lexical Richness of “Sense and Sensibility” and compute what percentage of this text is taken up by a specific word “the”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04826383002768831"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.727157145278861"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text2.count('the'), len(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q and A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. A Closer Look at Python: Texts as Lists of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a text? At one level, it is a sequence of symbols on a page such as this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At another level, it is a sequence of chapters, made up of a sequence of sections, where each section is a sequence of paragraphs, and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, for our purposes, we will think of a text as nothing more than a sequence of words and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how we represent text in Python, in this case the opening sentence of Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the prompt we've given a name we made up, sent1, followed by the equals sign, and then some quoted words, separated with commas, and surrounded with brackets. \n",
    "# This bracketed material is known as a list in Python: it is how we store a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can inspect it by typing the name. We can ask for its length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can even apply our own lexical_diversity() function to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Make up a few sentences of your own, by typing a name, equals sign, and a list of words, like this: ex1 = ['Monty', 'Python', 'and', 'the', 'Holy', 'Grail’, ‘the’ ]. Repeat some of the other Python operations we saw earlier in 1, e.g., sorted(ex1), len(set(ex1)), ex1.count('the'), lexical_diversity(ex1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = [\"Monty\",\"loves\",\"the\",\"NLP\",\"class\",\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', 'Monty', 'NLP', 'class', 'loves', 'the']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.count(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(ex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding two lists creates a new list with everything from the first list, followed by everything from the second list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This special use of the addition operation is called concatenation; it combines the lists together into a single list. We can concatenate sentences to build up a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Python', 'and', 'the', 'Holy', 'Grail']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Monty', 'Python'] + ['and', 'the', 'Holy', 'Grail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to add a single item to a list? This is known as appending. When we append() to a list, the list itself is updated as a result of the operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1.append(\"Some\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Some']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Indexing Lists\n",
    "# We instruct Python to show us the item that occurs at an index such as 173 in a text by writing the name of the text followed by the index inside square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awaken'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the converse; given a word, find the index of when it first occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4.index('awaken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes are a common way to access the words of a text, or, more generally, the elements of any list. Python permits us to access sublists as well, extracting manageable pieces of language from large texts, a technique known as slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U86',\n",
       " 'thats',\n",
       " 'why',\n",
       " 'something',\n",
       " 'like',\n",
       " 'gamefly',\n",
       " 'is',\n",
       " 'so',\n",
       " 'good',\n",
       " 'because',\n",
       " 'you',\n",
       " 'can',\n",
       " 'actually',\n",
       " 'play',\n",
       " 'a',\n",
       " 'full',\n",
       " 'game',\n",
       " 'without',\n",
       " 'buying',\n",
       " 'it']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5[16715:16735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'\",\n",
       " 're',\n",
       " 'an',\n",
       " 'anarcho',\n",
       " '-',\n",
       " 'syndicalist',\n",
       " 'commune',\n",
       " '.',\n",
       " 'We',\n",
       " 'take',\n",
       " 'it',\n",
       " 'in',\n",
       " 'turns',\n",
       " 'to',\n",
       " 'act',\n",
       " 'as',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'executive',\n",
       " 'officer',\n",
       " 'for',\n",
       " 'the',\n",
       " 'week']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text6[1600:1625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexes have some subtleties, and we'll explore these with the help of an artificial sentence:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=['word1', 'word2', 'word3', 'word4', 'word5','word6', 'word7', 'word8', 'word9', 'word10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word1'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word10'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-baa8b4ccd19d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a closer look at slicing, using our artificial sentence again. Here we verify that the slice 5:8 includes sent elements at indexes 5, 6, and 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By convention, m:n means elements m…n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word6', 'word7', 'word8']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word6'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word7'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word8'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the next example shows, we can omit the first number if the slice begins at the start of the list [1], and we can omit the second number if the slice goes to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word1', 'word2', 'word3']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word5', 'word6', 'word7', 'word8', 'word9', 'word10']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can modify an element of a list by assigning to one of its index values. In the next example, we put sent[0] on the left of the equals sign [1]. We can also replace an entire slice with new material [2]. A consequence of this last change is that the list only has four elements, and accessing a later value generates an erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[0]='First'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[9]='Last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[1:9]=['Second','Third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First', 'Second', 'Third', 'Last']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-9d73df3f8677>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Such lines have the form: variable = expression. Python will evaluate the expression, and save its result to the variable. This process is called assignment. It does not generate any output; you have to type the variable on a line of its own to inspect its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    " my_sent = ['Bravely', 'bold', 'Sir', 'Robin', ',', 'rode', 'forth', 'from', 'Camelot', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrase=my_sent[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bold', 'Sir', 'Robin']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "wOrDs=sorted(noun_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robin', 'Sir', 'bold']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wOrDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that capitalized words appear before lowercase words in sorted lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take care with your choice of names (or identifiers) for Python variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, you should start the name with a letter, optionally followed by digits (0 to 9) or letters. Thus, abc23 is fine, but 23abc will cause a syntax error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names are case-sensitive, which means that myVar and myvar are distinct variables. Variable names cannot contain whitespace, but you can separate words using an underscore, e.g., my_var. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful not to insert a hyphen instead of an underscore: my-var is wrong, since Python interprets the \"-\" as a minus sign.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the methods we used to access the elements of a list also work with individual words, or strings. For example, we can assign a string to a variable [1], index a string [2], and slice a string [3]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Monty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mont'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also perform multiplication and addition with strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MontyMonty'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty!'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name+'!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can join the words of a list to make a single string, or split a string into a list, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['Monty', 'Python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Python']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty Python'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q and A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Computing with Language: Simple Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's return to our exploration of the ways we can bring our computational resources to bear on large quantities of text. We began this discussion in 1, and saw how to search for words in context, how to compile the vocabulary of a text, how to generate random text in the same style, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section we pick up the question of what makes a text distinct, and use automatic methods to find characteristic words and expressions of a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Frequency Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a \"distribution\" because it tells us how the total number of word tokens in the text are distributed across the vocabulary items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we often need frequency distributions in language processing, NLTK provides built-in support for them. Let's use a FreqDist to find the 50 most frequent words of Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = FreqDist(text1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 18713, 'the': 13721, '.': 6862, 'of': 6536, 'and': 6024, 'a': 4569, 'to': 4542, ';': 4072, 'in': 3916, 'that': 2982, ...})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do any words produced in the last example help us grasp the topic or genre of this text? Only one word, whale, is slightly informative! It occurs over 900 times. The rest of the words tell us nothing about the text; they're just English \"plumbing.\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What proportion of the text is taken up with such words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can generate a cumulative frequency plot for these words, using fdist1.plot(50, cumulative=True),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x189457b0a20>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.plot(50, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above 50 words account for nearly half the book!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the frequent words don't help us, how about the words that occur once only, the so-called hapaxes? View them by typing fdist1.hapaxes(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Herman',\n",
       " 'Melville',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'School',\n",
       " 'threadbare',\n",
       " 'lexicons',\n",
       " 'mockingly',\n",
       " 'flags',\n",
       " 'mortality',\n",
       " 'signification',\n",
       " 'HACKLUYT',\n",
       " 'Sw',\n",
       " 'HVAL',\n",
       " 'roundness',\n",
       " 'Dut',\n",
       " 'Ger',\n",
       " 'WALLEN',\n",
       " 'WALW',\n",
       " 'IAN',\n",
       " 'RICHARDSON',\n",
       " 'KETOS',\n",
       " 'GREEK',\n",
       " 'CETUS',\n",
       " 'LATIN',\n",
       " 'WHOEL',\n",
       " 'ANGLO',\n",
       " 'SAXON',\n",
       " 'WAL',\n",
       " 'HWAL',\n",
       " 'SWEDISH',\n",
       " 'ICELANDIC',\n",
       " 'BALEINE',\n",
       " 'BALLENA',\n",
       " 'FEGEE',\n",
       " 'ERROMANGOAN',\n",
       " 'Librarian',\n",
       " 'painstaking',\n",
       " 'burrower',\n",
       " 'grub',\n",
       " 'Vaticans',\n",
       " 'stalls',\n",
       " 'higgledy',\n",
       " 'piggledy',\n",
       " 'gospel',\n",
       " 'promiscuously',\n",
       " 'commentator',\n",
       " 'belongest',\n",
       " 'sallow',\n",
       " 'Pale',\n",
       " 'Sherry',\n",
       " 'loves',\n",
       " 'bluntly',\n",
       " 'Subs',\n",
       " 'thankless',\n",
       " 'Hampton',\n",
       " 'Court',\n",
       " 'hie',\n",
       " 'refugees',\n",
       " 'pampered',\n",
       " 'Michael',\n",
       " 'Raphael',\n",
       " 'unsplinterable',\n",
       " 'GENESIS',\n",
       " 'JOB',\n",
       " 'JONAH',\n",
       " 'punish',\n",
       " 'ISAIAH',\n",
       " 'soever',\n",
       " 'cometh',\n",
       " 'incontinently',\n",
       " 'perisheth',\n",
       " 'PLUTARCH',\n",
       " 'MORALS',\n",
       " 'breedeth',\n",
       " 'Whirlpooles',\n",
       " 'Balaene',\n",
       " 'arpens',\n",
       " 'PLINY',\n",
       " 'Scarcely',\n",
       " 'TOOKE',\n",
       " 'LUCIAN',\n",
       " 'TRUE',\n",
       " 'catched',\n",
       " 'OCTHER',\n",
       " 'VERBAL',\n",
       " 'TAKEN',\n",
       " 'MOUTH',\n",
       " 'ALFRED',\n",
       " '890',\n",
       " 'gudgeon',\n",
       " 'retires',\n",
       " 'MONTAIGNE',\n",
       " 'APOLOGY',\n",
       " 'RAIMOND',\n",
       " 'SEBOND',\n",
       " 'Nick',\n",
       " 'RABELAIS',\n",
       " 'cartloads',\n",
       " 'STOWE',\n",
       " 'ANNALS',\n",
       " 'LORD',\n",
       " 'BACON',\n",
       " 'Touching',\n",
       " 'ork',\n",
       " 'DEATH',\n",
       " 'sovereignest',\n",
       " 'bruise',\n",
       " 'HAMLET',\n",
       " 'leach',\n",
       " 'Mote',\n",
       " 'availle',\n",
       " 'returne',\n",
       " 'againe',\n",
       " 'worker',\n",
       " 'Dinting',\n",
       " 'paine',\n",
       " 'thro',\n",
       " 'maine',\n",
       " 'FAERIE',\n",
       " 'Immense',\n",
       " 'til',\n",
       " 'DAVENANT',\n",
       " 'PREFACE',\n",
       " 'GONDIBERT',\n",
       " 'spermacetti',\n",
       " 'Hosmannus',\n",
       " 'Nescio',\n",
       " 'VIDE',\n",
       " 'Spencer',\n",
       " 'Talus',\n",
       " 'flail',\n",
       " 'threatens',\n",
       " 'jav',\n",
       " 'lins',\n",
       " 'WALLER',\n",
       " 'SUMMER',\n",
       " 'ISLANDS',\n",
       " 'Commonwealth',\n",
       " 'Civitas',\n",
       " 'OPENING',\n",
       " 'SENTENCE',\n",
       " 'HOBBES',\n",
       " 'LEVIATHAN',\n",
       " 'Silly',\n",
       " 'Mansoul',\n",
       " 'chewing',\n",
       " 'sprat',\n",
       " 'PILGRIM',\n",
       " 'PROGRESS',\n",
       " 'Created',\n",
       " 'PARADISE',\n",
       " 'LOST',\n",
       " '---\"',\n",
       " 'Hugest',\n",
       " 'Stretched',\n",
       " 'Draws',\n",
       " 'FULLLER',\n",
       " 'PROFANE',\n",
       " 'HOLY',\n",
       " 'STATE',\n",
       " 'DRYDEN',\n",
       " 'ANNUS',\n",
       " 'MIRABILIS',\n",
       " 'aground',\n",
       " 'EDGE',\n",
       " 'TEN',\n",
       " 'SPITZBERGEN',\n",
       " 'PURCHAS',\n",
       " 'wantonness',\n",
       " 'fuzzing',\n",
       " 'vents',\n",
       " 'HERBERT',\n",
       " 'INTO',\n",
       " 'ASIA',\n",
       " 'AFRICA',\n",
       " 'SCHOUTEN',\n",
       " 'SIXTH',\n",
       " 'CIRCUMNAVIGATION',\n",
       " 'Elbe',\n",
       " 'ducat',\n",
       " 'herrings',\n",
       " 'GREENLAND',\n",
       " 'Several',\n",
       " 'Fife',\n",
       " 'Anno',\n",
       " '1652',\n",
       " 'Pitferren',\n",
       " 'SIBBALD',\n",
       " 'FIFE',\n",
       " 'KINROSS',\n",
       " 'Myself',\n",
       " 'Sperma',\n",
       " 'ceti',\n",
       " 'fierceness',\n",
       " 'RICHARD',\n",
       " 'STRAFFORD',\n",
       " 'LETTER',\n",
       " 'BERMUDAS',\n",
       " 'PHIL',\n",
       " 'TRANS',\n",
       " '1668',\n",
       " 'PRIMER',\n",
       " 'COWLEY',\n",
       " '1729',\n",
       " '\"...',\n",
       " 'frequendy',\n",
       " 'insupportable',\n",
       " 'disorder',\n",
       " 'ULLOA',\n",
       " 'SOUTH',\n",
       " 'AMERICA',\n",
       " 'sylphs',\n",
       " 'petticoat',\n",
       " 'Oft',\n",
       " 'Tho',\n",
       " 'RAPE',\n",
       " 'LOCK',\n",
       " 'NAT',\n",
       " 'wales',\n",
       " 'JOHNSON',\n",
       " 'COOK',\n",
       " 'dung',\n",
       " 'lime',\n",
       " 'juniper',\n",
       " 'UNO',\n",
       " 'VON',\n",
       " 'TROIL',\n",
       " 'LETTERS',\n",
       " 'BANKS',\n",
       " 'SOLANDER',\n",
       " '1772',\n",
       " 'Nantuckois',\n",
       " 'JEFFERSON',\n",
       " 'MEMORIAL',\n",
       " 'MINISTER',\n",
       " 'REFERENCE',\n",
       " 'PARLIAMENT',\n",
       " 'SOMEWHERE',\n",
       " 'guarding',\n",
       " 'protecting',\n",
       " 'robbers',\n",
       " 'BLACKSTONE',\n",
       " 'Rodmond',\n",
       " 'suspends',\n",
       " 'attends',\n",
       " 'FALCONER',\n",
       " 'Bright',\n",
       " 'roofs',\n",
       " 'domes',\n",
       " 'rockets',\n",
       " 'Around',\n",
       " 'unwieldy',\n",
       " 'COWPER',\n",
       " 'VISIT',\n",
       " 'LONDON',\n",
       " 'HUNTER',\n",
       " 'DISSECTION',\n",
       " 'SMALL',\n",
       " 'SIZED',\n",
       " 'aorta',\n",
       " 'gushing',\n",
       " 'PALEY',\n",
       " 'THEOLOGY',\n",
       " 'mammiferous',\n",
       " 'hind',\n",
       " 'BARON',\n",
       " 'CUVIER',\n",
       " 'COLNETT',\n",
       " 'PURPOSE',\n",
       " 'EXTENDING',\n",
       " 'SPERMACETI',\n",
       " 'Floundered',\n",
       " 'chace',\n",
       " 'peopling',\n",
       " 'Gather',\n",
       " 'Led',\n",
       " 'instincts',\n",
       " 'trackless',\n",
       " 'Assaulted',\n",
       " 'voracious',\n",
       " 'spiral',\n",
       " 'MONTGOMERY',\n",
       " 'WORLD',\n",
       " 'FLOOD',\n",
       " 'Paean',\n",
       " 'fatter',\n",
       " 'Flounders',\n",
       " 'CHARLES',\n",
       " 'LAMB',\n",
       " 'TRIUMPH',\n",
       " '1690',\n",
       " 'OBED',\n",
       " 'Susan',\n",
       " 'HAWTHORNE',\n",
       " 'TWICE',\n",
       " 'bespeak',\n",
       " 'raal',\n",
       " 'COOPER',\n",
       " 'PILOT',\n",
       " 'Berlin',\n",
       " 'Gazette',\n",
       " 'ECKERMANN',\n",
       " 'CONVERSATIONS',\n",
       " 'GOETHE',\n",
       " 'ESSEX',\n",
       " 'WAS',\n",
       " 'ATTACKED',\n",
       " 'FINALLY',\n",
       " 'DESTROYED',\n",
       " 'OWEN',\n",
       " 'CHACE',\n",
       " 'FIRST',\n",
       " 'SAID',\n",
       " 'VESSEL',\n",
       " 'YORK',\n",
       " '1821',\n",
       " 'piping',\n",
       " 'dimmed',\n",
       " 'phospher',\n",
       " 'ELIZABETH',\n",
       " 'OAKES',\n",
       " 'SMITH',\n",
       " 'amounted',\n",
       " '440',\n",
       " 'SCORESBY',\n",
       " 'Mad',\n",
       " 'agonies',\n",
       " 'endures',\n",
       " 'infuriated',\n",
       " 'rears',\n",
       " 'snaps',\n",
       " 'propelled',\n",
       " 'observers',\n",
       " 'opportunities',\n",
       " 'habitudes',\n",
       " 'BEALE',\n",
       " 'offensively',\n",
       " 'artful',\n",
       " 'mischievous',\n",
       " 'FREDERICK',\n",
       " 'DEBELL',\n",
       " '1840',\n",
       " 'October',\n",
       " 'Raise',\n",
       " 'ay',\n",
       " 'THAR',\n",
       " 'bowes',\n",
       " 'os',\n",
       " 'ROSS',\n",
       " 'ETCHINGS',\n",
       " 'CRUIZE',\n",
       " '1846',\n",
       " 'Globe',\n",
       " 'transactions',\n",
       " 'relate',\n",
       " 'HUSSEY',\n",
       " 'SURVIVORS',\n",
       " 'parried',\n",
       " 'MISSIONARY',\n",
       " 'JOURNAL',\n",
       " 'TYERMAN',\n",
       " 'boldest',\n",
       " 'persevering',\n",
       " 'REPORT',\n",
       " 'DANIEL',\n",
       " 'SPEECH',\n",
       " 'SENATE',\n",
       " 'APPLICATION',\n",
       " 'ERECTION',\n",
       " 'BREAKWATER',\n",
       " 'CAPTORS',\n",
       " 'WHALEMAN',\n",
       " 'ADVENTURES',\n",
       " 'BIOGRAPHY',\n",
       " 'GATHERED',\n",
       " 'HOMEWARD',\n",
       " 'COMMODORE',\n",
       " 'PREBLE',\n",
       " 'REV',\n",
       " 'CHEEVER',\n",
       " 'MUTINEER',\n",
       " 'BROTHER',\n",
       " 'ANOTHER',\n",
       " 'MCCULLOCH',\n",
       " 'COMMERCIAL',\n",
       " 'reciprocal',\n",
       " 'clews',\n",
       " 'SOMETHING',\n",
       " 'UNPUBLISHED',\n",
       " 'CURRENTS',\n",
       " 'Pedestrians',\n",
       " 'recollect',\n",
       " 'gateways',\n",
       " 'VOYAGER',\n",
       " 'ARCTIC',\n",
       " 'NEWSPAPER',\n",
       " 'TAKING',\n",
       " 'RETAKING',\n",
       " 'HOBOMACK',\n",
       " 'MIRIAM',\n",
       " 'FISHERMAN',\n",
       " 'appliance',\n",
       " 'RIBS',\n",
       " 'TRUCKS',\n",
       " 'Terra',\n",
       " 'Del',\n",
       " 'Fuego',\n",
       " 'DARWIN',\n",
       " 'NATURALIST',\n",
       " \";--'\",\n",
       " '!\\'\"',\n",
       " 'WHARTON',\n",
       " 'Loomings',\n",
       " 'spleen',\n",
       " 'regulating',\n",
       " 'circulation',\n",
       " 'Whenever',\n",
       " 'drizzly',\n",
       " 'hypos',\n",
       " 'philosophical',\n",
       " 'Cato',\n",
       " 'Manhattoes',\n",
       " 'reefs',\n",
       " 'downtown',\n",
       " 'gazers',\n",
       " 'Circumambulate',\n",
       " 'Corlears',\n",
       " 'Coenties',\n",
       " 'Slip',\n",
       " 'Whitehall',\n",
       " 'Posted',\n",
       " 'sentinels',\n",
       " 'spiles',\n",
       " 'pier',\n",
       " 'lath',\n",
       " 'counters',\n",
       " 'desks',\n",
       " 'loitering',\n",
       " 'shady',\n",
       " 'Inlanders',\n",
       " 'lanes',\n",
       " 'alleys',\n",
       " 'attract',\n",
       " 'dale',\n",
       " 'dreamiest',\n",
       " 'shadiest',\n",
       " 'quietest',\n",
       " 'enchanting',\n",
       " 'Saco',\n",
       " 'crucifix',\n",
       " 'Deep',\n",
       " 'mazy',\n",
       " 'Tiger',\n",
       " 'Tennessee',\n",
       " 'Rockaway',\n",
       " 'Persians',\n",
       " 'deity',\n",
       " 'Narcissus',\n",
       " 'ungraspable',\n",
       " 'hazy',\n",
       " 'quarrelsome',\n",
       " 'offices',\n",
       " 'abominate',\n",
       " 'toils',\n",
       " 'trials',\n",
       " 'barques',\n",
       " 'schooners',\n",
       " 'broiling',\n",
       " 'buttered',\n",
       " 'judgmatically',\n",
       " 'peppered',\n",
       " 'reverentially',\n",
       " 'idolatrous',\n",
       " 'dotings',\n",
       " 'ibis',\n",
       " 'roasted',\n",
       " 'bake',\n",
       " 'plumb',\n",
       " 'Van',\n",
       " 'Rensselaers',\n",
       " 'Randolphs',\n",
       " 'Hardicanutes',\n",
       " 'lording',\n",
       " 'tallest',\n",
       " 'decoction',\n",
       " 'Seneca',\n",
       " 'Stoics',\n",
       " 'Testament',\n",
       " 'promptly',\n",
       " 'rub',\n",
       " 'infliction',\n",
       " 'BEING',\n",
       " 'PAID',\n",
       " 'urbane',\n",
       " 'ills',\n",
       " 'monied',\n",
       " 'consign',\n",
       " 'prevalent',\n",
       " 'violate',\n",
       " 'Pythagorean',\n",
       " 'commonalty',\n",
       " 'police',\n",
       " 'surveillance',\n",
       " 'programme',\n",
       " 'solo',\n",
       " 'CONTESTED',\n",
       " 'ELECTION',\n",
       " 'PRESIDENCY',\n",
       " 'UNITED',\n",
       " 'STATES',\n",
       " 'ISHMAEL',\n",
       " 'BLOODY',\n",
       " 'AFFGHANISTAN',\n",
       " 'managers',\n",
       " 'genteel',\n",
       " 'comedies',\n",
       " 'farces',\n",
       " 'cunningly',\n",
       " 'disguises',\n",
       " 'cajoling',\n",
       " 'unbiased',\n",
       " 'freewill',\n",
       " 'discriminating',\n",
       " 'overwhelming',\n",
       " 'undeliverable',\n",
       " 'itch',\n",
       " 'forbidden',\n",
       " 'ignoring',\n",
       " 'lodges',\n",
       " 'Carpet',\n",
       " 'Bag',\n",
       " 'Manhatto',\n",
       " 'candidates',\n",
       " 'penalties',\n",
       " 'Tyre',\n",
       " 'Carthage',\n",
       " 'imported',\n",
       " 'cobblestones',\n",
       " 'bitingly',\n",
       " 'shouldering',\n",
       " 'price',\n",
       " 'fervent',\n",
       " 'asphaltic',\n",
       " 'pavement',\n",
       " 'flinty',\n",
       " 'projections',\n",
       " 'soles',\n",
       " 'Too',\n",
       " 'cheapest',\n",
       " 'cheeriest',\n",
       " 'invitingly',\n",
       " 'particles',\n",
       " 'peer',\n",
       " 'Angel',\n",
       " 'Doom',\n",
       " 'wailing',\n",
       " 'gnashing',\n",
       " 'Wretched',\n",
       " 'entertainment',\n",
       " 'Moving',\n",
       " 'emigrant',\n",
       " 'poverty',\n",
       " 'creak',\n",
       " 'lodgings',\n",
       " 'zephyr',\n",
       " 'hob',\n",
       " 'toasting',\n",
       " 'observest',\n",
       " 'sashless',\n",
       " 'glazier',\n",
       " 'reasonest',\n",
       " 'chinks',\n",
       " 'crannies',\n",
       " 'lint',\n",
       " 'chattering',\n",
       " 'shiverings',\n",
       " 'cob',\n",
       " 'redder',\n",
       " 'Orion',\n",
       " 'glitters',\n",
       " 'conservatories',\n",
       " 'president',\n",
       " 'temperance',\n",
       " 'blubbering',\n",
       " 'straggling',\n",
       " 'wainscots',\n",
       " 'reminding',\n",
       " 'oilpainting',\n",
       " 'besmoked',\n",
       " 'defaced',\n",
       " 'unequal',\n",
       " 'crosslights',\n",
       " 'hags',\n",
       " 'delineate',\n",
       " 'bewitched',\n",
       " 'ponderings',\n",
       " 'boggy',\n",
       " 'soggy',\n",
       " 'squitchy',\n",
       " 'froze',\n",
       " 'heath',\n",
       " 'icebound',\n",
       " 'represents',\n",
       " 'Horner',\n",
       " 'foundered',\n",
       " 'clubs',\n",
       " 'harvesting',\n",
       " 'hacking',\n",
       " 'horrifying',\n",
       " 'Mixed',\n",
       " 'Nathan',\n",
       " 'Swain',\n",
       " 'corkscrew',\n",
       " 'Blanco',\n",
       " 'sojourning',\n",
       " 'fireplaces',\n",
       " 'duskier',\n",
       " 'cockpits',\n",
       " 'rarities',\n",
       " 'Projecting',\n",
       " 'Within',\n",
       " 'shelves',\n",
       " 'flasks',\n",
       " 'bustles',\n",
       " 'deliriums',\n",
       " 'Abominable',\n",
       " 'tumblers',\n",
       " 'cylinders',\n",
       " 'goggling',\n",
       " 'deceitfully',\n",
       " 'tapered',\n",
       " 'Parallel',\n",
       " 'pecked',\n",
       " 'footpads',\n",
       " 'Fill',\n",
       " 'shilling',\n",
       " 'examining',\n",
       " 'SKRIMSHANDER',\n",
       " 'accommodated',\n",
       " 'unoccupied',\n",
       " 'haint',\n",
       " 'pose',\n",
       " 'whalin',\n",
       " 'decidedly',\n",
       " 'objectionable',\n",
       " 'wander',\n",
       " 'Battery',\n",
       " 'ruminating',\n",
       " 'adorning',\n",
       " 'potatoes',\n",
       " 'sartainty',\n",
       " 'diabolically',\n",
       " 'steaks',\n",
       " 'undress',\n",
       " 'looker',\n",
       " 'rioting',\n",
       " 'Grampus',\n",
       " 'seed',\n",
       " 'Feegees',\n",
       " 'tramping',\n",
       " 'Enveloped',\n",
       " 'bedarned',\n",
       " 'eruption',\n",
       " 'officiating',\n",
       " 'brimmers',\n",
       " 'complained',\n",
       " 'potion',\n",
       " 'colds',\n",
       " 'catarrhs',\n",
       " 'liquor',\n",
       " 'arrantest',\n",
       " 'topers',\n",
       " 'obstreperously',\n",
       " 'aloof',\n",
       " 'desirous',\n",
       " 'hilarity',\n",
       " 'coffer',\n",
       " 'Southerner',\n",
       " 'mountaineers',\n",
       " 'Alleghanian',\n",
       " 'missed',\n",
       " 'supernaturally',\n",
       " 'congratulate',\n",
       " 'multiply',\n",
       " 'bachelor',\n",
       " 'abominated',\n",
       " 'tidiest',\n",
       " 'bedwards',\n",
       " 'shan',\n",
       " 'tablecloth',\n",
       " 'Skrimshander',\n",
       " 'bump',\n",
       " 'spraining',\n",
       " 'eider',\n",
       " 'yoking',\n",
       " 'rickety',\n",
       " 'whirlwinds',\n",
       " 'knockings',\n",
       " 'dismissed',\n",
       " 'popped',\n",
       " 'cherishing',\n",
       " 'chuckled',\n",
       " 'chuckle',\n",
       " 'mightily',\n",
       " 'catches',\n",
       " 'bamboozingly',\n",
       " 'overstocked',\n",
       " 'toothpick',\n",
       " 'rayther',\n",
       " 'BROWN',\n",
       " 'slanderin',\n",
       " 'farrago',\n",
       " 'BROKE',\n",
       " 'Sartain',\n",
       " 'Mt',\n",
       " 'Hecla',\n",
       " 'persist',\n",
       " 'mystifying',\n",
       " 'unsay',\n",
       " 'criminal',\n",
       " 'Wall',\n",
       " 'purty',\n",
       " 'sarmon',\n",
       " 'rips',\n",
       " 'tellin',\n",
       " 'bought',\n",
       " 'balmed',\n",
       " 'curios',\n",
       " 'sellin',\n",
       " 'inions',\n",
       " 'fooling',\n",
       " 'idolators',\n",
       " 'Depend',\n",
       " 'reg',\n",
       " 'lar',\n",
       " 'spliced',\n",
       " 'Johnny',\n",
       " 'sprawling',\n",
       " 'Arter',\n",
       " 'glim',\n",
       " 'jiffy',\n",
       " 'irresolute',\n",
       " 'vum',\n",
       " 'WON',\n",
       " 'Folding',\n",
       " 'scrutiny',\n",
       " 'porcupine',\n",
       " 'moccasin',\n",
       " 'ponchos',\n",
       " 'parade',\n",
       " 'rainy',\n",
       " 'remembering',\n",
       " 'commended',\n",
       " 'cobs',\n",
       " 'Nod',\n",
       " 'footfall',\n",
       " 'unlacing',\n",
       " 'blackish',\n",
       " 'plasters',\n",
       " 'inkling',\n",
       " 'Placing',\n",
       " 'crammed',\n",
       " 'scalp',\n",
       " 'mildewed',\n",
       " 'Ignorance',\n",
       " 'parent',\n",
       " 'nonplussed',\n",
       " 'undressing',\n",
       " 'checkered',\n",
       " 'Thirty',\n",
       " 'frogs',\n",
       " 'quaked',\n",
       " 'wrapall',\n",
       " 'dreadnaught',\n",
       " 'fumbled',\n",
       " 'Remembering',\n",
       " 'manikin',\n",
       " 'tenpin',\n",
       " 'andirons',\n",
       " 'jambs',\n",
       " 'bricks',\n",
       " 'appropriate',\n",
       " 'applying',\n",
       " 'hastier',\n",
       " 'withdrawals',\n",
       " 'antics',\n",
       " 'devotee',\n",
       " 'extinguishing',\n",
       " 'unceremoniously',\n",
       " 'bagged',\n",
       " 'sportsman',\n",
       " 'woodcock',\n",
       " 'uncomfortableness',\n",
       " 'deliberating',\n",
       " 'puffed',\n",
       " 'sang',\n",
       " 'Stammering',\n",
       " 'conjured',\n",
       " 'responses',\n",
       " 'debel',\n",
       " 'flourishing',\n",
       " 'Angels',\n",
       " 'flourishings',\n",
       " 'peddlin',\n",
       " 'sleepe',\n",
       " 'grunted',\n",
       " 'gettee',\n",
       " 'motioning',\n",
       " 'comely',\n",
       " 'insured',\n",
       " 'Counterpane',\n",
       " 'parti',\n",
       " 'triangles',\n",
       " 'interminable',\n",
       " 'caper',\n",
       " 'supperless',\n",
       " '21st',\n",
       " 'hemisphere',\n",
       " 'sigh',\n",
       " 'Sixteen',\n",
       " 'ached',\n",
       " 'coaches',\n",
       " 'stockinged',\n",
       " 'slippering',\n",
       " 'misbehaviour',\n",
       " 'unendurable',\n",
       " 'stepmothers',\n",
       " 'misfortunes',\n",
       " 'steeped',\n",
       " 'shudderingly',\n",
       " 'confounding',\n",
       " 'soberly',\n",
       " 'recurred',\n",
       " 'predicament',\n",
       " 'unlock',\n",
       " 'bridegroom',\n",
       " 'clasp',\n",
       " 'hugged',\n",
       " 'rouse',\n",
       " 'snore',\n",
       " 'scratch',\n",
       " 'Throwing',\n",
       " 'expostulations',\n",
       " 'unbecomingness',\n",
       " 'matrimonial',\n",
       " 'dawning',\n",
       " 'overture',\n",
       " 'innate',\n",
       " 'compliment',\n",
       " 'civility',\n",
       " 'rudeness',\n",
       " 'toilette',\n",
       " 'dressing',\n",
       " 'donning',\n",
       " 'gaspings',\n",
       " 'booting',\n",
       " 'caterpillar',\n",
       " 'outlandishness',\n",
       " 'manners',\n",
       " 'education',\n",
       " 'undergraduate',\n",
       " 'dreamt',\n",
       " 'cowhide',\n",
       " 'pinched',\n",
       " 'curtains',\n",
       " 'indecorous',\n",
       " 'contented',\n",
       " 'restricting',\n",
       " 'donned',\n",
       " 'lathering',\n",
       " 'unsheathes',\n",
       " 'whets',\n",
       " 'Rogers',\n",
       " 'cutlery',\n",
       " 'Afterwards',\n",
       " 'baton',\n",
       " 'Breakfast',\n",
       " 'pleasantly',\n",
       " 'bountifully',\n",
       " 'laughable',\n",
       " 'bosky',\n",
       " 'unshorn',\n",
       " 'gowns',\n",
       " 'toasted',\n",
       " 'lingers',\n",
       " 'tarried',\n",
       " 'barred',\n",
       " 'Grub',\n",
       " 'Park',\n",
       " 'assurance',\n",
       " 'polish',\n",
       " 'occasioned',\n",
       " 'embarrassed',\n",
       " 'bashfulness',\n",
       " 'duelled',\n",
       " 'winking',\n",
       " 'tastes',\n",
       " 'sheepishly',\n",
       " 'bashful',\n",
       " 'icicle',\n",
       " 'admirer',\n",
       " 'cordially',\n",
       " 'grappling',\n",
       " 'genteelly',\n",
       " 'eschewed',\n",
       " 'undivided',\n",
       " '6',\n",
       " 'circulating',\n",
       " 'nondescripts',\n",
       " 'Chestnut',\n",
       " 'jostle',\n",
       " 'Regent',\n",
       " 'Lascars',\n",
       " 'Bombay',\n",
       " 'Apollo',\n",
       " 'Feegeeans',\n",
       " 'Tongatobooarrs',\n",
       " 'Erromanggoans',\n",
       " 'Pannangians',\n",
       " 'Brighggians',\n",
       " 'weekly',\n",
       " 'Vermonters',\n",
       " 'stalwart',\n",
       " 'frames',\n",
       " 'felled',\n",
       " 'strutting',\n",
       " 'wester',\n",
       " 'bombazine',\n",
       " 'cloak',\n",
       " 'mow',\n",
       " 'gloves',\n",
       " 'joins',\n",
       " 'outfit',\n",
       " 'waistcoats',\n",
       " 'Hay',\n",
       " 'Seed',\n",
       " 'tract',\n",
       " 'dearest',\n",
       " 'pave',\n",
       " 'eggs',\n",
       " 'patrician',\n",
       " 'parks',\n",
       " 'scraggy',\n",
       " 'scoria',\n",
       " 'Herr',\n",
       " 'dowers',\n",
       " 'nieces',\n",
       " 'reservoirs',\n",
       " 'maples',\n",
       " 'bountiful',\n",
       " 'proffer',\n",
       " 'passer',\n",
       " 'cones',\n",
       " 'blossoms',\n",
       " 'superinduced',\n",
       " 'carnation',\n",
       " 'Salem',\n",
       " 'sweethearts',\n",
       " 'Puritanic',\n",
       " 'Whaleman',\n",
       " 'Wrapping',\n",
       " 'Each',\n",
       " 'quote',\n",
       " 'TALBOT',\n",
       " 'Near',\n",
       " 'Desolation',\n",
       " '1st',\n",
       " 'SISTER',\n",
       " 'ROBERT',\n",
       " 'WILLIS',\n",
       " 'ELLERY',\n",
       " 'NATHAN',\n",
       " 'COLEMAN',\n",
       " 'WALTER',\n",
       " 'CANNY',\n",
       " 'SETH',\n",
       " 'GLEIG',\n",
       " 'Forming',\n",
       " 'ELIZA',\n",
       " '31st',\n",
       " 'MARBLE',\n",
       " 'SHIPMATES',\n",
       " 'EZEKIEL',\n",
       " 'HARDY',\n",
       " 'AUGUST',\n",
       " '3d',\n",
       " '1833',\n",
       " 'WIDOW',\n",
       " 'Shaking',\n",
       " 'glazed',\n",
       " 'Affected',\n",
       " 'relatives',\n",
       " 'unhealing',\n",
       " 'sympathetically',\n",
       " 'wounds',\n",
       " 'bleed',\n",
       " 'blanks',\n",
       " ...]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9002"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist1.hapaxes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list contains lexicographer, cetological, contraband, expostulations, and about 9,000 others. It seems that there are too many rare words, and without seeing the context we probably can't guess what half of the hapaxes mean in any case! Since neither frequent nor infrequent words help, we need to try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6.  Try the preceding frequency distribution example for yourself, for text2. Output the 10 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist2 = FreqDist(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Fine-grained Selection of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6833 samples and 141576 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 9397, 'to': 4063, '.': 3975, 'the': 3861, 'of': 3565, 'and': 3350, 'her': 2436, 'a': 2043, 'I': 2004, 'in': 1904, ...})"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 9397),\n",
       " ('to', 4063),\n",
       " ('.', 3975),\n",
       " ('the', 3861),\n",
       " ('of', 3565),\n",
       " ('and', 3350),\n",
       " ('her', 2436),\n",
       " ('a', 2043),\n",
       " ('I', 2004),\n",
       " ('in', 1904)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, let's look at the long words of a text; perhaps these will be more characteristic and informative. For this we adapt some notation from set theory. We would like to find the words from the vocabulary of the text that are more than 15 characters long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word w in the vocabulary V, we check whether len(w) is greater than 15; all other words will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "V=set(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_words=[w for w in V if len(w)>15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIRCUMNAVIGATION',\n",
       " 'Physiognomically',\n",
       " 'apprehensiveness',\n",
       " 'cannibalistically',\n",
       " 'characteristically',\n",
       " 'circumnavigating',\n",
       " 'circumnavigation',\n",
       " 'circumnavigations',\n",
       " 'comprehensiveness',\n",
       " 'hermaphroditical',\n",
       " 'indiscriminately',\n",
       " 'indispensableness',\n",
       " 'irresistibleness',\n",
       " 'physiognomically',\n",
       " 'preternaturalness',\n",
       " 'responsibilities',\n",
       " 'simultaneousness',\n",
       " 'subterraneousness',\n",
       " 'supernaturalness',\n",
       " 'superstitiousness',\n",
       " 'uncomfortableness',\n",
       " 'uncompromisedness',\n",
       " 'undiscriminating',\n",
       " 'uninterpenetratingly']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  these very long words are often hapaxes (i.e., unique) and perhaps it would be better to find frequently occurring long words. This seems promising since it eliminates frequent short words (e.g., the) and infrequent long words (e.g. antiphilosophists). Here are all words from the chat corpus that are longer than seven characters, that occur more than seven times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist5=FreqDist(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#14-19teens',\n",
       " '#talkcity_adults',\n",
       " '((((((((((',\n",
       " '........',\n",
       " 'Question',\n",
       " 'actually',\n",
       " 'anything',\n",
       " 'computer',\n",
       " 'cute.-ass',\n",
       " 'everyone',\n",
       " 'football',\n",
       " 'innocent',\n",
       " 'listening',\n",
       " 'remember',\n",
       " 'seriously',\n",
       " 'something',\n",
       " 'together',\n",
       " 'tomorrow',\n",
       " 'watching']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text5) if len(w)>7 and fdist5[w]>7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how we have used two conditions: len(w) > 7 ensures that the words are longer than seven letters, and fdist5[w] > 7 ensures that these words occur more than seven times. At last we have managed to automatically identify the frequently-occurring content-bearing words of the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is a modest but important milestone: a tiny piece of code, processing tens of thousands of words, produces some informative output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Collocations and Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A collocation is a sequence of words that occur together unusually often. Thus red wine is a collocation, whereas the wine is not. A characteristic of collocations is that they are resistant to substitution with words that have similar senses; for example, maroon wine sounds definitely odd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a handle on collocations, we start off by extracting from a text a list of word pairs, also known as bigrams. This is easily accomplished with the function bigrams():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('more', 'is'), ('is', 'said'), ('said', 'than'), ('than', 'done')]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(['more', 'is', 'said', 'than', 'done']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see that the pair of words than-done is a bigram, and we write it in Python as ('than', 'done’). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collocations are essentially just frequent bigrams, except that we want to pay more attention to the cases that involve rare words. In particular, we want to find bigrams that occur more often than we would expect based on the frequency of the individual words. The collocations() function does this for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal Government; General Government; American people; Vice President; God bless; Chief Justice; Old World; Almighty God; Fellow citizens; Chief Magistrate; every citizen; one another; fellow Americans; Indian tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "print('; '.join(text4.collocation_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would like; medium build; social drinker; quiet nights; non smoker; long term; age open; Would like; easy going; financially secure; fun times; similar interests; Age open; weekends away; poss rship; well presented; never married; single mum; permanent relationship; slim build\n"
     ]
    }
   ],
   "source": [
    "print('; '.join(text8.collocation_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Counting Other Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting words is useful, but we can count other things too. For example, we can look at the distribution of word lengths in a text, by creating a FreqDist out of a long list of numbers, where each number is the length of the corresponding word in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist=FreqDist(len(w) for w in text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19 samples and 260819 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({3: 50223, 1: 47933, 4: 42345, 2: 38513, 5: 26597, 6: 17111, 7: 14399, 8: 9966, 9: 6428, 10: 3528, ...})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But there are at most only 20 distinct items being counted, the numbers 1 through 20, because there are only 20 different word lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 50223),\n",
       " (1, 47933),\n",
       " (4, 42345),\n",
       " (2, 38513),\n",
       " (5, 26597),\n",
       " (6, 17111),\n",
       " (7, 14399),\n",
       " (8, 9966),\n",
       " (9, 6428),\n",
       " (10, 3528),\n",
       " (11, 1873),\n",
       " (12, 1053),\n",
       " (13, 567),\n",
       " (14, 177),\n",
       " (15, 70),\n",
       " (16, 22),\n",
       " (17, 12),\n",
       " (18, 1),\n",
       " (20, 1)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50223"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19255882431878046"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.freq(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this we see that the most frequent word length is 3, and that words of length 3 account for roughly 50,000 (or 20%) of the words making up the book. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions Defined for NLTK's Frequency Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist=FreqDist(samples) # create a frequency distribution dictionary containing the given samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist['monstrous']  # count of the number of times a given word occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist.freq('monstrous') # count the frequency of a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist.N()  # count the total number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist.most_common(n) # the n most common samples and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist.max() # sample with the greatest count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist.tabulate() # tabulate the frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist.plot（）# graphical plot of the frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 18713, 'the': 13721, '.': 6862, 'of': 6536, 'and': 6024, 'a': 4569, 'to': 4542, ';': 4072, 'in': 3916, 'that': 2982, ...})"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['monstrous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.834076505162584e-05"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.freq('monstrous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q and A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Back to Python: Making Decisions and Taking Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far, our little programs have had some interesting qualities: the ability to work with language, and the potential to save human effort through automation. A key feature of programming is the ability of machines to make decisions on our behalf, executing instructions when certain conditions are met, or repeatedly looping through text data until some condition is satisfied. This feature is known as control, and is the focus of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python supports a wide range of operators, such as <, >=,!=, for testing the relationship between values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use these to select different words from a sentence of news text. Here are some examples — only the operator is changed from one line to the next. They all use sent7, the first sentence from text7 (Wall Street Journal). As before, if you get an error saying that sent7 is undefined, you need to first type: from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '61', 'old', ',', 'the', 'as', 'a', '29', '.']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '61', 'old', ',', 'will', 'join', 'the', 'as', 'a', 'Nov.', '29', '.']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [w for w in sent7 if len(w) <= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will', 'join', 'Nov.']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [w for w in sent7 if len(w) != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Word Comparision Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.startswith(t)  # test if s starts with t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.endswith(t)  # test if s ends with t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t in s   # test if t is a substring of s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.islower() # test if s contains cased characters and all are lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.isupper() # test if s contains cased characters and all are uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.isalpha() # test if s is non-empty and all characters in s are alphabetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.isalnum() # test if s is non-empty and all characters in s are alphanumeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.isdigit() # test if s is non-empty and all characters in s are digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.istitle() # test if s contains cased characters and is titlecased(i.e. all words in s have initial capitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are some examples of these operators being used to select words from our texts: words ending with -ableness; words containing gnt; words having an initial capital; and words consisting entirely of digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nonexecutive']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(sent7) if w.startswith('non'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'as',\n",
       " 'board',\n",
       " 'director',\n",
       " 'join',\n",
       " 'nonexecutive',\n",
       " 'old',\n",
       " 'the',\n",
       " 'will',\n",
       " 'years']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.isupper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " 'a',\n",
       " 'as',\n",
       " 'board',\n",
       " 'director',\n",
       " 'join',\n",
       " 'nonexecutive',\n",
       " 'old',\n",
       " 'the',\n",
       " 'will',\n",
       " 'years']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.isalpha())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29',\n",
       " '61',\n",
       " 'Pierre',\n",
       " 'Vinken',\n",
       " 'a',\n",
       " 'as',\n",
       " 'board',\n",
       " 'director',\n",
       " 'join',\n",
       " 'nonexecutive',\n",
       " 'old',\n",
       " 'the',\n",
       " 'will',\n",
       " 'years']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.isalnum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comfortableness',\n",
       " 'honourableness',\n",
       " 'immutableness',\n",
       " 'indispensableness',\n",
       " 'indomitableness',\n",
       " 'intolerableness',\n",
       " 'palpableness',\n",
       " 'reasonableness',\n",
       " 'uncomfortableness']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text1) if w.endswith('ableness'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sovereignty', 'sovereignties', 'sovereignty']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(term for term in set(text4) if 'gnt' in term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nov.', 'Pierre', 'Vinken']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.istitle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '61']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also create more complex conditions. If c is a condition, then not c is also a condition. If we have two conditions c1 and c2, then we can combine them to form a new condition using conjunction and disjunction: c1 and c2, c1 or c2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7 Run the following examples and try to explain what is going on in each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock-index',\n",
       " 'index-arbitrage',\n",
       " 'index-fund',\n",
       " 'index-options',\n",
       " 'index-related',\n",
       " 'stock-index']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text7) if '-' in w and 'index' in w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Returns all the words which have hyphen and index, both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abelmizraim',\n",
       " 'Allonbachuth',\n",
       " 'Beerlahairoi',\n",
       " 'Canaanitish',\n",
       " 'Chedorlaomer',\n",
       " 'Girgashites',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Ishmeelites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Kirjatharba',\n",
       " 'Melchizedek',\n",
       " 'Mesopotamia',\n",
       " 'Peradventure',\n",
       " 'Philistines',\n",
       " 'Zaphnathpaaneah']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wd for wd in set(text3) if wd.istitle() and len(wd) > 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Return words with more than 1o syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', '29', '61', 'Nov.', 'Pierre', 'Vinken']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(sent7) if not w.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: All elements which are not lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ancient',\n",
       " 'ceiling',\n",
       " 'conceit',\n",
       " 'conceited',\n",
       " 'conceive',\n",
       " 'conscience',\n",
       " 'conscientious',\n",
       " 'conscientiously',\n",
       " 'deceitful',\n",
       " 'deceive',\n",
       " 'deceived',\n",
       " 'deceiving',\n",
       " 'deficiencies',\n",
       " 'deficiency',\n",
       " 'deficient',\n",
       " 'delicacies',\n",
       " 'excellencies',\n",
       " 'fancied',\n",
       " 'insufficiency',\n",
       " 'insufficient',\n",
       " 'legacies',\n",
       " 'perceive',\n",
       " 'perceived',\n",
       " 'perceiving',\n",
       " 'prescience',\n",
       " 'prophecies',\n",
       " 'receipt',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'receiving',\n",
       " 'society',\n",
       " 'species',\n",
       " 'sufficient',\n",
       " 'sufficiently',\n",
       " 'undeceive',\n",
       " 'undeceiving']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t for t in set(text2) if 'cie' in t or 'cei' in t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Returns words which have cei or cie in it as they seem to be tricky and then sort them in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2  Operating on Every Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python performs the same operation on every element of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In 3, we saw some examples of counting items other than words. Let's take a closer look at the notation we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Length of each words in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'MOBY',\n",
       " 'DICK',\n",
       " 'BY',\n",
       " 'HERMAN',\n",
       " 'MELVILLE',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'SUPPLIED',\n",
       " 'BY',\n",
       " 'A',\n",
       " 'LATE',\n",
       " 'CONSUMPTIVE',\n",
       " 'USHER',\n",
       " 'TO',\n",
       " 'A',\n",
       " 'GRAMMAR',\n",
       " 'SCHOOL',\n",
       " ')',\n",
       " 'THE',\n",
       " 'PALE',\n",
       " 'USHER',\n",
       " '--',\n",
       " 'THREADBARE',\n",
       " 'IN',\n",
       " 'COAT',\n",
       " ',',\n",
       " 'HEART',\n",
       " ',',\n",
       " 'BODY',\n",
       " ',',\n",
       " 'AND',\n",
       " 'BRAIN',\n",
       " ';',\n",
       " 'I',\n",
       " 'SEE',\n",
       " 'HIM',\n",
       " 'NOW',\n",
       " '.',\n",
       " 'HE',\n",
       " 'WAS',\n",
       " 'EVER',\n",
       " 'DUSTING',\n",
       " 'HIS',\n",
       " 'OLD',\n",
       " 'LEXICONS',\n",
       " 'AND',\n",
       " 'GRAMMARS',\n",
       " ',',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'QUEER',\n",
       " 'HANDKERCHIEF',\n",
       " ',',\n",
       " 'MOCKINGLY',\n",
       " 'EMBELLISHED',\n",
       " 'WITH',\n",
       " 'ALL',\n",
       " 'THE',\n",
       " 'GAY',\n",
       " 'FLAGS',\n",
       " 'OF',\n",
       " 'ALL',\n",
       " 'THE',\n",
       " 'KNOWN',\n",
       " 'NATIONS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'WORLD',\n",
       " '.',\n",
       " 'HE',\n",
       " 'LOVED',\n",
       " 'TO',\n",
       " 'DUST',\n",
       " 'HIS',\n",
       " 'OLD',\n",
       " 'GRAMMARS',\n",
       " ';',\n",
       " 'IT',\n",
       " 'SOMEHOW',\n",
       " 'MILDLY',\n",
       " 'REMINDED',\n",
       " 'HIM',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " 'MORTALITY',\n",
       " '.',\n",
       " '\"',\n",
       " 'WHILE',\n",
       " 'YOU',\n",
       " 'TAKE',\n",
       " 'IN',\n",
       " 'HAND',\n",
       " 'TO',\n",
       " 'SCHOOL',\n",
       " 'OTHERS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'TO',\n",
       " 'TEACH',\n",
       " 'THEM',\n",
       " 'BY',\n",
       " 'WHAT',\n",
       " 'NAME',\n",
       " 'A',\n",
       " 'WHALE',\n",
       " '-',\n",
       " 'FISH',\n",
       " 'IS',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'CALLED',\n",
       " 'IN',\n",
       " 'OUR',\n",
       " 'TONGUE',\n",
       " 'LEAVING',\n",
       " 'OUT',\n",
       " ',',\n",
       " 'THROUGH',\n",
       " 'IGNORANCE',\n",
       " ',',\n",
       " 'THE',\n",
       " 'LETTER',\n",
       " 'H',\n",
       " ',',\n",
       " 'WHICH',\n",
       " 'ALMOST',\n",
       " 'ALONE',\n",
       " 'MAKETH',\n",
       " 'THE',\n",
       " 'SIGNIFICATION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'WORD',\n",
       " ',',\n",
       " 'YOU',\n",
       " 'DELIVER',\n",
       " 'THAT',\n",
       " 'WHICH',\n",
       " 'IS',\n",
       " 'NOT',\n",
       " 'TRUE',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HACKLUYT',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'SW',\n",
       " '.',\n",
       " 'AND',\n",
       " 'DAN',\n",
       " '.',\n",
       " 'HVAL',\n",
       " '.',\n",
       " 'THIS',\n",
       " 'ANIMAL',\n",
       " 'IS',\n",
       " 'NAMED',\n",
       " 'FROM',\n",
       " 'ROUNDNESS',\n",
       " 'OR',\n",
       " 'ROLLING',\n",
       " ';',\n",
       " 'FOR',\n",
       " 'IN',\n",
       " 'DAN',\n",
       " '.',\n",
       " 'HVALT',\n",
       " 'IS',\n",
       " 'ARCHED',\n",
       " 'OR',\n",
       " 'VAULTED',\n",
       " '.\"',\n",
       " '--',\n",
       " 'WEBSTER',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'MORE',\n",
       " 'IMMEDIATELY',\n",
       " 'FROM',\n",
       " 'THE',\n",
       " 'DUT',\n",
       " '.',\n",
       " 'AND',\n",
       " 'GER',\n",
       " '.',\n",
       " 'WALLEN',\n",
       " ';',\n",
       " 'A',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " 'WALW',\n",
       " '-',\n",
       " 'IAN',\n",
       " ',',\n",
       " 'TO',\n",
       " 'ROLL',\n",
       " ',',\n",
       " 'TO',\n",
       " 'WALLOW',\n",
       " '.\"',\n",
       " '--',\n",
       " 'RICHARDSON',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " ',',\n",
       " 'GREEK',\n",
       " '.',\n",
       " 'CETUS',\n",
       " ',',\n",
       " 'LATIN',\n",
       " '.',\n",
       " 'WHOEL',\n",
       " ',',\n",
       " 'ANGLO',\n",
       " '-',\n",
       " 'SAXON',\n",
       " '.',\n",
       " 'HVALT',\n",
       " ',',\n",
       " 'DANISH',\n",
       " '.',\n",
       " 'WAL',\n",
       " ',',\n",
       " 'DUTCH',\n",
       " '.',\n",
       " 'HWAL',\n",
       " ',',\n",
       " 'SWEDISH',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ICELANDIC',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ENGLISH',\n",
       " '.',\n",
       " 'BALEINE',\n",
       " ',',\n",
       " 'FRENCH',\n",
       " '.',\n",
       " 'BALLENA',\n",
       " ',',\n",
       " 'SPANISH',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'FEGEE',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'ERROMANGOAN',\n",
       " '.',\n",
       " 'EXTRACTS',\n",
       " '(',\n",
       " 'SUPPLIED',\n",
       " 'BY',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'LIBRARIAN',\n",
       " ').',\n",
       " 'IT',\n",
       " 'WILL',\n",
       " 'BE',\n",
       " 'SEEN',\n",
       " 'THAT',\n",
       " 'THIS',\n",
       " 'MERE',\n",
       " 'PAINSTAKING',\n",
       " 'BURROWER',\n",
       " 'AND',\n",
       " 'GRUB',\n",
       " '-',\n",
       " 'WORM',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'POOR',\n",
       " 'DEVIL',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " 'APPEARS',\n",
       " 'TO',\n",
       " 'HAVE',\n",
       " 'GONE',\n",
       " 'THROUGH',\n",
       " 'THE',\n",
       " 'LONG',\n",
       " 'VATICANS',\n",
       " 'AND',\n",
       " 'STREET',\n",
       " '-',\n",
       " 'STALLS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'EARTH',\n",
       " ',',\n",
       " 'PICKING',\n",
       " 'UP',\n",
       " 'WHATEVER',\n",
       " 'RANDOM',\n",
       " 'ALLUSIONS',\n",
       " 'TO',\n",
       " 'WHALES',\n",
       " 'HE',\n",
       " 'COULD',\n",
       " 'ANYWAYS',\n",
       " 'FIND',\n",
       " 'IN',\n",
       " 'ANY',\n",
       " 'BOOK',\n",
       " 'WHATSOEVER',\n",
       " ',',\n",
       " 'SACRED',\n",
       " 'OR',\n",
       " 'PROFANE',\n",
       " '.',\n",
       " 'THEREFORE',\n",
       " 'YOU',\n",
       " 'MUST',\n",
       " 'NOT',\n",
       " ',',\n",
       " 'IN',\n",
       " 'EVERY',\n",
       " 'CASE',\n",
       " 'AT',\n",
       " 'LEAST',\n",
       " ',',\n",
       " 'TAKE',\n",
       " 'THE',\n",
       " 'HIGGLEDY',\n",
       " '-',\n",
       " 'PIGGLEDY',\n",
       " 'WHALE',\n",
       " 'STATEMENTS',\n",
       " ',',\n",
       " 'HOWEVER',\n",
       " 'AUTHENTIC',\n",
       " ',',\n",
       " 'IN',\n",
       " 'THESE',\n",
       " 'EXTRACTS',\n",
       " ',',\n",
       " 'FOR',\n",
       " 'VERITABLE',\n",
       " 'GOSPEL',\n",
       " 'CETOLOGY',\n",
       " '.',\n",
       " 'FAR',\n",
       " 'FROM',\n",
       " 'IT',\n",
       " '.',\n",
       " 'AS',\n",
       " 'TOUCHING',\n",
       " 'THE',\n",
       " 'ANCIENT',\n",
       " 'AUTHORS',\n",
       " 'GENERALLY',\n",
       " ',',\n",
       " 'AS',\n",
       " 'WELL',\n",
       " 'AS',\n",
       " 'THE',\n",
       " 'POETS',\n",
       " 'HERE',\n",
       " 'APPEARING',\n",
       " ',',\n",
       " 'THESE',\n",
       " 'EXTRACTS',\n",
       " 'ARE',\n",
       " 'SOLELY',\n",
       " 'VALUABLE',\n",
       " 'OR',\n",
       " 'ENTERTAINING',\n",
       " ',',\n",
       " 'AS',\n",
       " 'AFFORDING',\n",
       " 'A',\n",
       " 'GLANCING',\n",
       " 'BIRD',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'EYE',\n",
       " 'VIEW',\n",
       " 'OF',\n",
       " 'WHAT',\n",
       " 'HAS',\n",
       " 'BEEN',\n",
       " 'PROMISCUOUSLY',\n",
       " 'SAID',\n",
       " ',',\n",
       " 'THOUGHT',\n",
       " ',',\n",
       " 'FANCIED',\n",
       " ',',\n",
       " 'AND',\n",
       " 'SUNG',\n",
       " 'OF',\n",
       " 'LEVIATHAN',\n",
       " ',',\n",
       " 'BY',\n",
       " 'MANY',\n",
       " 'NATIONS',\n",
       " 'AND',\n",
       " 'GENERATIONS',\n",
       " ',',\n",
       " 'INCLUDING',\n",
       " 'OUR',\n",
       " 'OWN',\n",
       " '.',\n",
       " 'SO',\n",
       " 'FARE',\n",
       " 'THEE',\n",
       " 'WELL',\n",
       " ',',\n",
       " 'POOR',\n",
       " 'DEVIL',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " ',',\n",
       " 'WHOSE',\n",
       " 'COMMENTATOR',\n",
       " 'I',\n",
       " 'AM',\n",
       " '.',\n",
       " 'THOU',\n",
       " 'BELONGEST',\n",
       " 'TO',\n",
       " 'THAT',\n",
       " 'HOPELESS',\n",
       " ',',\n",
       " 'SALLOW',\n",
       " 'TRIBE',\n",
       " 'WHICH',\n",
       " 'NO',\n",
       " 'WINE',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'WORLD',\n",
       " 'WILL',\n",
       " 'EVER',\n",
       " 'WARM',\n",
       " ';',\n",
       " 'AND',\n",
       " 'FOR',\n",
       " 'WHOM',\n",
       " 'EVEN',\n",
       " 'PALE',\n",
       " 'SHERRY',\n",
       " 'WOULD',\n",
       " 'BE',\n",
       " 'TOO',\n",
       " 'ROSY',\n",
       " '-',\n",
       " 'STRONG',\n",
       " ';',\n",
       " 'BUT',\n",
       " 'WITH',\n",
       " 'WHOM',\n",
       " 'ONE',\n",
       " 'SOMETIMES',\n",
       " 'LOVES',\n",
       " 'TO',\n",
       " 'SIT',\n",
       " ',',\n",
       " 'AND',\n",
       " 'FEEL',\n",
       " 'POOR',\n",
       " '-',\n",
       " 'DEVILISH',\n",
       " ',',\n",
       " 'TOO',\n",
       " ';',\n",
       " 'AND',\n",
       " 'GROW',\n",
       " 'CONVIVIAL',\n",
       " 'UPON',\n",
       " 'TEARS',\n",
       " ';',\n",
       " 'AND',\n",
       " 'SAY',\n",
       " 'TO',\n",
       " 'THEM',\n",
       " 'BLUNTLY',\n",
       " ',',\n",
       " 'WITH',\n",
       " 'FULL',\n",
       " 'EYES',\n",
       " 'AND',\n",
       " 'EMPTY',\n",
       " 'GLASSES',\n",
       " ',',\n",
       " 'AND',\n",
       " 'IN',\n",
       " 'NOT',\n",
       " 'ALTOGETHER',\n",
       " 'UNPLEASANT',\n",
       " 'SADNESS',\n",
       " '--',\n",
       " 'GIVE',\n",
       " 'IT',\n",
       " 'UP',\n",
       " ',',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUBS',\n",
       " '!',\n",
       " 'FOR',\n",
       " 'BY',\n",
       " 'HOW',\n",
       " 'MUCH',\n",
       " 'THE',\n",
       " 'MORE',\n",
       " 'PAINS',\n",
       " 'YE',\n",
       " 'TAKE',\n",
       " 'TO',\n",
       " 'PLEASE',\n",
       " 'THE',\n",
       " 'WORLD',\n",
       " ',',\n",
       " 'BY',\n",
       " 'SO',\n",
       " 'MUCH',\n",
       " 'THE',\n",
       " 'MORE',\n",
       " 'SHALL',\n",
       " 'YE',\n",
       " 'FOR',\n",
       " 'EVER',\n",
       " 'GO',\n",
       " 'THANKLESS',\n",
       " '!',\n",
       " 'WOULD',\n",
       " 'THAT',\n",
       " 'I',\n",
       " 'COULD',\n",
       " 'CLEAR',\n",
       " 'OUT',\n",
       " 'HAMPTON',\n",
       " 'COURT',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'TUILERIES',\n",
       " 'FOR',\n",
       " 'YE',\n",
       " '!',\n",
       " 'BUT',\n",
       " 'GULP',\n",
       " 'DOWN',\n",
       " 'YOUR',\n",
       " 'TEARS',\n",
       " 'AND',\n",
       " 'HIE',\n",
       " 'ALOFT',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'ROYAL',\n",
       " '-',\n",
       " 'MAST',\n",
       " 'WITH',\n",
       " 'YOUR',\n",
       " 'HEARTS',\n",
       " ';',\n",
       " 'FOR',\n",
       " 'YOUR',\n",
       " 'FRIENDS',\n",
       " 'WHO',\n",
       " 'HAVE',\n",
       " 'GONE',\n",
       " 'BEFORE',\n",
       " 'ARE',\n",
       " 'CLEARING',\n",
       " 'OUT',\n",
       " 'THE',\n",
       " 'SEVEN',\n",
       " '-',\n",
       " 'STORIED',\n",
       " 'HEAVENS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'MAKING',\n",
       " 'REFUGEES',\n",
       " 'OF',\n",
       " 'LONG',\n",
       " '-',\n",
       " 'PAMPERED',\n",
       " 'GABRIEL',\n",
       " ',',\n",
       " 'MICHAEL',\n",
       " ',',\n",
       " 'AND',\n",
       " 'RAPHAEL',\n",
       " ',',\n",
       " 'AGAINST',\n",
       " 'YOUR',\n",
       " 'COMING',\n",
       " '.',\n",
       " 'HERE',\n",
       " 'YE',\n",
       " 'STRIKE',\n",
       " 'BUT',\n",
       " 'SPLINTERED',\n",
       " 'HEARTS',\n",
       " 'TOGETHER',\n",
       " '--',\n",
       " 'THERE',\n",
       " ',',\n",
       " 'YE',\n",
       " 'SHALL',\n",
       " 'STRIKE',\n",
       " 'UNSPLINTERABLE',\n",
       " 'GLASSES',\n",
       " '!',\n",
       " 'EXTRACTS',\n",
       " '.',\n",
       " '\"',\n",
       " 'AND',\n",
       " 'GOD',\n",
       " 'CREATED',\n",
       " 'GREAT',\n",
       " 'WHALES',\n",
       " '.\"',\n",
       " '--',\n",
       " 'GENESIS',\n",
       " '.',\n",
       " '\"',\n",
       " 'LEVIATHAN',\n",
       " 'MAKETH',\n",
       " 'A',\n",
       " 'PATH',\n",
       " 'TO',\n",
       " 'SHINE',\n",
       " 'AFTER',\n",
       " 'HIM',\n",
       " ';',\n",
       " 'ONE',\n",
       " 'WOULD',\n",
       " 'THINK',\n",
       " 'THE',\n",
       " 'DEEP',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'HOARY',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JOB',\n",
       " '.',\n",
       " '\"',\n",
       " 'NOW',\n",
       " 'THE',\n",
       " 'LORD',\n",
       " 'HAD',\n",
       " 'PREPARED',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'FISH',\n",
       " 'TO',\n",
       " 'SWALLOW',\n",
       " 'UP',\n",
       " 'JONAH',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JONAH',\n",
       " '.',\n",
       " '\"',\n",
       " 'THERE',\n",
       " 'GO',\n",
       " 'THE',\n",
       " 'SHIPS',\n",
       " ';',\n",
       " 'THERE',\n",
       " 'IS',\n",
       " 'THAT',\n",
       " 'LEVIATHAN',\n",
       " 'WHOM',\n",
       " 'THOU',\n",
       " 'HAST',\n",
       " 'MADE',\n",
       " 'TO',\n",
       " 'PLAY',\n",
       " 'THEREIN',\n",
       " '.\"',\n",
       " '--',\n",
       " 'PSALMS',\n",
       " '.',\n",
       " '\"',\n",
       " 'IN',\n",
       " 'THAT',\n",
       " 'DAY',\n",
       " ',',\n",
       " 'THE',\n",
       " 'LORD',\n",
       " 'WITH',\n",
       " 'HIS',\n",
       " 'SORE',\n",
       " ',',\n",
       " 'AND',\n",
       " 'GREAT',\n",
       " ',',\n",
       " 'AND',\n",
       " 'STRONG',\n",
       " 'SWORD',\n",
       " ',',\n",
       " 'SHALL',\n",
       " 'PUNISH',\n",
       " 'LEVIATHAN',\n",
       " 'THE',\n",
       " 'PIERCING',\n",
       " 'SERPENT',\n",
       " ',',\n",
       " 'EVEN',\n",
       " 'LEVIATHAN',\n",
       " 'THAT',\n",
       " 'CROOKED',\n",
       " 'SERPENT',\n",
       " ';',\n",
       " 'AND',\n",
       " 'HE',\n",
       " 'SHALL',\n",
       " 'SLAY',\n",
       " 'THE',\n",
       " 'DRAGON',\n",
       " 'THAT',\n",
       " 'IS',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " '.\"',\n",
       " '--',\n",
       " 'ISAIAH',\n",
       " '\"',\n",
       " 'AND',\n",
       " 'WHAT',\n",
       " 'THING',\n",
       " 'SOEVER',\n",
       " 'BESIDES',\n",
       " 'COMETH',\n",
       " 'WITHIN',\n",
       " 'THE',\n",
       " 'CHAOS',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'MONSTER',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'MOUTH',\n",
       " ',',\n",
       " 'BE',\n",
       " 'IT',\n",
       " 'BEAST',\n",
       " ',',\n",
       " 'BOAT',\n",
       " ',',\n",
       " 'OR',\n",
       " 'STONE',\n",
       " ',',\n",
       " 'DOWN',\n",
       " 'IT',\n",
       " 'GOES',\n",
       " 'ALL',\n",
       " 'INCONTINENTLY',\n",
       " 'THAT',\n",
       " 'FOUL',\n",
       " 'GREAT',\n",
       " 'SWALLOW',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'PERISHETH',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'BOTTOMLESS',\n",
       " 'GULF',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " 'PAUNCH',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLUTARCH',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'MORALS',\n",
       " '.',\n",
       " '\"',\n",
       " 'THE',\n",
       " 'INDIAN',\n",
       " 'SEA',\n",
       " 'BREEDETH',\n",
       " 'THE',\n",
       " 'MOST',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'BIGGEST',\n",
       " 'FISHES',\n",
       " 'THAT',\n",
       " 'ARE',\n",
       " ':',\n",
       " 'AMONG',\n",
       " 'WHICH',\n",
       " 'THE',\n",
       " 'WHALES',\n",
       " 'AND',\n",
       " 'WHIRLPOOLES',\n",
       " 'CALLED',\n",
       " 'BALAENE',\n",
       " ',',\n",
       " 'TAKE',\n",
       " 'UP',\n",
       " 'AS',\n",
       " 'MUCH',\n",
       " 'IN',\n",
       " 'LENGTH',\n",
       " 'AS',\n",
       " 'FOUR',\n",
       " 'ACRES',\n",
       " 'OR',\n",
       " 'ARPENS',\n",
       " 'OF',\n",
       " 'LAND',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLINY',\n",
       " '.',\n",
       " '\"',\n",
       " 'SCARCELY',\n",
       " 'HAD',\n",
       " 'WE',\n",
       " 'PROCEEDED',\n",
       " 'TWO',\n",
       " 'DAYS',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " ',',\n",
       " 'WHEN',\n",
       " 'ABOUT',\n",
       " 'SUNRISE',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'MANY',\n",
       " 'WHALES',\n",
       " 'AND',\n",
       " 'OTHER',\n",
       " 'MONSTERS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " ',',\n",
       " 'APPEARED',\n",
       " '.',\n",
       " 'AMONG',\n",
       " 'THE',\n",
       " 'FORMER',\n",
       " ',',\n",
       " 'ONE',\n",
       " 'WAS',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'MOST',\n",
       " 'MONSTROUS',\n",
       " 'SIZE',\n",
       " '.',\n",
       " '...',\n",
       " 'THIS',\n",
       " 'CAME',\n",
       " 'TOWARDS',\n",
       " 'US',\n",
       " ',',\n",
       " 'OPEN',\n",
       " '-',\n",
       " 'MOUTHED',\n",
       " ',',\n",
       " 'RAISING',\n",
       " 'THE',\n",
       " 'WAVES',\n",
       " 'ON',\n",
       " 'ALL',\n",
       " 'SIDES',\n",
       " ',',\n",
       " 'AND',\n",
       " 'BEATING',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " 'BEFORE',\n",
       " 'HIM',\n",
       " 'INTO',\n",
       " 'A',\n",
       " 'FOAM',\n",
       " '.\"',\n",
       " '--',\n",
       " 'TOOKE',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'LUCIAN',\n",
       " '.',\n",
       " '\"',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " '.\"',\n",
       " '\"',\n",
       " 'HE',\n",
       " 'VISITED',\n",
       " 'THIS',\n",
       " 'COUNTRY',\n",
       " 'ALSO',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'VIEW',\n",
       " 'OF',\n",
       " 'CATCHING',\n",
       " 'HORSE',\n",
       " '-',\n",
       " 'WHALES',\n",
       " ',',\n",
       " 'WHICH',\n",
       " 'HAD',\n",
       " 'BONES',\n",
       " 'OF',\n",
       " 'VERY',\n",
       " 'GREAT',\n",
       " 'VALUE',\n",
       " 'FOR',\n",
       " 'THEIR',\n",
       " 'TEETH',\n",
       " ',',\n",
       " 'OF',\n",
       " 'WHICH',\n",
       " 'HE',\n",
       " 'BROUGHT',\n",
       " 'SOME',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'KING',\n",
       " '.',\n",
       " '...',\n",
       " 'THE',\n",
       " 'BEST',\n",
       " 'WHALES',\n",
       " 'WERE',\n",
       " 'CATCHED',\n",
       " 'IN',\n",
       " 'HIS',\n",
       " 'OWN',\n",
       " 'COUNTRY',\n",
       " ',',\n",
       " 'OF',\n",
       " 'WHICH',\n",
       " 'SOME',\n",
       " 'WERE',\n",
       " 'FORTY',\n",
       " '-',\n",
       " 'EIGHT',\n",
       " ',',\n",
       " 'SOME',\n",
       " 'FIFTY',\n",
       " 'YARDS',\n",
       " 'LONG',\n",
       " '.',\n",
       " 'HE',\n",
       " ...]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.upper() for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Returns all words which are capital words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we are not double-counting words like This and this,  which differ only in capitalization,  we've wiped 2,000 off the vocabulary count! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: length of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17231"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word.lower() for word in text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: length of the words which are in text 1 but are lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can go a step further and eliminate numbers and punctuation from the vocabulary count by filtering out any non-alphabetic items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16948"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word.lower() for word in text1 if word.isalpha()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: select the words which are alphabets and then make it lower case and then count the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it lowercases all the purely alphabetic items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Nested Code Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "word='cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word length is less than 5\n"
     ]
    }
   ],
   "source": [
    "if len(word)<5:\n",
    "    print('word length is less than 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: prints the if statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we change the conditional test to len(word) >= 5, to check that the length of word is greater than or equal to 5, then the test will no longer be true. This time, the body of the if statement will not be executed, and no message is shown to the user:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(word)>=5:\n",
    "    print('word length is greater than or equal to 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: no output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An if statement is known as a control structure because it controls whether the code in the indented block will be run. Another control structure is the for loop. Try the following, and remember to include the colon and the four spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n",
      "me\n",
      "Ishmael\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in ['Call','me','Ishmael','.']:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: print all the elements in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4  Looping with Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is called a loop because Python executes the code in circular fashion. It starts by performing the assignment word = 'Call', effectively using the word variable to name the first item of the list. Then, it displays the value of word to the user. Next, it goes back to the for statement, and performs the assignment word = 'me', before displaying this new value to the user, and so on. It continues in this fashion until every item of the list has been processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n",
      "Ishmael\n"
     ]
    }
   ],
   "source": [
    "sent1=['Call','me','Ishmael','.']\n",
    "for xyzzy in sent1:\n",
    "    if xyzzy.endswith('l'):\n",
    "        print(xyzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: print only if the word ends with a 'l'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also specify an action to be taken if the condition of the if statement is not met. Here we see the elif (else if) statement, and the else statement. Notice that these also have colons before the indented code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call is a titlecase word\n",
      "me is a lowercase word\n",
      "Ishmael is a titlecase word\n",
      ". is punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in sent1:\n",
    "    if token.islower():\n",
    "        print(token,'is a lowercase word')\n",
    "    elif token.istitle():\n",
    "        print(token,'is a titlecase word')\n",
    "    else:\n",
    "        print(token, 'is punctuation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: identify words and run the particular case as mentioned above via if/else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we create a list of cie and cei words, then we loop over each item and print it. Notice the extra information given in the print statement: end=' '. This tells Python to print a space (not the default newline) after each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "tricky = sorted(w for w in set(text2) if 'cie' in w or 'cei' in w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancient ceiling conceit conceited conceive conscience conscientious conscientiously deceitful deceive deceived deceiving deficiencies deficiency deficient delicacies excellencies fancied insufficiency insufficient legacies perceive perceived perceiving prescience prophecies receipt receive received receiving society species sufficient sufficiently undeceive undeceiving "
     ]
    }
   ],
   "source": [
    "for word in tricky:\n",
    "    print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Returns words which have cei or cie in it as they seem to be tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lab report as PDF and submit it to Blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q and A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5 Automatic Natural Language Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
